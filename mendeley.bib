@inproceedings{abbas-et-al:splc11,
abstract = {We describe ongoing work in knowledge evolution management for autonomic software product lines. We explore how an autonomic product line may benefit from new knowledge originating from different source activities and artifacts at run time. The motivation for sharing run-time knowledge is that products may self-optimize at run time and thus improve quality faster compared to traditional software product line evolution. We propose two mechanisms that support knowledge evolution in product lines: online learning and knowledge sharing. We describe two basic scenarios for runtime knowledge evolution that involves these mechanisms. We evaluate online learning and knowledge sharing in a small product line setting that shows promising results.},
address = {Munich, Germany},
author = {Abbas, Nadeem and Andersson, Jesper and Weyns, Danny},
booktitle = {Proc. of the 15th International Software Product Line Conference (SPLC '11)},
doi = {10.1145/2019136.2019177},
file = {:Users/vitor/Mendeley/Abbas, Andersson, Weyns - 2011 - Knowledge evolution in autonomic software product lines.pdf:pdf},
isbn = {9781450307895},
keywords = {bibtex,commented,knowledge sharing,online learning,self-adaptation,software product lines},
mendeley-tags = {bibtex,commented},
month = {aug},
pages = {36},
publisher = {ACM},
title = {{Knowledge evolution in autonomic software product lines}},
url = {http://dl.acm.org/citation.cfm?doid=2019136.2019177},
year = {2011}
}
@inproceedings{abdolshah-et-al:icime09,
abstract = {Six Sigma has been a powerful and successful tool in manufacturing industries to reduce rate of rejects and to enhance productivity. The service industries are diversified and the features are different from manufacturing industries. Thus, the use of Six Sigma in service industries and its benefits are limited to some specific types of services like health care and banks. This paper focuses on key performance indicators of Six Sigma and elements to cover a wider range of services. From the analysis of the service models, service industries structures and also by comparing between the features of service and manufacturing industries, the main challenges in application of Six Sigma in service industries can be identified. Further analysis of these challenges showed that the proper implementation of Six Sigma in service industries requires not only the effective operational strategies, but also customers' needs and satisfaction must be considered and designed into the implementation phase. The paper proposed that for the successful implementation of Six Sigma in service industry, instead of just DMAIC, a design phase should be included (DDMAIC). The main meaning of this new phase and its affection will be described.},
address = {Kuala Lumpur, Malaysia},
author = {Abdolshah, Mohammad and Yusuff, Rosnah Mohd. and Ismail, Md. Yusof B. and Hong, Tang Sai},
booktitle = {Proc. of the 2009 International Conference on Information Management and Engineering},
doi = {10.1109/ICIME.2009.120},
file = {:Users/vitor/Mendeley/Abdolshah et al. - 2009 - Overcoming the challenges of implementating Six Sigma in service industries.pdf:pdf},
isbn = {978-0-7695-3595-1},
keywords = {bibtex,implementation of six sigma,not-commented,service industry,six sigma,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
month = {apr},
pages = {191--195},
publisher = {IEEE},
title = {{Overcoming the challenges of implementating Six Sigma in service industries}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5077025},
year = {2009}
}
@inproceedings{acher-et-al:rrt09,
abstract = {Self-adaptive and dynamic systems adapt their behavior ac- cording to the context of execution. The contextual information exhibits multiple variability factors which induce many possible configurations of the software system at runtime. The challenge is to specify the adapta- tion rules that can link the dynamic variability of the context with the possible variants of the system. Our work investigates the systematic use of feature models for modeling the context and the software variants, together with their inter relations, as a way to configure the adaptive system with respect to a particular context. A case study in the domain of video surveillance systems is used to illustrate the approach.},
address = {Denver, CO, USA},
author = {Acher, Mathieu and Collet, Philippe and Fleurey, Franck and Lahire, Philippe and Moisan, Sabine and Rigault, Jean-Paul},
booktitle = {Proc. of the 4th Workshop on Models@run.time},
file = {:Users/vitor/Mendeley/Acher et al. - 2009 - Modeling Context and Dynamic Adaptations with Feature Models.pdf:pdf},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {oct},
pages = {89--98},
publisher = {CEUR},
title = {{Modeling Context and Dynamic Adaptations with Feature Models}},
url = {http://ceur-ws.org/Vol-509/},
year = {2009}
}
@inproceedings{ahmad:notere10,
abstract = {Self-adaptive systems are capable of autonomously modifying their behavior at run-time in response to changing environmental conditions. In order to modify the behavior, requirements play an important role, as they tend to change for these systems. For this we need to identify those requirements that are concerned with the adaptability features of the self-adaptive systems. In order to cope with the uncertainty inherent in self-adaptive systems, requirements engineering languages for these systems should include explicit constructs. RELAX is a requirement engineering language tor self-adaptive systems that incorporates uncertainty into the specification of these systems. To go one step further, we aim at developing a domain specific language that would bridge the gap between requirements and the overall system model. The first step that is illustrated in this paper is to build a textual editor for RELAX.},
address = {Tozeur, Tunisia},
author = {Ahmad, Manzoor},
booktitle = {Proc. of the 10th Annual International Conference on New Technologies of Distributed Systems},
doi = {10.1109/NOTERE.2010.5536629},
file = {:Users/vitor/Mendeley/Ahmad - 2010 - First step towards a Domain Specific Language for Self-Adaptive Systems.pdf:pdf},
isbn = {978-1-4244-7067-9},
keywords = {bibtex,commented,das,domain specific language,dsl,dynamically adaptive systems,eclipse modeling framework,emf},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {285--290},
publisher = {IEEE},
title = {{First step towards a Domain Specific Language for Self-Adaptive Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5536629},
year = {2010}
}
@techreport{ahnert-pg14,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Ahnert, Rogner R.},
file = {:Users/vitor/Mendeley/Ahnert - 2014 - Ger{\^{e}}ncia de Conhecimento Aplicada ao Desenvolvimento {\'{A}}gil de Software com SCRUM.pdf:pdf},
institution = {Projeto de Gradua{\c{c}}{\~{a}}o, Departamento de Inform{\'{a}}tica, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{Ger{\^{e}}ncia de Conhecimento Aplicada ao Desenvolvimento {\'{A}}gil de Software com SCRUM}},
year = {2014}
}
@inproceedings{ali-et-al:istar10,
abstract = {Software evolution is the main research focus of the Tropos group at University of Trento (UniTN): how do we build systems that are aware of their requirements, and are able to dynamically reconfigure themselves in response to changes in context (the environment within which they operate) and requirements. The purpose of this report is to offer an overview of ongoing work at UniTN. In particular, the report presents ideas and results of four lines of research: contextual requirements modeling and reasoning, commitments and goal models, developing self-reconfigurable systems, and requirements awareness.},
address = {Hammamet, Tunisia},
annote = {Short paper},
author = {Ali, Raian and Chopra, Amit K. and Dalpiaz, Fabiano and Giorgini, Paolo and Mylopoulos, John and Souza, V{\'{i}}tor E. S.},
booktitle = {Proc. of the 4th International i* Workshop},
file = {:Users/vitor/Mendeley/Ali et al. - 2010 - The Evolution of Tropos Contexts, Commitments and Adaptivity.pdf:pdf},
keywords = {bibtex,export},
mendeley-tags = {bibtex,export},
pages = {15--19},
publisher = {CEUR},
title = {{The Evolution of Tropos: Contexts, Commitments and Adaptivity}},
url = {http://sunsite.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-586/},
year = {2010}
}
@article{ali-et-al:rej10,
abstract = {Requirements engineering (RE) research often ignores or presumes a uniform nature of the context in which the system operates. This assumption is no longer valid in emerging computing paradigms, such as ambient, pervasive and ubiquitous computing, where it is essential to monitor and adapt to an inherently varying context. Besides influencing the software, context may influence stakeholders' goals and their choices to meet them. In this paper, we propose a goal-oriented RE modeling and reasoning framework for systems operating in varying contexts. We introduce contextual goal models to relate goals and contexts; context analysis to refine contexts and identify ways to verify them; reasoning techniques to derive requirements reflecting the context and users priorities at runtime; and finally, design time reasoning techniques to derive requirements for a system to be developed at minimum cost and valid in all considered contexts. We illustrate and evaluate our approach through a case study about a museum-guide mobile information system.},
annote = {10.1007/s00766-010-0110-z},
author = {Ali, Raian and Dalpiaz, Fabiano and Giorgini, Paolo},
doi = {10.1007/s00766-010-0110-z},
file = {:Users/vitor/Mendeley/Ali, Dalpiaz, Giorgini - 2010 - A goal-based framework for contextual requirements modeling and analysis.pdf:pdf},
issn = {0947-3602},
journal = {Requirements Engineering},
keywords = {bibtex,context analysis,contextual requirements,goal modeling,not-commented,requirement analysis},
mendeley-tags = {bibtex,not-commented},
number = {4},
pages = {439--458},
publisher = {Springer London},
title = {{A goal-based framework for contextual requirements modeling and analysis}},
url = {http://www.springerlink.com/content/823187363781lg37/},
volume = {15},
year = {2010}
}
@inproceedings{ali-et-al:ebpism11,
abstract = {Requirements evolution is a main driver for systems evolution. Traditionally, requirements evolution is associated to changes in the users' needs and environments. In this paper, we explore another cause for requirements evolution: assumptions. Requirements engineers often make assumptions stating, for example, that satisfying certain sub-requirements and/or correctly executing certain system functionalities would lead to reach a certain requirement. However, assumptions might be, or eventually become, invalid. We outline an approach to monitor, at runtime, the assumptions in a requirements model and to evolve the model to reflect the validity level of such assumptions. We introduce two types of requirements evolution: autonomic (which evolves the priorities of system alternatives based on their success/failure in meeting requirements) and designer-supported (which detects loci in the requirements model containing invalid assumptions and recommends designers to take evolutionary actions).},
address = {London, UK},
annote = {Qualis 2012: B4},
author = {Ali, Raian and Dalpiaz, Fabiano and Giorgini, Paolo and Souza, V{\'{i}}tor E. S.},
booktitle = {Proc. of the 12th International Conference on Enterprise, Business-Process and Information Systems Modeling},
doi = {10.1007/978-3-642-21759-3_27},
editor = {Halpin, Terry and Nurcan, Selmin and Krogstie, John and Soffer, Pnina and Proper, Erik and Schmidt, Rainer and Bider, Ilia},
file = {:Users/vitor/Mendeley/Ali et al. - 2011 - Requirements Evolution From Assumptions to Reality.pdf:pdf},
isbn = {978-3-642-21758-6},
keywords = {bibtex,contextual requirements,export,requirements evolution,requirements modeling},
mendeley-tags = {bibtex,export},
month = {jun},
pages = {372--382},
publisher = {Springer},
series = {Lecture Notes in Business Information Processing},
title = {{Requirements Evolution: From Assumptions to Reality}},
url = {http://www.springerlink.com/content/p645731n8520324h/},
volume = {81},
year = {2011}
}
@inproceedings{ali-et-al:enase12,
abstract = {Adaptive systems are characterized by the ability to monitor changes in their volatile world and react to monitored changes when needed. The ultimate goal of adaptation is that users' requirements are always met correctly and efficiently. Adaptation is traditionally driven by the changing state of the system internal and its surrounding environment. Such state should be monitored and analyzed to decide upon a suitable alternative behaviour to adopt. In this paper, we introduce another driver for adaptation which is the users' collective judgement on the alternative behaviors of a system. This judgmenet should be infered from the individual users' feedback given iteratviely during the lifetime of a system. Users' feedback reflects their main interest which is the validity and the quality of a system behaviour as a means to meet their requirements. We propose social adaptation which is a specific kind of adaptation that treats users' feedback, obtained during the software lifetime, as a primary driver in planning and guiding adaptation. We propose a novel requirements engineering modelling and analysis approach meant for systems adopting social adaptation. We evaluate our approach by applying it in practice and report on the results.},
address = {Wroclaw, Poland},
author = {Ali, Raian and Solis, Carlos and Omoronyia, Inah and Salehie, Mazeiar and Nuseibeh, Bashar},
booktitle = {Proc. of the 7th International Conference on Evaluation of Novel Approaches to Software Engineering},
editor = {Filipe, Joaquim and Maciaszek, Leszek A.},
file = {:Users/vitor/Mendeley/Ali et al. - 2012 - Social Adaptation - When Software Gives Users a Voice(2).pdf:pdf},
keywords = {bibtex,not-commented,requirements engineering,requirements-driven adaptation,social adaptation},
mendeley-tags = {bibtex,not-commented},
month = {jun},
number = {November},
pages = {75--84},
publisher = {SciTePress},
title = {{Social Adaptation - When Software Gives Users a Voice}},
url = {http://www.informatik.uni-trier.de/{~}ley/db/conf/enase/enase2012.html},
year = {2012}
}
@book{alur-et-al:book03,
abstract = {In the world of software, a pattern is a tangible manifestation of an organization's tribal memory. A pattern provides a common solution to a common problem and so, within the culture of one specific organization or within one domain, naming and then specifying a pattern represents the codification of a common solution, drawn from proven, prior experience. Having a good language of patterns at your disposal is like having an extended team of experts sitting at your side during development: by applying one of their patterns, you in effect take the benefit of their hard-won knowledge. As such, the best patterns are not so much invented as they are discovered and then harvested from existing, successful systems. Thus, at its most mature state, a pattern is full of things that work, absent of things that don't work, and revealing of the wisdom and rationale of its designers. Deep, really useful, patterns are typically ancient: you see one and will often remark, "Hey, I've done that before." However, the very naming of the pattern gives you a vocabulary that you didn't have previously and so helps you apply that pattern in ways you otherwise might have not have realized. Ultimately, the effect of such a pattern will be to make your system simpler. Patterns not only help you build simpler systems that work, but they also help you build beautiful programs. In a culture of time starvation, writing beautiful software is often impossible. That's sad, for as professionals, we strive to build things of quality. By applying a good set of patterns, it is possible to bring a degree of elegance in to your systems that might otherwise have been lacking. The authors of Core J2EE Patterns have harvested a really useful set of patterns. Don't get me wrong: J2EE is certainly an important platform, enabling teams to build some very powerful systems. However, reality is, there is still a wide semantic gap between the abstractions and services that J2EE provides and the final application that a team must build. Patterns such as specified in this book represent solutions that appear again and again in filling that gap. By applying these patterns, you thus carry out the primary means of reducing software risk: you write less software. Rather than discovering these solutions on your own, apply these patterns, which have already proven their utility in existing systems. More than just naming a set of patterns, the authors make them approachable by specifying their semantics using the UML. Additionally, they show you how to apply these patterns and how to refactor your system to take advantage of them. Again, it's just like having a team of experts sitting at your side.},
author = {Alur, Deepak and Crupi, John and Malks, Dan},
edition = {2nd},
isbn = {0131422464},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Prentice Hall / Sun Microsystems Press},
title = {{Core J2EE Patterns: Best Practices and Design Strategies}},
url = {http://www.corej2eepatterns.com/AboutTheBook.htm},
year = {2003}
}
@inproceedings{an-et-al:ceceast04,
abstract = {Sense-and-Respond systems realize the concepts of autonomic computing at the level of business processes. One of the key requirements to build Sense-and- Respond systems is to accurately capture and model the dynamical behavior of business metrics, a.k.a. key performance indicators (KPI). System Dynamics (SD) models and the runtime engines provide means to understand both key performance indicators and the dynamic behaviors (e.g. causality) among them. In this paper, we present a system dynamics model based upon a scenario from supply chain management domain. Our purpose is to demonstrate an alternative approach of building Sense-and-Respond systems. Specifically, we use system dynamics to formally define the KPIs of both the retail inventory and the supplier backlog. Additionally, we introduce objective functions and control variables as the optimization elements being part of the system dynamics formalism. Therefore, the decision (e.g. the order size from manufacturer to suppliers) would correspond to the optimal solution of the system with respect to the defined objective. These concepts will be explained through scenarios. The enabling reference architecture and deployment method using system dynamics are also presented in this paper. After the system dynamics models and corresponding components are deployed to the field, the whole system will manifest the Sense-and- Respond behavior in a dynamical fashion.},
address = {Beijing , China},
annote = {Very badly written, but very interesting topic. See references for more interesting readings.},
author = {An, Lianjun and Jeng, Jun-Jang and Ettl, Markus and Chung, Jen-Yao},
booktitle = {IEEE International Conference on E-Commerce Technology for Dynamic E-Business},
doi = {10.1109/CEC-EAST.2004.11},
file = {:Users/vitor/Mendeley/An et al. - 2004 - A System Dynamics Framework for Sense-and-Respond Systems.pdf:pdf},
isbn = {0-7695-2206-8},
keywords = {autonomic business process,bibtex,commented,optimal control,sense-and-respond system,summarized,system dynamics},
mendeley-tags = {bibtex,commented,summarized},
month = {sep},
pages = {6--13},
publisher = {IEEE},
title = {{A System Dynamics Framework for Sense-and-Respond Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1388294},
year = {2004}
}
@incollection{andersson-et-al:sesas09,
abstract = {It is commonly agreed that a self-adaptive software system is one that can modify itself at run-time due to changes in the system, its requirements, or the environment in which it is deployed. A cursory review of the software engineering literature attests to the wide spectrum of software systems that are described as self-adaptive. The way self-adaptation is conceived depends on various aspects, such as the users' requirements, the particular properties of a system, and the characteristics of the environment. In this paper, we propose a classification of modeling dimensions for self-adaptive software systems. Each modeling dimension describes a particular facet of the system that is relevant to self-adaptation. The modeling dimensions provide the engineers with a common set of vocabulary for specifying the self-adaptive properties under consideration and select suitable solutions. We illustrate how the modeling dimensions apply to several application scenarios.},
annote = {10.1007/978-3-642-02161-9{\_}2},
author = {Andersson, Jesper and de Lemos, Rog{\'{e}}rio and Malek, Sam and Weyns, Danny},
booktitle = {Software Engineering for Self-Adaptive Systems},
doi = {10.1007/978-3-642-02161-9_2},
editor = {Cheng, Betty H. C. and de Lemos, Rog{\'{e}}rio and Giese, Holger and Inverardi, Paola and Magee, Jeff},
file = {:Users/vitor/Mendeley/Andersson et al. - 2009 - Modeling Dimensions of Self-Adaptive Software Systems.pdf:pdf},
isbn = {978-3-642-02160-2},
keywords = {bibtex,commented,dynamic adaptation,modeling,self-*,self-adaptive,summarized},
mendeley-tags = {bibtex,commented,summarized},
pages = {27--47},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Modeling Dimensions of Self-Adaptive Software Systems}},
url = {http://www.springerlink.com/content/2542744254123656/},
volume = {5525},
year = {2009}
}
@techreport{andriao-araujo-spec06,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Andri{\~{a}}o, Carlos Eduardo and de Ara{\'{u}}jo, Frederico Xavier},
institution = {P{\'{o}}s-gradua{\c{c}}{\~{a}}o em Java, Tecnologias e Desenvolvimento de Sistemas, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{SAD – Sistema de Avalia{\c{c}}{\~{a}}o Disciplinar}},
year = {2006}
}
@inproceedings{angelopoulos-et-al:seams16,
abstract = {Self-adaptive software systems monitor their operation and adapt when their requirements fail due to unexpected phenomena in their environment. This paper examines the case where the environment changes dynamically over time and the chosen adaptation has to take into account such changes. In control theory, this type of adaptation is known as Model Predictive Control and comes with a well-developed theory and myriads of successful applications. The paper focuses on modelling the dynamic relationship between requirements and possible adaptations. It then proposes a controller that exploits this relationship to optimize the satisfaction of requirements relative to a cost-function. This is accomplished through a model-based framework for designing self-adaptive software systems that can guarantee a certain level of requirements satisfaction over time, by dynamically composing adaptation strategies when necessary. The proposed framework is illustrated and evaluated through a simulation of the Meeting-Scheduling System exemplar.},
address = {Austin, TX, USA},
author = {Angelopoulos, Konstantinos and Papadopoulos, Alessandro V. and Souza, V{\'{i}}tor E. S. and Mylopoulos, John},
booktitle = {Proc. of the 11th International Workshop on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1145/2897053.2897054},
file = {:Users/vitor/Mendeley/Angelopoulos et al. - 2016 - Model predictive control for software systems with CobRA.pdf:pdf},
isbn = {9781450341875},
keywords = {awareness requirements,bibtex,export,model predictive control,self-adaptive systems},
mendeley-tags = {bibtex,export},
month = {may},
pages = {35--46},
publisher = {ACM},
title = {{Model predictive control for software systems with CobRA}},
url = {http://dl.acm.org/citation.cfm?doid=2897053.2897054},
year = {2016}
}
@inproceedings{angelopoulos-et-al:seams14,
abstract = {Adaptive software systems monitor the environment to ensure that their requirements are being fullled. When this is not the case, their adaptation mechanism proposes an adaptation (a change to the behaviour/configuration) that can lead to restored satisfaction of system requirements. Unfortunately, such adaptation mechanisms don't work very well in cases where there are multiple failures (divergence of system behaviour relative to several requirements). This paper proposes an adaptation mechanism that can handle multiple failures. The proposal consists of extending the Qualia adaptation mechanism of Zanshin enriched with features adopted from Control Theory. The proposed framework supports the definition of requirements for the adaptation process prescribing how to deal at runtime with problems such as conflicting requirements and synchronization, enhancing the precision and effectiveness of the adaptation mechanism. The proposed mechanism, named Qualia+ is illustrated and evaluated with an example using the meeting scheduling exemplar.},
address = {Hyderabad, India},
annote = {Qualis 2012: B3},
author = {Angelopoulos, Konstantinos and Souza, V{\'{i}}tor E. S. and Mylopoulos, John},
booktitle = {Proc. of the 9th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1145/2593929.2593936},
file = {:Users/vitor/Mendeley/Angelopoulos, Souza, Mylopoulos - 2014 - Dealing with multiple failures in Zanshin a control-theoretic approach.pdf:pdf},
isbn = {9781450328647},
keywords = {Requirements Engineering,Zanshin,adaptive systems,bibtex,export,multiple fail- ures,optimization},
mendeley-tags = {bibtex,export},
month = {jun},
pages = {165--174},
publisher = {ACM},
title = {{Dealing with multiple failures in Zanshin: a control-theoretic approach}},
url = {http://dl.acm.org/citation.cfm?doid=2593929.2593936},
year = {2014}
}
@inproceedings{angelopoulos-et-al:er15,
abstract = {Variability is essential for adaptive software systems, because it captures the space of alternative adaptations a system is capable of when it needs to adapt. In this work, we propose to capture variability for an adaptation space in terms of a three dimensional model. The first dimension captures requirements through goals and reflects all possible ways of achieving these goals. The second dimension captures supported variations of a system's architectural structure, modeled in terms of connectors and components. The third dimension describes supported system behaviors, by modeling possible sequences for goal fulfillment and task execution. Of course, the three dimensions of a variability model are inter-twined as choices made with respect to one dimension have impact on the other two. Therefore, we propose an incremental design methodology for variability models that keeps the three dimensions aligned and consistent. We illustrate our proposal with a case study involving the meeting scheduling system exemplar.},
address = {Stockholm, Sweden},
annote = {Qualis 2012: A2},
author = {Angelopoulos, Konstantinos and Souza, V{\'{i}}tor E. S. and Mylopoulos, John},
booktitle = {Proc. of the 34th International Conference on Conceptual Modeling},
doi = {10.1007/978-3-319-25264-3_28},
editor = {Johannesson, Paul and Lee, Mong Li and Liddle, Stephen W. and Opdahl, Andreas L. and L{\'{o}}pez, {\'{O}}scar Pastor},
file = {:Users/vitor/Mendeley/Angelopoulos, Souza, Mylopoulos - 2015 - Capturing Variability in Adaptation Spaces A Three-Peaks Approach.pdf:pdf},
keywords = {architecture behaviors,bibtex,export,requirements,three-peaks,variability},
mendeley-tags = {bibtex,export},
month = {oct},
pages = {384--398},
publisher = {Springer},
title = {{Capturing Variability in Adaptation Spaces: A Three-Peaks Approach}},
url = {http://link.springer.com/10.1007/978-3-319-25264-3{\_}28},
year = {2015}
}
@inproceedings{angelopoulos-et-al:seams13,
abstract = {The growing interest in adaptive software systems has resulted in a number of different proposals for the de- sign of adaptive systems. Some approaches adopt architectural models, whereas others model adaptation options, at the level of requirements. This dichotomy has motivated us to perform a comparative study between two proposals for the design of adaptive systems: the Rainbow Framework (architecture- based) and our own proposal, Zanshin (requirements-based). This evaluation paper reports on our methodology and results. It also provides a comparison between the use of architectural and requirements models as centrepieces of adaptation, offering guidelines for the future research in the field of adaptive systems.},
address = {San Francisco, CA, USA},
annote = {Qualis 2012: B3},
author = {Angelopoulos, Konstantinos and Souza, V{\'{i}}tor E. S. and Pimentel, Jo{\~{a}}o},
booktitle = {Proc. of the 8th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1109/SEAMS.2013.6595489},
file = {:Users/vitor/Mendeley/Angelopoulos, Souza, Pimentel - 2013 - Requirements and Architectural Approaches to Adaptive Software Systems A Comparative Study.pdf:pdf},
keywords = {adaptation,adaptive systems,architecture,bibtex,comparative study,export,rainbow,requirements,zanshin},
mendeley-tags = {bibtex,export},
month = {may},
pages = {23--32},
publisher = {IEEE},
title = {{Requirements and Architectural Approaches to Adaptive Software Systems: A Comparative Study}},
url = {http://dl.acm.org/citation.cfm?id=2487343},
year = {2013}
}
@inproceedings{anton:icre96,
abstract = {Goals are a logical mechanism for identifying, organizing and justifying software requirements. Strategies are needed for the initial identification and construction of goals. In this paper we discuss goals from the perspective of two themes: goal analysis and goal evolution. We begin with an overview of the goal-based method we have developed and summarize our experiences in applying our method to a relatively large example. We illustrate some o fthe issues that practitioners face when suing a goal-based approach to specify the requirements for a system and close the paper with a discussion of needed future research on goal-based requirements analysis and evolution.},
address = {Colorado Springs, CO, USA},
author = {Ant{\'{o}}n, Annie I.},
booktitle = {Proc. of the 2nd International Conference on Requirements Engineering},
file = {:Users/vitor/Mendeley/Ant{\'{o}}n - 1996 - Goal-Based Requirements Analysis.pdf:pdf},
isbn = {0-8186-7252-8},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {136--144},
publisher = {IEEE},
title = {{Goal-Based Requirements Analysis}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=491438{\&}tag=1},
year = {1996}
}
@inproceedings{anton-potts:icse01,
abstract = {It has long been accepted that requirements analysis should precede architectural design and implementation, but in software evolution and reverse engineering this concern with black-box analysis of function has necessarily been de-emphasized in favor of code-based analysis and designer-oriented interpretation. We redress this balance by describing 'functional paleontology': an approach to analyzing the evolution of user-visible features or services independent of architecture and design intent. We classify the benefits and burdens of interpersonal communication services into core and peripheral categories and investigate the telephony services available to domestic subscribers over a fifty-year period. We report that services were introduced in discrete bursts, each of which emphasized different benefits and burdens. We discuss the general patterns of functional evolution that this "fossil record" illustrates and conclude by discussing their implications for forward engineering of software products.},
address = {Toronto, ON, Canada},
author = {Ant{\'{o}}n, Annie I. and Potts, Colin},
booktitle = {Proc. of the 23rd International Conference on Software Engineering},
doi = {10.1109/ICSE.2001.919115},
file = {:Users/vitor/Mendeley/Ant{\'{o}}n, Potts - 2001 - Functional Paleontology System Evolution as the User Sees It.pdf:pdf},
isbn = {0-7695-1050-7},
keywords = {bibtex,empirical methods,human-computer interaction (HCI),measurement,metrics,not-commented,requirements engineering,reverse engineering,software evolution},
mendeley-tags = {bibtex,not-commented},
month = {may},
pages = {421--430},
publisher = {IEEE},
title = {{Functional Paleontology: System Evolution as the User Sees It}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=919115},
year = {2001}
}
@book{aurum-wohlin:book05,
abstract = {Requirements engineering is the process by which the requirements for software systems are gathered, analyzed, documented, and managed throughout their complete lifecycle. Traditionally it has been concerned with technical goals for, functions of, and constraints on software systems. Aurum and Wohlin, however, argue that it is no longer appropriate for software systems professionals to focus only on functional and non-functional aspects of the intended system and to somehow assume that organizational context and needs are outside their remit. Instead, they call for a broader perspective in order to gain a better understanding of the interdependencies between enterprise stakeholders, processes, and software systems, which would in turn give rise to more appropriate techniques and higher-quality systems. Following an introductory chapter that provides an exploration of key issues in requirements engineering, the book is organized in three parts. Part 1 presents surveys of state-of-the art requirements engineering process research along with critical assessments of existing models, frameworks and techniques. Part 2 addresses key areas in requirements engineering, such as market-driven requirements engineering, goal modeling, requirements ambiguity, and others. Part 3 concludes the book with articles that present empirical evidence and experiences from practices in industrial projects. Its broader perspective gives this book its distinct appeal and makes it of interest to both researchers and practitioners, not only in software engineering but also in other disciplines such as business process engineering and management science.},
doi = {10.1007/3-540-28244-0},
editor = {Aurum, Ayb{\"{u}}ke and Wohlin, Claes},
isbn = {3-540-25043-3},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Springer},
title = {{Engineering and Managing Software Requirements}},
url = {http://link.springer.com/10.1007/3-540-28244-0},
year = {2005}
}
@inproceedings{awang-et-al:icsea09,
abstract = {Software needs to evolve to ensure it continuously relevant in supporting the needs of an organization. Thus, software evolution is unavoidable for its survival. Due to rapid changes in business environment and advancement of technology, simplifying software evolution becomes more challenging and may involve high cost. Approaches in simplifying software evolution via software adaptation have been the subject of many current researches. Based on exhaustive literature review, we define four classifications of approaches to software adaptation. The four approaches are Architecture-based, Component-based, Middleware-based and Agent-based. In this paper we present the results of a systematic comparison on the state-of-the-art in software adaptation approaches mentioned earlier. Five evaluation criteria are defined to compare the said approaches. The evaluation criteria used are scalability, context-awareness, heterogeneity, performance and dynamic evolvability. The result of the evaluation is used to determine the best current approach to developing adaptive software in order to simplify software evolution. The evaluation result is also used as input for the development of a framework to simplify software evolution. High-level view of the framework is presented towards the end of the paper.},
address = {Porto, Portugal},
author = {Awang, Nor Hazilawati and Kadir, Wan M.N. Wan and Shahibuddin, Shamsul},
booktitle = {Proc. of the 4th International Conference on Software Engineering Advances},
doi = {10.1109/ICSEA.2009.68},
file = {:Users/vitor/Mendeley/Awang, Kadir, Shahibuddin - 2009 - Comparative Evaluation of the State-of-the Art on Approaches to Software Adaptation.pdf:pdf},
isbn = {978-1-4244-4779-4},
keywords = {agent-based,architecture-based,bibtex,commented,component-based,middleware-based,software adaptation,software evolution},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {425--430},
publisher = {IEEE},
title = {{Comparative Evaluation of the State-of-the Art on Approaches to Software Adaptation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5298863},
year = {2009}
}
@techreport{barbacci-et-al:report03,
abstract = {The Quality Attribute Workshop (QAW) is a facilitated method that engages system stakeholders early in the life cycle to discover the driving quality attributes of a software-intensive system. The QAW was developed to complement the Architecture Tradeoff Analysis Method (ATAM) and provides a way to identify important quality attributes and clarify system requirements before the software architecture has been created. This is the third edition of a technical report describing the QAW. We have narrowed the scope of a QAW to the creation of prioritized and refined scenarios. This report describes the newly revised QAW and describes potential uses of the refined scenarios generated during it.},
author = {Barbacci, Mario R. and Ellison, Robert and Lattanze, Anthony J. and Stafford, Judith A. and Weinstock, Charles B. and Wood, William G.},
file = {:Users/vitor/Mendeley/Barbacci et al. - 2003 - Quality Attribute Workshops (QAWs), Third Edition.pdf:pdf},
institution = {CMU/SEI-2003-TR-016, Carnegie Mellon University},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
title = {{Quality Attribute Workshops (QAWs), Third Edition}},
url = {http://www.sei.cmu.edu/library/abstracts/reports/03tr016.cfm},
year = {2003}
}
@book{seams12,
abstract = {Gr{\"{u}}ezi and welcome to SEAMS 2012, the 7th ACM/IEEE International Symposium on Software Engineering for Adaptive and Self-Managing Systems, on June 4-5, 2012 in Z{\"{u}}rich, Switzerland. As in previous years SEAMS is co-located with the ACM/IEEE International Conference on Software Engineering (ICSE). The increasing complexity, distribution, and dynamism of many software-intensive systems impose self-managing capabilities as key requirements. These systems must be able to adapt themselves at runtime to cope with changes in operating environments, variability of resources, new user needs, intrusions, or faults. The goal is to preserve effective, secure, and safe operation and react to changes with no (or limited) human intervention. Solutions to complement software systems with self-managing and self-adaptive capabilities have been proposed by researchers in many different areas, including software architecture, fault-tolerant computing, robotics, control systems, programming languages, runtime program analysis and verification, and biologically-inspired computing. The SEAMS Symposium focuses on the software engineering aspects, including the methods, techniques, and tools that can be used to support self-adaptive, self-managing, self-healing, selfoptimizing, and self-configuring software systems. The objective of the SEAMS Symposium is to bring together researchers and practitioners from many diverse areas to investigate, discuss, and examine thoroughly the fundamental principles, state of the art, and critical challenges of self-adaptive and self-managing systems. This second year of SEAMS as a symposium continues to attract researchers and practitioners from the different disciplines interested in self-adaptive systems. We received 50 submissions, and after a thorough review process—each paper was reviewed by at least three program committee members—accepted 14 full papers and 5 short papers. The SEAMS 2012 program comprises two keynotes, presentations of the 19 technical papers, a panel on runtime validation and verification, and short reports on on-going activities in the self-adaptive systems community. The invited presentations feature two key research topics of self-adaptive systems. Professor Raffaello D'Andrea, ETH Z{\"{u}}rich (Switzerland) and co-founder of Kiva Systems, discusses model-based adaptation and learning for robotic systems. Professor Franco iiiZambonelli, Universit{\`{a}} di Modena e Reggio Emilia (Italy), addresses the benefits of reconciling self-adaptation and self-organization. The technical papers cover many different aspects of self-adaptive systems. Authors analyze and summarize existing systems and literature in the form of taxonomies and reference models and address requirements elicitation as well as design and validation of selfadaptive, service-based, and distributed systems. Researchers exploit models, stochastic verification and control theory to develop innovative solutions. The SEAMS 2012 Symposium also emphasizes the importance of identifying significant exemplars for the community to use as benchmarks to validate and compare approaches. In an exemplar session, anchored by an interesting traffic control system paper, paper presenters have the opportunity to outline their favorite example system. We are deeply indebted to many people for their help and support in organizing SEAMS 2012. First of all, we would like to thank all the authors who submitted papers and all the participants who contributed to the SEAMS 2012 Symposium in Z{\"{u}}rich. We particularly would like to thank the members of our Program Committee who reviewed the papers and participated in numerous discussions during the paper review process. We also would like to thank our Publicity Co-Chairs, Gabriel Tamura and Norha Villegas, who helped promote and advertise SEAMS 2012 to attract submissions and participants. We also greatly acknowledge the strong commitment and generous support from Martin Glinz, General Chair of ICSE 2012, and Kurt Schneider, Proceedings Chair, for arranging the SEAMS 2012 proceedings details. We also would like to acknowledge the co-sponsorship of the SEAMS Symposium by ACM SIGSoft and IEEE Computer Society Technical Council on Software Engineering (TCSE). Last, but not least, we thank Rog{\'{e}}rio de Lemos, Chair SEAMS Steering Committee, who continuously provided advice and kept us on track. Enjoy SEAMS 2012 and have a wonderful time in Z{\"{u}}rich and Switzerland!},
address = {Zurich, Switzerland},
doi = {10.1109/SEAMS.2012.6224406},
editor = {Baresi, Luciano and M{\"{u}}ller, Hausi A.},
isbn = {978-1-4673-1787-0},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {jun},
publisher = {IEEE},
title = {{Proceedings of the 7th International Symposium on Software Engineering for Adaptive and Self-Managing Systems}},
url = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6220308},
year = {2012}
}
@inproceedings{baresi-pasquale:icws10,
abstract = {Service compositions need to continuously self- adapt to cope with unexpected failures. In this context adaptation becomes a fundamental requirement that must be elicited along with the other functional and non functional requirements. Beside modelling, effective adaptation also demands means to trigger it at runtime as soon as the actual behavior of the composition deviates from stated requirements. This paper extends traditional goal models with adaptive goals to support continuous adaptation. Goals become live, runtime entities whose satisfaction level is dynamically updated. Furthermore, boundary infringement triggers adaptation capabilities. The paper also provides a methodology to trace goals onto the underlying composition, assess goals satisfaction at runtime, and activate adaptation consequently. All the key elements are demonstrated on the definition of the process to control an advanced washing machine.},
address = {Miami, FL, USA},
author = {Baresi, Luciano and Pasquale, Liliana},
booktitle = {Proc. of the 8th IEEE International Conference on Web Services},
doi = {10.1109/ICWS.2010.60},
file = {:Users/vitor/Mendeley/Baresi, Pasquale - 2010 - Adaptive Goals for Self-Adaptive Service Compositions.pdf:pdf},
isbn = {978-1-4244-8146-0},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {jul},
pages = {353--360},
publisher = {IEEE},
title = {{Adaptive Goals for Self-Adaptive Service Compositions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5552765},
year = {2010}
}
@inproceedings{baresi-et-al:re10,
abstract = {Self-adaptation is imposing as a key characteristic of many modern software systems to tackle their complexity and cope with the many environments in which they can operate. Self-adaptation is a requirement per-se, but it also impacts the other (conventional) requirements of the system; all these new and old requirements must be elicited and represented in a coherent and homogenous way. This paper presents FLAGS, an innovative goal model that generalizes the KAOS model, adds adaptive goals to embed adaptation countermeasures, and fosters self-adaptation by considering requirements as live, runtime entities. FLAGS also distinguishes between crisp goals, whose satisfaction is boolean, and fuzzy goals, whose satisfaction is represented through fuzzy constraints. Adaptation countermeasures are triggered by violated goals and the goal model is modified accordingly to maintain a coherent view of the system and enforce adaptation directives on the running system. The main elements of the approach are demonstrated through an example application.},
address = {Sidney, Australia},
author = {Baresi, Luciano and Pasquale, Liliana and Spoletini, Paola},
booktitle = {Proc. of the 18th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2010.25},
file = {:Users/vitor/Mendeley/Baresi, Pasquale, Spoletini - 2010 - Fuzzy Goals for Requirements-driven Adaptation.pdf:pdf},
isbn = {978-1-4244-8022-7},
keywords = {bibtex,fuzzy goals,goals,highlight,kaos,not-commented,self-adaptation},
mendeley-tags = {bibtex,highlight,not-commented},
month = {sep},
pages = {125--134},
publisher = {IEEE},
title = {{Fuzzy Goals for Requirements-driven Adaptation}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5636887{\&}tag=1},
year = {2010}
}
@incollection{barone-et-al:tpem11,
abstract = {Business organizations continuously monitor their environments, looking out for opportunities and threats that may help/hinder the fulfilment of their objectives. We are interested in strategic business models that support such governance activities. In this paper, we focus on the concept of composite indicator and show how it can be used as basic building block for strategic business models that support evaluation and decision-making. The main results of this paper include techniques and algorithms for deriving values for composite indicators, when the relationship between a composite indicator and its component indicators cannot be fully described using well-defined mathematical functions. Evaluation of our proposal includes an implemented Eclipse-based prototype tool supporting these techniques and two ongoing case studies.},
author = {Barone, Daniele and Jiang, Lei and Amyot, Daniel and Mylopoulos, John},
booktitle = {The Practice of Enterprise Modeling},
doi = {10.1007/978-3-642-24849-8_7},
editor = {Johannesson, Paul and Krogstie, John and Opdahl, AndreasL.},
file = {:Users/vitor/Mendeley/Barone et al. - 2011 - Reasoning with Key Performance Indicators.pdf:pdf},
isbn = {978-3-642-24848-1},
keywords = {Business intelligence,Business model,Conceptual modeling languages,Key performance indicators,Strategic planning,bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {82--96},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Business Information Processing},
title = {{Reasoning with Key Performance Indicators}},
url = {http://link.springer.com/chapter/10.1007{\%}2F978-3-642-24849-8{\_}7},
volume = {92},
year = {2011}
}
@inproceedings{barthelemy-et-al:aaaiss05,
abstract = {An important task for Homeland Security is the prediction of threat vulnerabilities, such as through the detection of relationships between seemingly disjoint entities. A structure used for this task is a "semantic graph", also known as a "relational data graph" or an "attributed relational graph". These graphs encode relationships as "typed" links between a pair of "typed" nodes. Indeed, semantic graphs are very similar to semantic networks used in AI. The node and link types are related through an ontology graph (also known as a schema). Furthermore, each node has a set of attributes associated with it (e.g., "age" may be an attribute of a node of type "person"). Unfortunately, the selection of types and attributes for both nodes and links depends on human expertise and is somewhat subjective and even arbitrary. This subjectiveness introduces biases into any algorithm that operates on semantic graphs. Here, we raise some knowledge representation issues for semantic graphs and provide some possible solutions using recently developed ideas in the field of complex networks. In particular, we use the concept of transitivity to evaluate the relevance of individual links in the semantic graph for detecting relationships. We also propose new statistical measures for semantic graphs and illustrate these semantic measures on graphs constructed from movies and terrorism data.},
address = {Palo Alto, CA, USA},
author = {Barth{\'{e}}lemy, Marc and Chow, Edmond T. and Eliassi-Rad, Tina},
booktitle = {Proc. of the 2005 AAAI Spring Symposium},
file = {:Users/vitor/Mendeley/Barth{\'{e}}lemy, Chow, Eliassi-Rad - 2005 - Knowledge Representation Issues in Semantic Graphs for Relationship Detection.pdf:pdf},
keywords = {bibtex,summarized},
mendeley-tags = {bibtex,summarized},
month = {mar},
pages = {91--98},
publisher = {AAAI Press},
title = {{Knowledge Representation Issues in Semantic Graphs for Relationship Detection}},
url = {http://www.aaai.org/Library/Symposia/Spring/2005/ss05-01-014.php},
year = {2005}
}
@inproceedings{bencharrada-glinz:iwpseevol10,
abstract = {Updating the requirements specification during software evolution is a manual and expensive task. Therefore, software engineers usually choose to apply modifications directly to the code and leave the requirements unchanged. This leads to the loss of the knowledge contained in the requirements documents and thus limits the evolvability of a software system. In this paper, we propose to employ the co-evolution of the code and its test suite to preserve or restore the alignment between implementation and requirements: when a change has been applied to the code, subsequent changes in the test suite as well as failing tests are analyzed and used to automatically generate hints about the affected requirements and how they should be changed. These hints support the engineer in maintaining the requirements specification and thus ease the further evolution of the software system.},
address = {Antwerp, Belgium},
author = {{Ben Charrada}, Eya and Glinz, Martin},
booktitle = {Proc. of the Joint ERCIM Workshop on Software Evolution and International Workshop on Principles of Software Evolution},
doi = {10.1145/1862372.1862387},
file = {:Users/vitor/Mendeley/Ben Charrada, Glinz - 2010 - An Automated Hint Generation Approach for Supporting the Evolution of Requirements Specifications.pdf:pdf},
isbn = {9781450301282},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {sep},
pages = {58--62},
publisher = {ACM},
title = {{An Automated Hint Generation Approach for Supporting the Evolution of Requirements Specifications}},
url = {http://portal.acm.org/citation.cfm?doid=1862372.1862387},
year = {2010}
}
@incollection{benavides-et-al:aise05,
abstract = {Software Product Line (SPL) Engineering has proved to be an effective method for software production. However, in the SPL community it is well recognized that variability in SPLs is increasing by the thousands. Hence, an automatic support is needed to deal with variability in SPL. Most of the current proposals for automatic reasoning on SPL are not devised to cope with extra–functional features. In this paper we introduce a proposal to model and reason on an SPL using constraint programming. We take into account functional and extra–functional features, improve current proposals and present a running, yet feasible implementation.},
author = {Benavides, David and Trinidad, Pablo and Ruiz-Cort{\'{e}}s, Antonio},
booktitle = {Advanced Information Systems Engineering},
doi = {10.1007/11431855_34},
editor = {Pastor, Oscar and e Cunha, Jo{\~{a}}o},
file = {:Users/vitor/Mendeley/Benavides, Trinidad, Ruiz-Cort{\'{e}}s - 2005 - Automated Reasoning on Feature Models.pdf:pdf},
isbn = {978-3-540-26095-0},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {491--503},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Automated Reasoning on Feature Models}},
url = {http://link.springer.com/chapter/10.1007{\%}2F11431855{\_}34},
volume = {3520},
year = {2005}
}
@book{mrt11,
editor = {Bencomo, Nelly and Blair, Gordon and Cheng, Betty H. C. and France, Robert and Jeanneret, C{\'{e}}dric},
file = {:Users/vitor/Mendeley/Unknown - 2011 - Proceedings of the 6th International Workshop on Models@run.time at the ACMIEEE 14th International Conference on Model.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {CEUR},
title = {{Proceedings of the 6th International Workshop on Models@run.time at the ACM/IEEE 14th International Conference on Model Driven Engineering Languages and Systems}},
url = {http://ceur-ws.org/Vol-794/},
year = {2011}
}
@inproceedings{bencomo-et-al:soar09,
abstract = {This paper revisits the relationship between software architecture and requirements focusing on the case of selfadaptive systems. The authors present their view of the state-of-the-art, including their own work, on both areas and their contribution towards the development of selfadaptive systems. The authors support the claim that there is no fundamental distinction between architectural decisions and architecturally significant requirements and discuss how these claims are specifically appropriate for the case of selfadaptive systems. A discussion of the approach described and challenges for the case of adaptive systems are also presented.},
address = {Cambridge, UK},
author = {Bencomo, Nelly and Grace, Paul and Sawyer, Pete},
booktitle = {Proc. of the 2009 Workshop on Self-Organizing Architectures (SOAR '09)},
file = {:Users/vitor/Mendeley/Bencomo, Grace, Sawyer - 2009 - Revisiting the Relationship between Software Architecture and Requirements the case of Dynamically Adapt.pdf:pdf},
keywords = {architecture,bibtex,commented,dnamically adaptive systems,requirements},
mendeley-tags = {bibtex,commented},
month = {sep},
title = {{Revisiting the Relationship between Software Architecture and Requirements: the case of Dynamically Adaptive Systems}},
url = {http://comp.eprints.lancs.ac.uk/2330/},
year = {2009}
}
@book{rrt11,
doi = {10.1109/ReRunTime.2011.6046240},
editor = {Bencomo, Nelly and Letier, Emmanuel and Finkelstein, Anthony and Whittle, Jon and Welsh, Kriss},
file = {:Users/vitor/Mendeley/Unknown - 2011 - Proceedings of the 2nd International Workshop on Requirements@Run.Time.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {IEEE},
title = {{Proceedings of the 2nd International Workshop on Requirements@Run.Time}},
url = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6035842},
year = {2011}
}
@inproceedings{bencomo-et-al:icse10,
abstract = {Computational reflection is a well-established technique that gives a program the ability to dynamically observe and possibly modify its behaviour. To date, however, reflection is mainly applied either to the software architecture or its implementation. We know of no approach that fully supports requirements reflection- that is, making requirements available as runtime objects. Although there is a body of literature on requirements monitoring, such work typically generates runtime artefacts from requirements and so the requirements themselves are not directly accessible at runtime. In this paper, we define requirements reflection and a set of research challenges. Requirements reflection is important because software systems of the future will be self-managing and will need to adapt continuously to changing environmental conditions. We argue requirements reflection can support such self-adaptive systems by making requirements first-class runtime entities, thus endowing software systems with the ability to reason about, understand, explain and modify requirements at runtime.},
address = {Cape Town, South Africa},
author = {Bencomo, Nelly and Whittle, Jon and Sawyer, Pete and Finkelstein, Anthony and Letier, Emmanuel},
booktitle = {Proc. of the 32nd ACM/IEEE International Conference on Software Engineering (ICSE '10)},
doi = {10.1145/1810295.1810329},
file = {:Users/vitor/Mendeley/Bencomo et al. - 2010 - Requirements Reflection Requirements as Runtime Entities.pdf:pdf},
isbn = {9781605587196},
keywords = {bibtex,commented,reflection,requirements,runtime,self-adaptive systems},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {199--202},
publisher = {ACM},
title = {{Requirements Reflection: Requirements as Runtime Entities}},
url = {http://portal.acm.org/citation.cfm?doid=1810295.1810329},
volume = {2},
year = {2010}
}
@inproceedings{bennet-rajlich:fse00,
abstract = {Software maintenance and evolution are characterised by their huge cost and slow speed of implementation. Yet they are inevitable activities - almost all software that is useful and successful stimulates user-generated requests for change and improvements. Our aim is to describe a landscape for research in software maintenance and evolution over the next ten years, in order to improve the speed and accuracy of change while reducing costs, by identifying key problems, promising solution strategies and topics of importance. The aims are met, by taking two approaches. Firstly current trends and practices are projected forward using a new model of software evolution called the staged model. Both strategic problems and research to solve particular tactical problems are described within this framework. Secondly, a longer term, and much more radical vision of software evolution is presented. Both general principles and specific research topics are provided, both within an overall strategy of engineering research and rationale .},
address = {Limerick, Ireland},
author = {Bennett, Keith H. and Rajlich, V{\'{a}}clav T.},
booktitle = {Proc. of the 22nd International Conference on Software Engineering},
doi = {10.1145/336512.336534},
file = {:Users/vitor/Mendeley/Bennett, Rajlich - 2000 - Software Maintenance and Evolution a Roadmap.pdf:pdf},
isbn = {1581132530},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {73--87},
publisher = {ACM},
title = {{Software Maintenance and Evolution: a Roadmap}},
url = {http://portal.acm.org/citation.cfm?doid=336512.336534},
year = {2000}
}
@article{berler-et-al:itb05,
abstract = {The advantages of the introduction of information and communication technologies in the complex health-care sector are already well-known and well-stated in the past. It is, never- theless, paradoxical that although the medical community has embraced with satisfaction most of the technological discoveries allowing the improvement in patient care, this has not happened when talking about health-care informatics. Taking the above issue of concern, our work proposes an information model for knowledge management (KM) based upon the use of key perfor- mance indicators (KPIs) in health-care systems. Based upon the use of the balanced scorecard (BSC) framework (Kaplan/Norton) and quality assurance techniques in health care (Donabedian), this paper is proposing a patient journey centered approach that drives information ﬂow at all levels of the day-to-day process of delivering effective and managed care, toward information assess- ment and knowledge discovery. In order to persuade health-care decision-makers to assess the added value of KM tools, those should be used to propose new performance measurement and performance management techniques at all levels of a health-care system. The proposed KPIs are forming a complete set of metrics that enable the performance management of a regional health-care system. In addition, the performance framework established is technically applied by the use of state-of-the-art KM tools such as data warehouses and business intelligence information systems. In that sense, the proposed infrastructure is, technologically speaking, an important KM tool that enables knowledge sharing amongst various health-care stakeholders and between different health-care groups. The use of BSC is an enabling framework toward a KM strategy in health care.},
author = {Berler, Alexander and Pavlopoulos, Sotiris and Koutsouris, Dimitris},
doi = {10.1109/TITB.2005.847196},
file = {:Users/vitor/Mendeley/Berler, Pavlopoulos, Koutsouris - 2005 - Using Key Performance Indicators as Knowledge-Management Tools at a Regional Health-Care Author.pdf:pdf},
issn = {1089-7771},
journal = {IEEE Transactions on Information Technology in Biomedicine},
keywords = {BSC,KM,KPI,balanced socrecard,bibtex,business intelligence,health-care system performance management,key performance indicators,knowledge management,not-commented,regional health-care authority,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
month = {jun},
number = {2},
pages = {184--192},
publisher = {IEEE},
title = {{Using Key Performance Indicators as Knowledge-Management Tools at a Regional Health-Care Authority Level}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1435416},
volume = {9},
year = {2005}
}
@misc{bernerslee:website06,
author = {Berners-Lee, Tim},
file = {:Users/vitor/Mendeley/Berners-Lee - 2006 - Linked Data - Design Issues,httpwww.w3.orgDesignIssuesLinkedData.html (last access May 7th, 2015).pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{Linked Data - Design Issues,http://www.w3.org/DesignIssues/LinkedData.html (last access: May 7th, 2015)}},
url = {http://www.w3.org/DesignIssues/LinkedData.html},
year = {2006}
}
@article{bernerslee-et-al:sa11,
abstract = {A new form of Web content that is meaningful to computers will unleash a revolution of new possibilities.},
author = {Berners-Lee, Tim and Hendler, Jim and Lassila, Ora},
file = {:Users/vitor/Mendeley/Berners-Lee, Hendler, Lassila - 2001 - The Semantic Web.pdf:pdf},
journal = {Scientific American},
keywords = {bibtex},
mendeley-tags = {bibtex},
number = {5},
pages = {34--43},
title = {{The Semantic Web}},
url = {http://www.scientificamerican.com/article/the-semantic-web/},
volume = {284},
year = {2001}
}
@inproceedings{berry-et-al:refsq05,
abstract = {This paper argues that there are four levels of requirements engineer- ing for and in a dynamic adaptive system: (1) by humans, for the general behavior of the system, (2) by the system itself, whenever it is adapting based on changes to its environment, (3) by humans, to decide when, how, and where the system is to adapt, and (4) by humans, doing research about adaptive systems.},
address = {Porto, Portugal},
author = {Berry, Daniel M. and Cheng, Betty H. C. and Zhang, Ji},
booktitle = {Proc. of the 11th International Workshop on Requirements Engineering: Foundation for Software Quality},
file = {:Users/vitor/Mendeley/Berry, Cheng, Zhang - 2005 - The Four Levels of Requirements Engineering for and in Dynamic Adaptive Systems.pdf:pdf},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {jun},
pages = {95--100},
title = {{The Four Levels of Requirements Engineering for and in Dynamic Adaptive Systems}},
url = {http://www.sse.uni-essen.de/refsq/downloads/summary-refsq05.pdf},
year = {2005}
}
@article{davies:ejis95,
abstract = {In this paper we use the case of the London Ambulance Service Computer Aided Despatch (LASCAD) project as a cogent example of the nature of information systems failure. Our aims are twofold: to set the LASCAD case in the context of previous case studies of IS failure and to use a web approach to organize the case material and hence assess the importance of two important explanatory frameworks for considering IS failure.},
author = {Beynon-Davies, Paul},
doi = {10.1057/ejis.1995.20},
file = {:Users/vitor/Mendeley/Beynon-Davies - 1995 - Information systems 'failure' the case of the London Ambulance Service's Computer Aided Despatch project.pdf:pdf},
issn = {0960-085X},
journal = {European Journal of Information Systems},
keywords = {bibtex,x-commented},
mendeley-tags = {bibtex,x-commented},
month = {aug},
number = {3},
pages = {171--184},
publisher = {Palgrave Macmillan},
title = {{Information systems 'failure': the case of the London Ambulance Service's Computer Aided Despatch project}},
url = {http://www.palgrave-journals.com/doifinder/10.1057/ejis.1995.20},
volume = {4},
year = {1995}
}
@techreport{bisgaard-et-al:report04,
abstract = {In this paper, we seek to map the current body of research into the area of context-awareness and the dimensions of context used. In addition we seek to summarize the difficulties or challenges identified through the body of research. The key findings of the presented body of research are summarized and the dimensions of context used are presented in a condensed form},
author = {Bisgaard, Jesper J. and Heise, Morten and Steffensen, Carsten},
file = {:Users/vitor/Mendeley/Bisgaard, Heise, Steffensen - 2004 - How is Context and Context-awareness Defined and Applied A Survey of Context-awareness.pdf:pdf},
institution = {Aalborg University},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{How is Context and Context-awareness Defined and Applied? A Survey of Context-awareness}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.4517},
year = {2004}
}
@article{blumsack-fernandez:energy12,
abstract = {The “smart grid” represents one of the greatest potential advances in electricity delivery infrastructure in the past century. While the technologies that collectively comprise the smart grid have existed for decades, the potential for changing the way that electricity is generated, delivered, utilized and priced is revolutionary. Not surprisingly, many countries have undertaken initiatives to rollout smart grid infrastructure at an aggressive pace. Understanding the fundamental changes that the smart grid is likely to introduce is important for the development of future energy scenarios and the environmental, social and economic implications of these scenarios. Here we present an overview of the emerging smart grid and outline a few implications for the energy modeling community. Specifically, we discuss the potential for the smart grid to act as an enabling technology for renewable energy integration, price-responsive electricity demand, electrified transportation and distributed energy production as examples of how the smart grid may fundamentally change future energy system scenario development. The smart grid is being deployed and implemented much faster than we are able to fully consider its implications, and in some cases public policy has a long way to go before it catches up with the pace of smart grid technology deployment.},
author = {Blumsack, Seth and Fernandez, Alisha},
doi = {10.1016/j.energy.2011.07.054},
editor = {Giampietro, Mario and Martin, Jesus Ramos and Ulgiati, Sergio},
file = {:Users/vitor/Mendeley/Blumsack, Fernandez - 2012 - Ready or not, here comes the smart grid!.pdf:pdf},
issn = {03605442},
journal = {Energy},
keywords = {bibtex,distributed energy,energy modeling,energy policy,not-commented,smart grid},
mendeley-tags = {bibtex,not-commented},
month = {jan},
number = {1},
pages = {61--68},
publisher = {Elsevier},
title = {{Ready or not, here comes the smart grid!}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0360544211005287},
volume = {37},
year = {2012}
}
@inproceedings{borges-et-al:icse2011,
abstract = {We propose a novel framework for adapting and evolving software requirements models. The framework uses model checking and machine learning techniques for verifying properties and evolving model descriptions. The paper offers two novel contributions and a preliminary evaluation and application of the ideas presented. First, the framework is capable of coping with errors in the specification process so that performance degrades gracefully. Second, the framework can also be used to re-engineer a model from examples only, when an initial model is not available. We provide a preliminary evaluation of our framework by applying it to a Pump System case study, and integrate our prototype tool with the NuSMV model checker. We show how the tool integrates verification and evolution of abstract models, and also how it is capable of re-engineering partial models given examples from an existing system.},
address = {Honolulu, HI, USA},
author = {Borges, Rafael V. and Garcez, Artur A. and Lamb, Luis C. and Nuseibeh, Bashar},
booktitle = {Proc. of the 33rd International Conference on Software Engineering},
doi = {10.1145/1985793.1985924},
file = {:Users/vitor/Mendeley/Borges et al. - 2011 - Learning to Adapt Requirements Specifications of Evolving Systems (NIER Track).pdf:pdf},
isbn = {9781450304450},
keywords = {adaptation,bibtex,commented,machine learning in software engineering},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {856--859},
publisher = {ACM},
title = {{Learning to Adapt Requirements Specifications of Evolving Systems (NIER Track)}},
url = {http://portal.acm.org/citation.cfm?doid=1985793.1985924},
year = {2011}
}
@article{bottcher-et-al:bttj06,
abstract = {Since the world with its markets, innovations and customers is changing faster than ever before, the key to survival for businesses is the ability to detect, assess and respond to changing conditions — rapidly and intelligently. Discovering changes, and reacting to or acting upon them before others do, has therefore become a strategic issue for many companies. Many businesses collect huge volumes of data. Commonly this data is continuously gathered over long periods and thus reflects changes in the parts of the business from which it has been derived. To control their business operations and to gain a competitive edge, it is crucial for businesses to detect these changes — early and precisely. However, existing data analysis techniques are insufficient for this task. The widely used method for defining key performance indicators is too weak to detect changes early enough, and requires time-consuming in-depth analysis before decisions can be made. State-of- the-art knowledge discovery techniques, on the other hand, provide the required level of detail, but assume that the domain under consideration is stable over time. This paper presents a framework that detects changes within a data set at virtually any level of granularity. The underlying idea is to derive a rule-based description of the data set at different points in time and to subsequently analyse how these rules change. While rules are themselves a very comprehensible representation of knowledge, further techniques are required to assist the data analyst in interpreting and assessing changes. Therefore the framework also contains methods to discard rules that are non-drivers for change, and to assess the interestingness of the detected changes.},
author = {B{\"{o}}ttcher, Mirko and Nauck, Detlef and Borgelt, Christian and Kruse, Rudolf},
doi = {10.1007/s10550-006-0064-3},
file = {:Users/vitor/Mendeley/B{\"{o}}ttcher et al. - 2006 - A framework for discovering interesting business changes from data.pdf:pdf},
issn = {1358-3948},
journal = {BT Technology Journal},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {apr},
number = {2},
pages = {219--228},
publisher = {Springer},
title = {{A framework for discovering interesting business changes from data}},
url = {http://link.springer.com/10.1007/s10550-006-0064-3},
volume = {24},
year = {2006}
}
@inproceedings{brake-et-al:seams08,
abstract = {Software Tuning Panels for Autonomic Control (STAC) is a project to assist in the integration of existing software into autonomic frameworks. It works by identifying tuning parameters and rearchitecting to expose them as a separate control panel module. The project poses three distinct research challenges: automating the identification of tuning parameters, rearchitecting to centralize and expose them, and combining these two capabilities to facilitate the integration of existing software into autonomic frameworks. Our previous work focused on the second problem, automating the rearchitecture to expose and isolate tuning parameters. In this paper we concentrate on the first problem, automating the identification of tuning parameters. We begin with an empirical study of documented tuning parameters in a number of open source applications. From our observations of these known tuning parameters, we create a catalogue of different kinds and organize them into a taxonomy. Finally, we characterize a member of the taxonomy as a source code pattern that is used to find similar tuning parameters. We report our experience in applying this methodology in the context of a large, open source Java system.},
address = {Leipzig, Germany},
author = {Brake, Nevon and Cordy, James R. and Dancy, Elizabeth and Litoiu, Marin and Popescu, Valentina},
booktitle = {Proc. of the 2008 International Workshop on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1145/1370018.1370031},
file = {:Users/vitor/Mendeley/Brake et al. - 2008 - Automating Discovery of Software Tuning Parameters.pdf:pdf},
isbn = {9781605580371},
keywords = {autonomic computing,bibtex,commented,design recovery,rearchitecture,static analysis,tuning parameter},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {65--72},
publisher = {ACM},
title = {{Automating Discovery of Software Tuning Parameters}},
url = {http://portal.acm.org/citation.cfm?doid=1370018.1370031},
year = {2008}
}
@inproceedings{bredeweg-et-al:ectel10,
abstract = {Scaffolding is a well-known approach to bridge the gap between novice and expert capabilities in a discovery-oriented learning environment. This paper discusses a set of knowledge representations referred to as Learning Spaces (LSs) that can be used to support learners in acquiring conceptual knowledge of system behaviour. The LSs are logically self-contained, meaning that models created at a specific LS can be simulated. Working with the LSs provides scaffolding for learners in two ways. First, each LS provides a restricted set of representational primitives to express knowledge, which focus the learner's knowledge construction process. Second, the logical consequences of an expression derived upon simulating, provide learners a reflective instrument for evaluating the status of their understanding, to which they can react accordingly. The work presented here is part of the DynaLearn project, which builds an Interactive Learning Environment to study a constructive approach to having learners develop a qualitative understanding of how systems behave. The work presented here thus focuses on tools to support educational research. Consequently, user-oriented evaluation of these tools is not a part of this paper.},
address = {Barcelona, Spain},
author = {Bredeweg, Bert and Liem, Jochem and Beek, Wouter and Salles, Paulo and Linnebank, Floris},
booktitle = {Proc. of the 5th European Conference on Technology Enhanced Learning},
doi = {10.1007/978-3-642-16020-2_4},
file = {:Users/vitor/Mendeley/Bredeweg et al. - 2010 - Learning Spaces as Representational Scaffolds for Learning Conceptual Knowledge of System Behaviour.pdf:pdf},
keywords = {architecture,bibtex,commented,conceptual knowledge,knowledge representation,qualitative reasoning,scaffolding},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {46--61},
publisher = {Springer},
title = {{Learning Spaces as Representational Scaffolds for Learning Conceptual Knowledge of System Behaviour}},
url = {http://link.springer.com/10.1007/978-3-642-16020-2{\_}4},
year = {2010}
}
@article{bredeweg-et-al:ei09,
abstract = {Easy to use workbenches for Qualitative Reasoning and modelling have been virtually nonexistent. This has a limiting effect on the use of this Artificial Intelligence technology and its uptake by a larger audience. We present Garp3, a user-friendly workbench that allows modellers to build, simulate, and inspect qualitative models of system behaviour. The workbench employs diagrammatic representations for users to interact with model content and simulation results, and provides seamless interoperability between the different modes of use. Domain experts can use Garp3 to create conceptual models in situations where numerical information is sparse or unavailable, or when they want to formalise their conceptual understanding of how systems behave. Garp3 can be applied to stakeholder management or dissemination activities to illustrate and explain phenomena, and facilitate discussion among participants. The workbench can also be used in formal education to have learners express concepts, or interact with existing models, and support them in developing their understanding of ‘how things work'. Garp3 incorporates a range of techniques from Artificial Intelligence known as knowledge-based techniques. The main goal of this paper is to present the representation and reasoning methods of these techniques as they have been developed and fine-tuned within the Garp3 workbench. The focus hereby is on the symbolic, non-numerical calculations that are required to generate the state-graph of a system's behaviour efficiently, while taking into account that users need to be able to track and understand this reasoning, both in terms of the end result and the intermediate results it delivers.},
author = {Bredeweg, Bert and Linnebank, Floris and Bouwer, Anders and Liem, Jochem},
doi = {10.1016/j.ecoinf.2009.09.009},
editor = {Recknagel, Friedrich},
file = {:Users/vitor/Mendeley/Bredeweg et al. - 2009 - Garp3 — Workbench for qualitative modelling and simulation.pdf:pdf},
issn = {15749541},
journal = {Ecological Informatics},
keywords = {bibtex,commented,conceptual knowledge and models,knowledge capture,qualitative knowledge and reasoning,qualitative modeling and simulation,software and workbench},
mendeley-tags = {bibtex,commented},
month = {nov},
number = {5-6},
pages = {263--281},
publisher = {Elsevier},
title = {{Garp3 — Workbench for qualitative modelling and simulation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1574954109000818},
volume = {4},
year = {2009}
}
@article{bredeweg-et-al:ei08,
abstract = {Successful transfer and uptake of qualitative reasoning technology for modelling and simulation in a variety of domains has been hampered by the lack of a structured methodology to support formalisation of ideas. We present a framework that structures and supports the capture of conceptual knowledge about system behaviour using a qualitative reasoning approach. This framework defines a protocol for representing content that supports the development of a conceptual understanding of systems and how they behave. The framework supports modellers in two ways. First, it structures and explicates the work involved in building models. Second, it facilitates easier comparison and evaluation of intermediate and final results of modelling efforts. We show how this framework has been used in developing qualitative reasoning models about three case studies of sustainable development in different river systems.},
author = {Bredeweg, Bert and Salles, Paulo and Bouwer, Anders and Liem, Jochem and Nuttle, Tim and Cioaca, Eugenia and Nakova, Elena and Noble, Richard and Caldas, Ana Luiza Rios and Uzunov, Yordan and Varadinova, Emilia and Zitek, Andreas},
doi = {10.1016/j.ecoinf.2007.02.002},
editor = {Recknagel, Friedrich},
file = {:Users/vitor/Mendeley/Bredeweg et al. - 2008 - Towards a structured approach to building qualitative reasoning models and simulations.pdf:pdf},
issn = {15749541},
journal = {Ecological Informatics},
keywords = {artificial intelligence,bibtex,commented,framework for qr modeling,naturnet-redime project,qualitative reasoning and modeling,qualitative simulation},
mendeley-tags = {bibtex,commented},
month = {jan},
number = {1},
pages = {1--12},
publisher = {Elsevier},
title = {{Towards a structured approach to building qualitative reasoning models and simulations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1574954107000052},
volume = {3},
year = {2008}
}
@article{breitman-et-al:jbcs99,
abstract = {In this article we present a survey on the area of Requirements Engineering anchored on the analysis of a real life case study, the London Ambulance Service [56]. We aim at bringing to context new methods, techniques and tools that should be of help to both reaserchers and practitioners. The case study in question is of special interest in that it is available to the public and deals with a very large system, of which the software system is only a part of. The survey is divided into four topics of interest: viewpoints, social aspects, evolution and non-functional requirements. This division resulted from the work method adopted by the authors. Our main goal is to bridge recent findings in Requirements Engineering research to a real world problem. In this light, we believe this article to be an important educational device.},
author = {Breitman, Karin K. and Leite, Julio C. S. P. and Finkelstein, Anthony},
doi = {10.1590/S0104-65001999000200003},
file = {:Users/vitor/Mendeley/Breitman, Leite, Finkelstein - 1999 - The world's a stage a survey on requirements engineering using a real-life case study.pdf:pdf},
issn = {0104-6500},
journal = {Journal of the Brazilian Computer Society},
keywords = {bibtex,conflict resolution,evolution,non-functional requirements,requirements engineering,traceability,viewpoints,x-commented},
mendeley-tags = {bibtex,x-commented},
month = {jul},
number = {1},
publisher = {Brazilian Computer Society},
title = {{The world's a stage: a survey on requirements engineering using a real-life case study}},
url = {http://www.scielo.br/scielo.php?script=sci{\_}arttext{\&}pid=S0104-65001999000200003{\&}lng=en{\&}nrm=iso{\&}tlng=en},
volume = {6},
year = {1999}
}
@article{bresciani-et-al:aamas04,
abstract = {Our goal in this paper is to introduce and motivate a methodology, called Tropos , 1 for building agent oriented software systems. Tropos is based on two key ideas. First, the notion of agent and all related mentalistic notions (for instance goals and plans) are used in all phases of software development, from early analysis down to the actual implementation. Second, Tropos covers also the very early phases of requirements analysis, thus allowing for a deeper understanding of the environment where the software must operate, and of the kind of interactions that should occur between software and human agents. The methodology is illustrated with the help of a case study. The Tropos language for conceptual modeling is formalized in a metamodel described with a set of UML class diagrams.},
annote = {10.1023/B:AGNT.0000018806.20944.ef},
author = {Bresciani, Paolo and Perini, Anna and Giorgini, Paolo and Giunchiglia, Fausto and Mylopoulos, John},
doi = {10.1023/B:AGNT.0000018806.20944.ef},
file = {:Users/vitor/Mendeley/Bresciani et al. - 2004 - Tropos An Agent-Oriented Software Development Methodology(2).pdf:pdf},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {agent-oriented methodologies,agent-oriented software engineering,bibtex,multi-agent systems,x-commented},
mendeley-tags = {bibtex,x-commented},
number = {3},
pages = {203--236},
publisher = {Springer},
title = {{Tropos: An Agent-Oriented Software Development Methodology}},
url = {http://www.springerlink.com/content/g757056736223u65/},
volume = {8},
year = {2004}
}
@article{berslin-et-al:ci2010,
abstract = {The Semantic Web has attracted significant attention during the last decade. On the one hand, many research groups have changed their focus towards Semantic Web research and research funding agencies particularly in Europe have explicitly mentioned Semantic Web in their calls for proposals. On the other hand, industry has also begun to watch developments with interest and a number of large companies have started to experiment with Semantic Web technologies to ascertain if these new technologies can be leveraged to add more value for their customers or internally within the company, while there are already several offers of vendors of Semantic Web solutions on the market. The essence of the Semantic Web is to structure Web-based information to make it more interoperable, machine-readable and thereafter to provide a means to relate various information concepts more easily and in a reusable way. The Semantic Web acts as an additional layer on the top of the Web, and is built around explicit representations of information concepts and their relationships such as ontologies and taxonomies. Furthermore, Semantic Web technologies are not only valuable on an open environment like the Web, but also in closed systems such as in industrial settings. Hence, these technologies can be efficiently deployed for domains including Web Services, Enterprise Application Integration, Knowledge Management and E-Commerce, fulfilling existing gaps in current applications. This paper focuses on this synthesis between Semantic Web technologies and systems problems within industrial applications. There will be a short review of Semantic Web standards, languages and technologies followed by a more detailed review of applications of Semantic Web computing in industry. The paper covers theoretical considerations as well as use cases and experience reports on the topic, and we also present some current challenges and opportunities in the domain.},
author = {Breslin, John G. and O'Sullivan, David and Passant, Alexandre and Vasiliu, Laurentiu},
doi = {10.1016/j.compind.2010.05.002},
file = {:Users/vitor/Mendeley/Breslin et al. - 2010 - Semantic Web computing in industry.pdf:pdf},
issn = {01663615},
journal = {Computers in Industry},
keywords = {bibtex,commented,e-commerce,enterprise application integration,knowledge management,semantic web,semantic web services},
mendeley-tags = {bibtex,commented},
month = {oct},
number = {8},
pages = {729--741},
publisher = {Elsevier},
title = {{Semantic Web computing in industry}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0166361510000515},
volume = {61},
year = {2010}
}
@inproceedings{brill-knauss:re11,
abstract = {Today, people find themselves surrounded by IT systems in their everyday life. Often they are not even aware that they are interacting with an IT system. More and more of these systems are context adaptive. Requirements to such systems may change for various reasons: The context may fundamentally change when other systems are introduced. New trends and fashions may evolve. Operators need to react quickly to such changes if they want to keep their systems competitive. Traditional approaches to requirements elicitation start to fail in this situation: context adaptive systems serve many users with different profiles. In addition, users may be reluctant to participate in improving it. Thus, it is hard to establish a representative model of requirements. Furthermore, it is hard to capture the context of requirements by subsequent interviews. In this paper we present a systematical approach for requirements elicitation based on observing anonymous users. The interaction of users with the system is observed in the normal working context. Observation is based on assumptions on how interaction should take place. Deviations from these assumptions point to new requirements. Observing a large number of users leads to a quantitative map of requirements in context. Preliminary evaluation shows that the approach is promising. It allows efficient observation of many stakeholders and the derivation of new requirements.},
address = {Trento, Italy},
author = {Brill, Olesia and Knauss, Eric},
booktitle = {Proc. of the 19th IEEE International Requirements Engineering Conference (RE '11)},
doi = {10.1109/RE.2011.6051660},
file = {:Users/vitor/Mendeley/Brill, Knauss - 2011 - Structured and unobtrusive observation of anonymous users and their context for requirements elicitation.pdf:pdf},
isbn = {978-1-4577-0921-0},
keywords = {bibtex,commented,context adaptive systems,requirements elicitation,requirements evolution,user observation},
mendeley-tags = {bibtex,commented},
month = {aug},
pages = {175--184},
publisher = {IEEE},
title = {{Structured and unobtrusive observation of anonymous users and their context for requirements elicitation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6051660},
year = {2011}
}
@article{bringuente-et-al:jidm11,
abstract = {During project planning, knowledge about software processes is useful in several situations: software processes are defined, activities are scheduled, and people are allocated to these activities. In this context, standard software processes are used as basis for defining project processes, and tools are used to support scheduling, people allocation, and so on. Ideally, people and tools should share a common conceptualization regarding this domain for allowing interoperability, and correct use of the tools. A domain ontology can be used to define an explicit representation of this shared conceptualization. Moreover, for a domain ontology to adequately serve as a reference model, it should be built explicitly taking foundational concepts into account. This paper discusses the reengineering of part of a Software Process Ontology based on the Unified Foundational Ontology (UFO). The part reengineered concerns standard processes, project processes, and activities, which are analyzed at the light of UFO concepts.},
author = {Bringuente, Ana C. O. and Falbo, Ricardo A. and Guizzardi, Giancarlo},
editor = {Oliveira, Jos{\'{e}} P. M.},
file = {:Users/vitor/Mendeley/Bringuente, Falbo, Guizzardi - 2011 - Using a Foundational Ontology for Reengineering a Software Process Ontology(2).pdf:pdf;:Users/vitor/Mendeley/Bringuente, Falbo, Guizzardi - 2011 - Using a Foundational Ontology for Reengineering a Software Process Ontology.pdf:pdf},
journal = {Journal of Information and Data Management},
keywords = {bibtex,commented,domain ontology,foundational ontology,ontology reengineering,software process,unified foundational ontology},
mendeley-tags = {bibtex,commented},
number = {3},
pages = {511--526},
publisher = {Brazilian Computer Society},
title = {{Using a Foundational Ontology for Reengineering a Software Process Ontology}},
url = {https://seer.lcc.ufmg.br/index.php/jidm/issue/view/6/showToc},
volume = {2},
year = {2011}
}
@inproceedings{brown-et-al:seams06,
abstract = {Adaptive software is being used increasingly frequently by various users, such as the medical community, software industry, and in response to terror attacks. Therefore, understanding the requirements of an adaptive system is crucial to developing them correctly. Developers need to be able to reason about the requirements of a system's adaptive behavior. Adaptation semantics are intended to describe how systems behave during adaptation. Previously, Zhang and Cheng formally specified three commonly occurring adaptation semantics in terms of Adapt operator-extended LTL (A-LTL). This paper presents goal-oriented specifications of these three adaptation semantics. These specifications, specified with the KAOS methodology, provide a graphical wrapper to the formal A-LTL specifications of the semantics. The combination of the goal-oriented, graphical KAOS specifications and A-LTL specifications provides the benefits of formal specifications as well as the benefits of an easier to understand, graphical, and more intuitive presentation of adaptive systems requirements. This work also provides a means to incorporate the adaptation semantics into the goal-oriented requirements specifications of an adaptive system.},
address = {Shanghai, China},
author = {Brown, Greg and Cheng, Betty H. C. and Goldsby, Heather J. and Zhang, Ji},
booktitle = {Proc. of the 2006 International Workshop on Self-adaptation and Self-managing Systems},
doi = {10.1145/1137677.1137682},
file = {:Users/vitor/Mendeley/Brown et al. - 2006 - Goal-oriented Specification of Adaptation Requirements Engineering in Adaptive Systems.pdf:pdf},
isbn = {1595934030},
keywords = {autonomic computing,bibtex,commented,dynamic adaptation,formal specification,goal-driven requirements engineering,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {may},
pages = {23--29},
publisher = {ACM},
title = {{Goal-oriented Specification of Adaptation Requirements Engineering in Adaptive Systems}},
url = {http://portal.acm.org/citation.cfm?doid=1137677.1137682},
year = {2006}
}
@book{saso11,
address = {Ann Arbor, MI, USA},
doi = {10.1109/SASO.2011.46},
editor = {Brueckner, Sven and Geihs, Kurt},
isbn = {978-1-4577-1614-0},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {oct},
publisher = {IEEE},
title = {{Proceedings of the 5th IEEE International Conference on Self-Adaptive and Self-Organizing Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6063480},
year = {2011}
}
@incollection{brun-et-al:sesas09,
abstract = {To deal with the increasing complexity of software systems and uncertainty of their environments, software engineers have turned to self-adaptivity. Self-adaptive systems are capable of dealing with a continuously changing environment and emerging requirements that may be unknown at design-time. However, building such systems cost-effectively and in a predictable manner is a major engineering challenge. In this paper, we explore the state-of-the-art in engineering self-adaptive systems and identify potential improvements in the design process. Our most important finding is that in designing self-adaptive systems, the feedback loops that control self-adaptation must become first-class entities. We explore feedback loops from the perspective of control engineering and within existing self-adaptive systems in nature and biology. Finally, we identify the critical challenges our community must address to enable systematic and well-organized engineering of self-adaptive and self-managing software systems.},
annote = {10.1007/978-3-642-02161-9{\_}3},
author = {Brun, Yuriy and {Di Marzo Serugendo}, Giovanna and Gacek, Cristina and Giese, Holger and Kienle, Holger and Litoiu, Marin and M{\"{u}}ller, Hausi A. and Pezz{\`{e}}, Mauro and Shaw, Mary},
booktitle = {Software Engineering for Self-Adaptive Systems},
doi = {10.1007/978-3-642-02161-9_3},
editor = {Cheng, Betty H. C. and de Lemos, Rog{\'{e}}rio and Giese, Holger and Inverardi, Paola and Magee, Jeff},
file = {:Users/vitor/Mendeley/Brun et al. - 2009 - Engineering Self-Adaptive Systems through Feedback Loops.pdf:pdf},
isbn = {978-3-642-02160-2},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
pages = {48--70},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Engineering Self-Adaptive Systems through Feedback Loops}},
url = {http://www.springerlink.com/content/32nm834361u37368/},
volume = {5525},
year = {2009}
}
@phdthesis{bryl:thesis09,
abstract = {A challenging aspect of modern information systems is the growing involvement of hu- mans and organizations in system structure and operation. Organizational environment in which software operates, the software system itself, the related hardware components and human users are often interdependent in a non trivial way, so that it is problematic to define a system boundary. We argue that an interdisciplinary notion of a Socio-Technical System (STS) is the one that captures the above mentioned aspects. Unlike traditional computer-based system, socio-technical systems include in their architecture and oper- ation not only software and hardware components, but also organizational and human actors. Such systems are regulated and constrained by internal organizational rules, ex- ternal laws and regulations. Among the challenging problems related to the analysis and design of a STS is the problem of understanding the requirements of its software component and the way in which the structure of human and organizational activities is in uenced by introducing technology. In particular, an important element in the design of a socio-technical system is the identification of a set of dependencies among actors which, if respected by all parties, will fulfill all stakeholder goals, namely, the requirements of the STS. In this thesis, we present a framework which aims at supporting the design of socio- technical systems, specifically the design of a network of inter-actor dependencies intended to fulfill a set of initial goals. The support comes in the form of a structured process and a tool that is founded on an off-the-shelf AI (Artificial Intelligence) planner which generates and evaluates alternative assignments of actor dependencies to identify an optimal or good enough design. We explore a range of measures for evaluating optimality, inspired by AI planning, multi-agent systems, social networks and Economics. We report on the application of the framework to the domains of secure systems design, safety critical systems, dynamic reconfiguration of an STS, as well as to the problem of instantiation of STS designs. We are also experimenting with our prototype tool to evaluate its scalability to realistic design problems.},
author = {Bryl, Volha},
file = {:Users/vitor/Mendeley/Bryl - 2009 - Supporting the Design of Socio-Technical Systems by Exploring and Evaluating Design Alternatives.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
school = {University of Trento},
title = {{Supporting the Design of Socio-Technical Systems by Exploring and Evaluating Design Alternatives}},
type = {PhD Thesis},
url = {https://dkm.fbk.eu/index.php/Volha{\_}Bryl's{\_}Publications{\#}Thesis},
year = {2009}
}
@article{budanitsky-hirst:cl06,
abstract = {The quantification of lexical semantic relatedness has many applications in NLP, and many different measures have been proposed. We evaluate five of these measures, all of which use WordNet as their central resource, by comparing their performance in detecting and correcting real-word spelling errors. An information-content-based measure proposed by Jiang and Conrath is found superior to those proposed by Hirst and St-Onge, Leacock and Chodorow, Lin, and Resnik. In addition, we explain why distributional similarity is not an adequate proxy for lexical semantic relatedness.},
author = {Budanitsky, Alexander and Hirst, Graeme},
doi = {10.1162/coli.2006.32.1.13},
editor = {Merlo, Paola},
file = {:Users/vitor/Mendeley/Budanitsky, Hirst - 2006 - Evaluating WordNet-based Measures of Lexical Semantic Relatedness.pdf:pdf},
issn = {0891-2017},
journal = {Computational Linguistics},
keywords = {bibtex,summarized},
mendeley-tags = {bibtex,summarized},
month = {mar},
number = {1},
pages = {13--47},
publisher = {MIT Press},
title = {{Evaluating WordNet-based Measures of Lexical Semantic Relatedness}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/coli.2006.32.1.13},
volume = {32},
year = {2006}
}
@techreport{trae:report04,
author = {Butler, Basil R. R. and Blair, Peter K. and Fox, Allan J. and Hall, Ian A. M. and Henry, Keith N. and McDermid, John A. and Parnaby, John and Sillem, Hayaatun and Rodd, Mike},
file = {:Users/vitor/Mendeley/Butler et al. - 2004 - The Challenges of Complex IT Projects.pdf:pdf},
institution = {The Royal Academy of Engineering (available at: http://www.raeng.org.uk/ComplexIT)},
isbn = {1-903496-15-2},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
title = {{The Challenges of Complex IT Projects}},
url = {http://www.raeng.org.uk/ComplexIT},
year = {2004}
}
@article{cabot-et-al:is10,
abstract = {UML is currently the most widely used modeling language for the specification of the conceptual schema (CS) of an information system (IS). However, UML falls short when it comes to allow business people to define in their own language (e.g. using their own terms in natural language) the policies and rules by which they run their business. To this purpose, the semantics of business vocabulary and business rules (SBVR) metamodel specification was proposed. SBVR is conceptualized optimally for business people and it is designed to be used for business purposes, independently of information systems designs. Clearly, SBVR and unified modeling language (UML) cannot be considered as isolated languages. Many of the business rules specified by business people must be automatically executed by the underlying information system, and thus, they must also appear in its UML CS. In this sense, the main goal of this paper is to bridge the gap between UML and SBVR by providing an automatic transformation from UML to SBVR specifications. Thanks to our transformation, designers will be able to interact with the business people (in their own language) to refine and validate the information modeled in the CS before the generation of the final IS implementation. Our transformation also takes into account all possible textual object constraint language (OCL) expressions that complement the UML graphical elements.},
author = {Cabot, Jordi and Pau, Raquel and Ravent{\'{o}}s, Ruth},
doi = {10.1016/j.is.2008.12.002},
file = {:Users/vitor/Mendeley/Cabot, Pau, Ravent{\'{o}}s - 2010 - From UMLOCL to SBVR Specifications a Challenging Transformation.pdf:pdf},
issn = {03064379},
journal = {Information Systems},
keywords = {bibtex,model transformation,not-commented,ocl,sbvr,uml},
mendeley-tags = {bibtex,not-commented},
month = {jun},
number = {4},
pages = {417--440},
publisher = {Elsevier},
title = {{From UML/OCL to SBVR Specifications: a Challenging Transformation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S030643790800094X},
volume = {35},
year = {2010}
}
@inproceedings{carzaniga-et-al:icse09,
abstract = {Modern societies are pervaded by computerized, heterogeneous devices designed for specific purposes, but also more and more often capable of interacting with other devices for entirely different purposes. For example, a cell phone could be used to purchase a train ticket on-line that could later be printed by a vending machine at the train station. This type of open environment is what we call a society of digital systems. In this paper, we outline the characteristics of societies of digital systems, and argue that they call for a new approach to cope with unforeseen interactions, possible incompatibilities, failures, and emergent behaviors. We argue that designers can not assume a closed or homogeneous world, and must instead naturally accommodate dynamic adaptations. Furthermore, self-adaptability, that is, the ability to adapt autonomically to a changing environment, also poses problems, as different adaptation strategies may interfere negatively, leading to unstable behaviors. As an initial concrete contribution to solve this problem, we propose a method to support the graceful integration of devices and software systems in an open environment. The method uses management information, and is specifically centered on the idea of expressing self-adaptation operations as change sets over the management information base.},
address = {Vancouver, Canada},
author = {Carzaniga, Antonio and Denaro, Giovanni and Pezz{\`{e}}, Mauro and Estublier, Jacky and Wolf, Alexander L.},
booktitle = {Proc. of the 31st International Conference on Software Engineering - Companion Volume},
doi = {10.1109/ICSE-COMPANION.2009.5071014},
file = {:Users/vitor/Mendeley/Carzaniga et al. - 2009 - Toward Deeply Adaptive Societies of Digital Systems.pdf:pdf},
isbn = {978-1-4244-3495-4},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {331--334},
publisher = {IEEE},
title = {{Toward Deeply Adaptive Societies of Digital Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5071014},
year = {2009}
}
@article{castro-et-al:is02,
abstract = {Information systems of the future will have to perform well within ever-changing organizational environments. Unfortunately, existing software development methodologies (object-oriented, structured or otherwise) have traditionally been inspired by programming concepts, not organizational ones, leading to a semantic gap between the software system and its operational environment. To reduce this gap, we propose a software development methodology named Tropos which is founded on concepts used to model early requirements. Our proposal adopts the in organizational modeling framework, which offers the notions of actor, goal and (actor) dependency, and uses these as a foundation to model early and late requirements, architectural and detailed design. The paper outlines Tropos phases through an e-business example, and sketches a formal language which underlies the methodology and is intended to support formal analysis. The methodology seems to complement well proposals for agent-oriented programming platforms.},
author = {Castro, Jaelson F. B. and Kolp, Manuel and Mylopoulos, John},
doi = {10.1016/S0306-4379(02)00012-1},
file = {:Users/vitor/Mendeley/Castro, Kolp, Mylopoulos - 2002 - Towards requirements-driven information systems engineering the Tropos project.pdf:pdf},
issn = {03064379},
journal = {Information Systems},
keywords = {bibtex,x-commented},
mendeley-tags = {bibtex,x-commented},
number = {6},
pages = {365--389},
publisher = {Elsevier},
title = {{Towards requirements-driven information systems engineering: the Tropos project}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0306437902000121},
volume = {27},
year = {2002}
}
@techreport{celino-pg14,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Celino, Danillo R.},
file = {:Users/vitor/Mendeley/Celino - 2014 - EODE Desenvolvimento do N{\'{u}}cleo de ODE em uma Plataforma Distribu{\'{i}}da e Extens{\'{i}}vel.pdf:pdf},
institution = {Projeto de Gradua{\c{c}}{\~{a}}o, Departamento de Inform{\'{a}}tica, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{EODE: Desenvolvimento do N{\'{u}}cleo de ODE em uma Plataforma Distribu{\'{i}}da e Extens{\'{i}}vel}},
year = {2014}
}
@article{cetina-et-al:computer09,
abstract = {Our research shows that autonomic behavior can be achieved by leveraging variability models at runtime. In this way, the modeling effort made at design time is not only useful for producing the system but also provides a richer semantic base for autonomic behavior during execution. The use of variability models at runtime brings new opportunities for autonomic capabilities by reutilizing the efforts invested at design time. Our proposed approach has two aspects: reuse of design knowledge to achieve AC and reuse of existing model-management technologies at runtime. We developed the Model-Based Reconfiguration Engine (MoRE) to implement model-management operations. Our research demonstrates the approach's feasibility for smart homes, especially for self-healing and -configuring capabilities.},
author = {Cetina, Carlos and Giner, Pau and Fons, Joan and Pelechano, Vicente},
doi = {10.1109/MC.2009.309},
file = {:Users/vitor/Mendeley/Cetina et al. - 2009 - Autonomic Computing through Reuse of Variability Models at Runtime The Case of Smart Homes.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {oct},
number = {10},
pages = {37--43},
publisher = {IEEE},
title = {{Autonomic Computing through Reuse of Variability Models at Runtime: The Case of Smart Homes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5280650},
volume = {42},
year = {2009}
}
@techreport{chelf-chou:report08,
author = {Chelf, Ben and Chou, Andy},
file = {:Users/vitor/Mendeley/Chelf, Chou - 2008 - Controlling Software Complexity The Business Case for Static Source Code Analysis.pdf:pdf},
institution = {Coverity, Inc. (available at: http://www.coverity.com/library/pdf/ControllingSoftwareComplexity.pdf)},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
title = {{Controlling Software Complexity: The Business Case for Static Source Code Analysis}},
url = {http://www.coverity.com/library/pdf/ControllingSoftwareComplexity.pdf},
year = {2008}
}
@inproceedings{chen-lin:soli06,
abstract = {Beyond limited scope of sole financial performance evaluation, balanced scorecard (BSC) provides a comprehensive evaluation model which covers aspects of customers, learning and growth of employee, and internal business process, in addition to finance dimension. To achieve successful implementation of BSC system, selecting key performance indicators (KPIs) precisely is a critical cornerstone. Most applications select KPIs in a subjective manner, which may raise hesitation during implementation. This paper thus employees a structured approach complementing analytic hierarchy process (AHP) with Habitual Domains Theory in identifying KPIs, and weighting of each indicator objectively. Utilizing service industry as an example, the proposed model demonstrates a systematic way to achieve precise evaluation integrating both subjective and objective elements.},
address = {Shanghai, China},
author = {Chen, Tai-Liang and Lin, Kuo-Liang},
booktitle = {Proc. of the 2006 IEEE International Conference on Service Operations and Logistics, and Informatics},
doi = {10.1109/SOLI.2006.328987},
file = {:Users/vitor/Mendeley/Chen, Lin - 2006 - Complementing AHP with Habitual Domains Theory to Identify Key Performance Indicators for Service Industry.pdf:pdf},
isbn = {1-4244-0318-9},
keywords = {analytical hierarchy process,balanced scorecard,bibtex,habitual domains,not-commented,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
month = {jun},
pages = {84--89},
publisher = {IEEE},
title = {{Complementing AHP with Habitual Domains Theory to Identify Key Performance Indicators for Service Industry}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4125556},
year = {2006}
}
@incollection{cheng-atlee:fose07,
abstract = {In this paper, we review current requirements engineering (RE) research and identify future research directions suggested by emerging software needs. First, we overview the state of the art in RE research. The research is considered with respect to technologies developed to address specific requirements tasks, such as elicitation, modeling, and analysis. Such a review enables us to identify mature areas of research, as well as areas that warrant further investigation. Next, we review several strategies for performing and extending RE research results, to help delineate the scope of future research directions. Finally, we highlight what we consider to be the “hot” current and future research topics, which aim to address RE needs for emerging systems of the future.},
author = {Cheng, Betty H. C. and Atlee, Joanne M.},
booktitle = {Future of Software Engineering (FOSE '07)},
doi = {10.1109/FOSE.2007.17},
file = {:Users/vitor/Mendeley/Cheng, Atlee - 2007 - Research Directions in Requirements Engineering.pdf:pdf},
isbn = {0-7695-2829-5},
keywords = {bibtex,x-commented},
mendeley-tags = {bibtex,x-commented},
month = {may},
pages = {285--303},
publisher = {IEEE},
title = {{Research Directions in Requirements Engineering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4221627},
year = {2007}
}
@book{seams09,
abstract = {With the rapid growth of web services and the continuous evolution from software-intensive systems to socio-technical ecosystems, the management of modern computing systems with many uncertainties in their environments presents significant challenges and risks for businesses. End-users increasingly demand software systems that are resilient, dependable, fault-tolerant, energy-efficient, or self-healing. One of the most promising approaches to engineering these properties is to equip software systems with feedback control to address the management of inherent system dynamics. The resulting self-adapting and self-managing computing systems are better able to cope with and even accommodate changing contexts and environments, shifting requirements, and computing-on-demand needs. The SEAMS workshop series consolidates the interests in the software engineering community on self-adaptive and self-managing systems. SEAMS provides a forum for researchers to share new results, raise awareness, and promote collaboration. SEAMS 2009 builds on the success of the SEAMS ICSE workshops of 2008 in Leipzig, Germany, 2007 in Minneapolis, USA, and 2006 in Shanghai, China.},
address = {Vancouver, BC, Canada},
booktitle = {Proc. of the 31st International Conference on Software Engineering - Companion Volume},
doi = {10.1109/ICSE-COMPANION.2009.5071063},
editor = {Cheng, Betty H. C. and de Lemos, Rogerio and Garlan, David and Giese, Holger and Litoiu, Marin and Magee, Jeff and Muller, Hausi A. and Taylor, Richard},
isbn = {978-1-4244-3495-4},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {may},
pages = {463--464},
publisher = {IEEE},
title = {{SEAMS 2009: Software engineering for adaptive and self-managing systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5071063},
year = {2009}
}
@book{cheng-et-al:book09,
abstract = {From 13.01 to 18.01.2008, the Dagstuhl Seminar 08031 "Software Engineering for SElf-Adaptive Systems" was held in the Intarnational Conference and Research Center (IBFI), Schloss Dagstuhl. During the seminar, several participants presented their current research, and ongoing work and open problems were discussed. Abstracts of the presentations given during the seminar as well as abstracts of seminar results and ideas are put together in this paper. The first section describes the seminar topics and goals in general. Links to extended abstracts or full papers are provided, if available.},
doi = {10.1007/978-3-642-02161-9},
editor = {Cheng, Betty H. C. and de Lemos, Rog{\'{e}}rio and Giese, Holger and Inverardi, Paola and Magee, Jeff},
file = {:Users/vitor/Mendeley/Unknown - 2009 - Software Engineering for Self-Adaptive Systems.pdf:pdf},
isbn = {978-3-642-02160-2},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Software Engineering for Self-Adaptive Systems}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-02161-9},
volume = {5525},
year = {2009}
}
@incollection{cheng-et-al:sesas09,
abstract = {The goal of this roadmap paper is to summarize the state-of-the-art and to identify critical challenges for the systematic software engineering of self-adaptive systems. The paper is partitioned into four parts, one for each of the identified essential views of self-adaptation: modelling dimensions, requirements, engineering, and assurances. For each view, we present the state-of-the-art and the challenges that our community must address. This roadmap paper is a result of the Dagstuhl Seminar 08031 on “Software Engineering for Self-Adaptive Systems,” which took place in January 2008.},
annote = {10.1007/978-3-642-02161-9{\_}1},
author = {Cheng, Betty H. C. and de Lemos, Rog{\'{e}}rio and Giese, Holger and Inverardi, Paola and Magee, Jeff and Andersson, Jesper and Becker, Basil and Bencomo, Nelly and Brun, Yuriy and Cukic, Bojan and {Di Marzo Serugendo}, Giovanna and Dustdar, Schahram and Finkelstein, Anthony and Gacek, Cristina and Geihs, Kurt and Grassi, Vincenzo and Karsai, Gabor and Kienle, Holger and Kramer, Jeff and Litoiu, Marin and Malek, Sam and Mirandola, Raffaela and M{\"{u}}ller, Hausi A. and Park, Sooyong and Shaw, Mary and Tichy, Matthias and Tivoli, Massimo and Weyns, Danny and Whittle, Jon},
booktitle = {Software Engineering for Self-Adaptive Systems},
doi = {10.1007/978-3-642-02161-9_1},
editor = {Cheng, Betty H. C. and de Lemos, Rog{\'{e}}rio and Giese, Holger and Inverardi, Paola and Magee, Jeff},
file = {:Users/vitor/Mendeley/Cheng et al. - 2009 - Software Engineering for Self-Adaptive Systems A Research Roadmap.pdf:pdf},
isbn = {978-3-642-02160-2},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {1--26},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Software Engineering for Self-Adaptive Systems: A Research Roadmap}},
url = {http://www.springerlink.com/content/h380742725036312/},
volume = {5525},
year = {2009}
}
@inproceedings{cheng-et-al:mdels09,
abstract = {Dynamically adaptive systems (DASs) are intended to monitor the execution environment and then dynamically adapt their behavior in response to changing environmental conditions. The uncertainty of the execution environment is a major motivation for dynamic adaptation; it is impossible to know at development time all of the possible combinations of environmental conditions that will be encountered. To date, the work performed in requirements engineering for a DAS includes requirements monitoring and reasoning about the correctness of adaptations, where the DAS requirements are assumed to exist. This paper introduces a goal-based modeling approach to develop the requirements for a DAS, while explicitly factoring uncertainty into the process and resulting requirements. We introduce a variation of threat modeling to identify sources of uncertainty and demonstrate how the RELAX specification language can be used to specify more flexible requirements within a goal model to handle the uncertainty.},
address = {Denver, CO, USA},
annote = {10.1007/978-3-642-04425-0{\_}36},
author = {Cheng, Betty H. C. and Sawyer, Pete and Bencomo, Nelly and Whittle, Jon},
booktitle = {Proc. of the 12th International Conference on Model Driven Engineering Languages and Systems (MODELS 09)},
doi = {10.1007/978-3-642-04425-0_36},
file = {:Users/vitor/Mendeley/Cheng et al. - 2009 - A Goal-Based Modeling Approach to Develop Requirements of an Adaptive System with Environmental Uncertainty.pdf:pdf},
isbn = {978-3-642-04424-3},
keywords = {bibtex,commented,dynamically adaptive systems,goal models,requirements engineering,uncertainty},
mendeley-tags = {bibtex,commented},
month = {oct},
pages = {468--483},
publisher = {Springer},
title = {{A Goal-Based Modeling Approach to Develop Requirements of an Adaptive System with Environmental Uncertainty}},
url = {http://www.springerlink.com/content/k5178g77k3255w35/},
year = {2009}
}
@phdthesis{cheng:thesis08,
abstract = {Modern, complex software systems (e-commerce, IT, critical infrastructures, etc.) are increasingly required to continue operation in the face of change, to self-adapt to accommodate shifting user priorities, resource variability, changing environments, and component failures. While manual oversight benefits from global problem contexts and flexible policies, human operators are costly and prone to error. Low-level, embedded mechanisms (exceptions, time-outs, etc.) are effective and timely for error recovery, but are local in scope to the point-of-failure, application-specific, and costly to modify when adaptation objectives change. An ideal solution leverages domain expertise, provides an end-to-end system perspective, adapts the system in a timely manner, and can be engineered cost-effectively.},
author = {Cheng, Shang-Wen},
file = {:Users/vitor/Mendeley/Cheng - 2008 - Rainbow Cost-Effective Software Architecture-based Self-adaptation.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
school = {Carnegie Mellon University},
title = {{Rainbow: Cost-Effective Software Architecture-based Self-adaptation}},
url = {http://acme.able.cs.cmu.edu/pubs/show.php?author=Shang-Wen{\_}Cheng},
year = {2008}
}
@article{cheng-garlan:jss12,
abstract = {Requirements for high availability in computing systems today demand that systems be self-adaptive to maintain expected qualities-of-service in the presence of system faults, variable environmental condi- tions, and changing user requirements. Autonomic computing tackles the challenge of automating tasks that humans would otherwise have to perform to achieve this goal. However, existing approaches to autonomic computing lack the ability to capture routine human repair tasks in a way that takes into account the business context humans use in selecting an appropriate form of adaptation, while dealing with timing delays and uncertainties in outcome of repair actions. In this article, we present Stitch, a language for representing repair strategies within the context of an architecture-based self-adaptation framework. Stitch supports the explicit representation of repair decision trees together with the ability to express business objectives, allowing a self-adaptive system to select a strategy that has optimal utility in a given context, even in the presence of potential timing delays and outcome uncertainty.},
author = {Cheng, Shang-Wen and Garlan, David},
doi = {10.1016/j.jss.2012.02.060},
editor = {Weyns, Danny and Malek, Sam and Andersson, Jesper and Schmerl, Bradley},
file = {:Users/vitor/Mendeley/Cheng, Garlan - 2012 - Stitch A language for architecture-based self-adaptation.pdf:pdf},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {bibtex,commented,rainbow,self-adaptation,strategy,tactic,uncertainty,utility},
mendeley-tags = {bibtex,commented},
month = {dec},
number = {12},
pages = {2860--2875},
publisher = {Elsevier},
title = {{Stitch: A language for architecture-based self-adaptation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121212000714},
volume = {85},
year = {2012}
}
@inproceedings{cheng-et-al:icse09,
abstract = {Rainbow is an approach for engineering self- adaptive systems, with run-time, closed-loop control over target systems to monitor, detect, decide, and act on opportunities for system improvement. RAIDE enables adaptation engineers to customize the Rainbow framework, simulate adaptation behavior, and deploy Rainbow run-time components.},
address = {Vancouver, BC, Canada},
author = {Cheng, Shang-Wen and Garlan, David and Schmerl, Bradley},
booktitle = {Proc. of the 31st International Conference on Software Engineering (ICSE '09) - Companion Volume},
doi = {10.1109/ICSE-COMPANION.2009.5071049},
file = {:Users/vitor/Mendeley/Cheng, Garlan, Schmerl - 2009 - RAIDE for engineering architecture-based self-adaptive systems.pdf:pdf},
isbn = {978-1-4244-3495-4},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {435--436},
publisher = {IEEE},
title = {{RAIDE for engineering architecture-based self-adaptive systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5071049},
year = {2009}
}
@inproceedings{cheng-et-al:seams09,
abstract = {Rainbow is a framework for engineering a system with run-time, self-adaptive capabilities to monitor, detect, decide, and act on opportunities for system improvement. We applied Rainbow to a system, Znn.com, and evaluated its effectiveness to self-adapt on three levels: its effectiveness to maintain quality attribute in the face of changing conditions, run-time overheads of adaptation, and the engineering effort to use it to add self-adaptive capabilities to Znn.com. We make Znn.com and the associated evaluation tools available to the community so that other researchers can use it to evaluate their own systems and the community can compare different systems. In this paper, we report on our evaluation experience, reflect on some principles for benchmarking self-adaptive systems, and discuss the suitability of our evaluation tools for this purpose.},
address = {Vancouver, BC, Canada},
author = {Cheng, Shang-Wen and Garlan, David and Schmerl, Bradley},
booktitle = {Proc. of the ICSE 2009 Workshop on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1109/SEAMS.2009.5069082},
file = {:Users/vitor/Mendeley/Cheng, Garlan, Schmerl - 2009 - Evaluating the Effectiveness of the Rainbow Self-Adaptive System.pdf:pdf},
isbn = {978-1-4244-3724-5},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {may},
pages = {132--141},
publisher = {IEEE},
title = {{Evaluating the Effectiveness of the Rainbow Self-Adaptive System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5069082},
year = {2009}
}
@article{chess-et-al:ibmsj03,
abstract = {System and network security are vital parts of any autonomic computing solution. The ability of a system to react consistently and correctly to situations ranging from benign but unusual events to outright attacks is key to the achievement of the goals of self-protection, self-healing, and self-optimization. Because they are often built around the interconnection of elements from different administrative domains, autonomic systems raise additional security challenges, including the establishment of a trustworthy system identity, automatically handling changes in system conﬁguration and interconnections, and greatly increased conﬁguration complexity. On the other hand, the techniques of autonomic computing offer the promise of making systems more secure, by effectively and automatically enforcing high- level security policies. In this paper, we discuss these and other security and privacy challenges posed by autonomic systems and provide some recommendations for how these challenges may be met.},
address = {Riverton, NJ, USA},
author = {Chess, David M. and Palmer, Charles C. and White, Steve R.},
doi = {10.1147/sj.421.0107},
file = {:Users/vitor/Mendeley/Chess, Palmer, White - 2003 - Security in an autonomic computing environment.pdf:pdf},
issn = {0018-8670},
journal = {IBM Systems Journal},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
number = {1},
pages = {107--118},
publisher = {IEEE},
title = {{Security in an autonomic computing environment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5386832},
volume = {42},
year = {2003}
}
@inproceedings{chess-et-al:icac04,
abstract = {The behavior of a system results from the behaviors of its components, and from the interactions and relationships among them. In order to create computing systems that manage themselves, we will need to design both the behaviors of the individual elements, and the relationships that are formed among them. This paper describes a research project called Unity, carried out at IBM's Thomas J. Watson Research Center, in which we explore some of the behaviors and relationships that will allow complex computing systems to manage themselves; to be self- configuring, self-optimizing, self-protecting, and self- healing. The four principle aspects of Unity that we will examine are the overall architecture of the system, the role of utility functions in decision-making within the system, the way the system uses goal-driven self- assembly to configure itself, and the design patterns that enable self-healing within the system.},
address = {New York, NY, USA},
author = {Chess, David M. and Segal, Alla and Whalley, Ian and White, Steve R.},
booktitle = {Proc. of the 2004 International Conference on Autonomic Computing},
doi = {10.1109/ICAC.2004.1301357},
file = {:Users/vitor/Mendeley/Chess et al. - 2004 - Unity Experiences with a Prototype Autonomic Computing System.pdf:pdf},
isbn = {0-7695-2114-2},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {140--147},
publisher = {IEEE},
title = {{Unity: Experiences with a Prototype Autonomic Computing System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1301357},
year = {2004}
}
@misc{chinnici-shannon:website09,
author = {Chinnici, Roberto and Shannon, Bill},
file = {:Users/vitor/Mendeley/Chinnici, Shannon - 2009 - JSR 316 Java(TM) Platform, Enterprise Edition 6 (Java EE 6) Specification, httpjcp.orgenjsrdetailid=316 (last.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{JSR 316: Java(TM) Platform, Enterprise Edition 6 (Java EE 6) Specification, http://jcp.org/en/jsr/detail?id=316 (last access: September 29th, 2010)}},
url = {http://jcp.org/en/jsr/detail?id=316},
year = {2009}
}
@book{chung-et-al:book00,
author = {Chung, Lawrence and Nixon, Brian A. and Yu, Eric and Mylopoulos, John},
doi = {10.1007/978-1-4615-5269-7},
isbn = {978-1-4613-7403-9},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Springer},
title = {{Non-Functional Requirements in Software Engineering}},
url = {http://link.springer.com/10.1007/978-1-4615-5269-7},
year = {2000}
}
@article{corcho-et-al:dke03,
abstract = {In this paper we review and compare the main methodologies, tools and languages for building ontologies that have been reported in the literature, as well as the main relationships among them. Ontology technology is nowadays mature enough: many methodologies, tools and languages are already available. The future work in this field should be driven towards the creation of a common integrated workbench for ontology developers to facilitate ontology development, exchange, evaluation, evolution and management, to provide methodological support for these tasks, and translations to and from different ontology languages. This workbench should not be created from scratch, but instead integrating the technology components that are currently available.},
author = {Corcho, Oscar and Fern{\'{a}}ndez-L{\'{o}}pez, Mariano and G{\'{o}}mez-P{\'{e}}rez, Asunci{\'{o}}n},
doi = {10.1016/S0169-023X(02)00195-7},
file = {:Users/vitor/Mendeley/Corcho, Fern{\'{a}}ndez-L{\'{o}}pez, G{\'{o}}mez-P{\'{e}}rez - 2003 - Methodologies, tools and languages for building ontologies. Where is their meeting poi.pdf:pdf},
issn = {0169023X},
journal = {Data {\&} Knowledge Engineering},
keywords = {bibtex,commented,ontology,ontology language,ontology methodology,ontology tool},
mendeley-tags = {bibtex,commented},
month = {jul},
number = {1},
pages = {41--64},
publisher = {Elsevier},
title = {{Methodologies, tools and languages for building ontologies. Where is their meeting point?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169023X02001957},
volume = {46},
year = {2003}
}
@inproceedings{corcho-et-al:www06,
abstract = {We describe the architecture of the ODESeW 2.0 Semantic Web application development platform, which has been used to generate the internal and external Web sites of several R{\&}D projects.},
address = {Edinburgh, Scotland},
author = {Corcho, Oscar and L{\'{o}}pez-Cima, Angel and G{\'{o}}mez-P{\'{e}}rez, Asunci{\'{o}}n},
booktitle = {Proc. of the 15th International Conference on World Wide Web},
doi = {10.1145/1135777.1136009},
isbn = {1595933239},
keywords = {bibtex,framework,semantic web,web application},
mendeley-tags = {bibtex},
month = {may},
pages = {1049--1050},
publisher = {ACM},
title = {{The ODESeW 2.0 semantic web application framework}},
url = {http://portal.acm.org/citation.cfm?doid=1135777.1136009},
year = {2006}
}
@article{cornford-et-al:maes06,
abstract = {At JPL we have developed and implemented a process for achieving life-cycle risk management. This process has been embodied in a software tool and is called defect detection and prevention (DDP). The DDP process can be succinctly stated as: determine where we want to be, what could get in the way and how we will get there. The "determine where we want to be" is captured as trees of requirements and the "what could get in the way" is captured as trees of potential failure modes. Scoring the impacts of these failure modes on the requirements results in a prioritized set of failure modes. The user then selects from a set of preventative measures, analyses, process controls and tests (PACTs) each of which has an effectiveness versus the various failure modes. It is the goal of the DDP process to optimally select the subset of the PACTs which minimizes the residual risk subject to the project resource constraints. The DDP process is intended to facilitate risk management over the entire project life cycle beginning with architectural and advanced technology decisions all the way through operation. As the project design, technology content, and implementation approach matures, the requirements and failure mode trees are elaborated upon to accommodate the additional information. Thus, the DDP process is a systematic, continuous, top-down approach to managing risk. Implementation of the DDP process requires a critical mass of expertise (usually the project team and a few specialists) and captures both their engineering judgement as well as available quantitative data. This additional data may result from models, layouts, prototype testing, other focused risk evaluations and institutional experiences. The DDP process also identifies areas where additional information would be advantageous, thus allowing a project to target critical areas of risk or risk uncertainty. This also allows the project to identify those areas which would benefit the most from application of other qu- - antitative tools and methods (e.g. Monte Carlo simulations, FMECAs, fault trees). The software tool supports the DDP process by providing guidance for implementing the process steps, graphical visualizations of the various trees, their interrelationships and the current risk landscape. The tool is capable of supporting on-the-fly knowledge elicitation as well as integrating off-line deliberations. There are a variety of available outputs including graphs, trees and reports as well as clear identification of the driving requirements, "tall-pole" residual risks and the PACTs which have been selected and agreed upon. The DDP process has been applied at various levels of assembly including the system and subsystem levels, as well as down to the component level. Recently, significant benefits have been realized from application to advanced technologies, where the focus has been on increasing the infusion rates of these technologies by identification and mitigation of risks prior to delivery to a project.},
author = {Cornford, Steven L. and Feather, Martin S. and Hicks, Kenneth A.},
doi = {10.1109/MAES.2006.1662004},
file = {:Users/vitor/Mendeley/Cornford, Feather, Hicks - 2006 - DDP A Tool for Life-Cycle Risk Management.pdf:pdf},
issn = {0885-8985},
journal = {IEEE Aerospace and Electronic Systems Magazine},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {jun},
number = {6},
pages = {13--22},
publisher = {IEEE},
title = {{DDP: A Tool for Life-Cycle Risk Management}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1662004},
volume = {21},
year = {2006}
}
@techreport{costa-pg15,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {da Costa, Thiago Martinho},
file = {:Users/vitor/Mendeley/Costa - 2015 - Resgate - Despacho de ambul{\^{a}}ncia automatizado.pdf:pdf},
institution = {Projeto de Gradua{\c{c}}{\~{a}}o, Departamento de Inform{\'{a}}tica, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{Resgate - Despacho de ambul{\^{a}}ncia automatizado}},
year = {2015}
}
@inproceedings{cunningham-song:er07,
abstract = {Customer Relationship Management (CRM) is a strategy that supports an organization's decision-making process to retain long-term and profitable relationships with its customers. Effective CRM analyses require a detailed data warehouse model that can support various CRM analyses and deep understanding on CRM-related business questions. In this paper, we present a taxonomy of CRM analysis categories. Our CRM taxonomy includes CRM strategies, CRM category analyses, CRM business questions, their potential uses, and key performance indicators (KPIs) for those analysis types. Our CRM taxonomy can be used in selecting and evaluating a data schema for CRM analyses, CRM vendors, CRM strategies, and KPIs.},
address = {Auckland, New Zealand},
author = {Cunningham, Colleen and Song, Il-Yeol},
booktitle = {Tutorials, posters, panels and industrial contributions at the 26th International Conference on Conceptual Modeling},
file = {:Users/vitor/Mendeley/Cunningham, Song - 2007 - A Taxonomy of Customer Relationship Management Analyses for Data Warehousing.pdf:pdf},
isbn = {978-1-920682-64-4},
keywords = {CRM,CRM analyses,KPIs,bibtex,customer relationship management,data warehousing,key performance indicators,not-commented,summarized,taxonomy},
mendeley-tags = {bibtex,not-commented,summarized},
month = {nov},
pages = {97--102},
publisher = {Australian Computer Society},
title = {{A Taxonomy of Customer Relationship Management Analyses for Data Warehousing}},
url = {http://dl.acm.org/citation.cfm?id=1386972},
year = {2007}
}
@phdthesis{dalpiaz:thesis11,
abstract = {ocio-Technical System (STS). The thesis proposes a comprehensive framework for designing self-adaptive software that operates within a socio-technical system. The framework is founded upon the notions of contextual and social variability. A key ingredient of our approach is to rely on high-level abstractions to represent the purpose of the system (requirements model), to explicitly rep- resent the commitments that exist among participating actors in an STS, and also to con- sider how operational context influences requirements. The proposed framework consists of (i) modelling and analysis techniques for representing and reasoning about contextual and social variability; (ii) a conceptual architecture for self-adaptive STSs; and (iii) a set of algorithms to diagnose a failure and to compute and select a new variant that ad- dresses the failure. To evaluate our proposal, we developed two prototype implementations of our architecture to demonstrate different features of our framework, and successfully applied them to two case studies. In addition, the thesis reports encouraging results on experiments we conducted with our implementations in order to check for scalability.},
author = {Dalpiaz, Fabiano},
file = {:Users/vitor/Mendeley/Dalpiaz - 2011 - Exploiting Contextual and Social Variability for Software Adaptation.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
number = {January},
school = {University of Trento},
title = {{Exploiting Contextual and Social Variability for Software Adaptation}},
type = {PhD Thesis},
url = {http://eprints-phd.biblio.unitn.it/451/},
year = {2011}
}
@inproceedings{dalpiaz-et-al:rcis13,
abstract = {Goal models capture stakeholder requirements for a system-to-be, but also circumscribe a space of alternative specifications for fulfilling these requirements. Recent proposals for self-adaptive software systems rely on variants of goal models to support monitoring and adaptation functions. In such cases, goal models serve as mechanisms in terms of which systems reflect upon their requirements during their operation. We argue that existing proposals for using goal models at runtime are using design artifacts for purposes they were not intended, i.e., for reasoning about runtime system behavior. In this paper, we propose a conceptual distinction between Design-time Goal Models (DGMs)-used to design a system-and Runtime Goal Models (RGMs)-used to analyze a system's runtime behavior with respect to its requirements. RGMs extend DGMs with additional state, behavioral and historical information about the fulfillment of goals. We propose a syntactic structure for RGMs, a method for deriving them from DGMs, and runtime algorithms that support their monitoring.},
address = {Paris, France},
author = {Dalpiaz, Fabiano and Borgida, Alexander and Horkoff, Jennifer and Mylopoulos, John},
booktitle = {Proc. of the IEEE 7th International Conference on Research Challenges in Information Science},
doi = {10.1109/RCIS.2013.6577674},
file = {:Users/vitor/Mendeley/Dalpiaz et al. - 2013 - Runtime goal models.pdf:pdf},
isbn = {978-1-4673-2914-9},
keywords = {bibtex,goal reasoning,not-commented,requirements at runtime,runtime goal models,self-adaptive systems},
mendeley-tags = {bibtex,not-commented},
month = {may},
pages = {1--11},
publisher = {IEEE},
title = {{Runtime goal models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6577674},
year = {2013}
}
@incollection{dalpiaz-et-al:er10,
abstract = {We address the challenge of adaptation in open systems. Open systems are characterized by interactions among autonomous and heterogeneous participants. In such systems, each participant is a locus of adaptation; nonetheless, a participant would typically have to interact with others in order to effect an adaptation. Existing approaches for software adaptation do not readily apply to such settings as they rely upon control-based abstractions. We build upon recent work on modeling interaction via social commitments . Our contributions in this paper include (1) formalizing the notion of a participant's strategy for a goal not just in terms of goals and plans, but also in terms of the commitments required, and (2) a conceptual model and framework for adaptation built around this notion of strategy that allows using arbitrary strategy selection criteria—for example, trust. We illustrate our contributions with examples from the emergency services domain.},
annote = {10.1007/978-3-642-16373-9{\_}3},
author = {Dalpiaz, Fabiano and Chopra, Amit K. and Giorgini, Paolo and Mylopoulos, John},
booktitle = {Conceptual Modeling -- ER 2010},
doi = {10.1007/978-3-642-16373-9_3},
editor = {Parsons, Jeffrey and Saeki, Motoshi and Shoval, Peretz and Woo, Carson and Wand, Yair},
file = {:Users/vitor/Mendeley/Dalpiaz et al. - 2010 - Adaptation in Open Systems Giving Interaction Its Rightful Place.pdf:pdf},
isbn = {978-3-642-16372-2},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {31--45},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Adaptation in Open Systems: Giving Interaction Its Rightful Place}},
url = {http://www.springerlink.com/content/3676152m95u81247/},
volume = {6412},
year = {2010}
}
@incollection{dalpiaz-et-al:caise09,
abstract = {Self-reconfiguration is the capability of a system to autonomously switch from one configuration to a better one in response to failure or context change. There is growing demand for software systems able to self-reconfigure, and specifically systems that can fulfill their requirements in dynamic environments. We propose a conceptual architecture that provides systems with self-reconfiguration capabilities, enacting a model-based adaptation process based on requirements models. We describe the logical view on our architecture for self-reconfiguration, then we detail the main mechanisms to monitor for and diagnose failures. We present a case study where a self-reconfiguring system assists a patient perform daily tasks, such as getting breakfast, within her home. The challenge for the system is to fulfill its mission regardless of the context, also to compensate for failures caused by patient inaction or other omissions in the environment of the system.},
annote = {10.1007/978-3-642-02144-2{\_}22},
author = {Dalpiaz, Fabiano and Giorgini, Paolo and Mylopoulos, John},
booktitle = {Advanced Information Systems Engineering},
doi = {10.1007/978-3-642-02144-2_22},
editor = {van Eck, Pascal and Gordijn, Jaap and Wieringa, Roel},
file = {:Users/vitor/Mendeley/Dalpiaz, Giorgini, Mylopoulos - 2009 - An Architecture for Requirements-Driven Self-reconfiguration.pdf:pdf},
isbn = {978-3-642-02143-5},
keywords = {bibtex,highlight,not-commented,summarized},
mendeley-tags = {bibtex,highlight,not-commented,summarized},
pages = {246--260},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{An Architecture for Requirements-Driven Self-reconfiguration}},
url = {http://www.springerlink.com/content/p6k0n0r2840737n3/},
volume = {5565},
year = {2009}
}
@article{dalpiaz-et-al:rej12,
abstract = {A socio-technical system (STS) consists of an interplay of humans, organizations, and technical systems. STSs are heterogeneous, dynamic, unpredictable, and weakly controllable. Their operational environment changes unexpectedly, actors join and leave the system at will, actors fail to meet their objectives and under-perform, and dependencies on other actors are violated. To deal with such situations, we propose an architecture for STSs that makes an STS self-reconfigurable, i.e., capable of switching autonomously from one configuration to a better one. Our architecture performs a Monitor-Diagnose-Reconcile-Compensate cycle: it monitors actor behaviors and context changes, diagnoses failures and under-performance by checking whether monitored behavior is compliant with actors goals, finds a possible way to address the problem, and enacts compensation actions to reconcile actual and desired behavior. Compensation actions take into account the autonomy of participants in an STS, which cannot be controlled. Our architecture is requirements driven : we use extended Tropos goal models to diagnose failures as well as to identify alternative strategies to meet requirements. After presenting our conceptual architecture and the algorithms, it is founded upon; we describe a prototype implementation applied to a case study concerning smart-homes. We also provide experimental results that suggest that our architecture scales well as the size of the STS grows.},
annote = {10.1007/s00766-011-0132-1},
author = {Dalpiaz, Fabiano and Giorgini, Paolo and Mylopoulos, John},
doi = {10.1007/s00766-011-0132-1},
file = {:Users/vitor/Mendeley/Dalpiaz, Giorgini, Mylopoulos - 2012 - Adaptive socio-technical systems a requirements-based approach.pdf:pdf},
issn = {0947-3602},
journal = {Requirements Engineering},
keywords = {bibtex,goal models,not-commented,requirements engineering,self-adaptive software,socio-technical},
mendeley-tags = {bibtex,not-commented},
number = {1},
pages = {1--24},
publisher = {Springer},
title = {{Adaptive socio-technical systems: a requirements-based approach}},
url = {http://www.springerlink.com/content/q120737787t30m25/},
volume = {18},
year = {2012}
}
@inproceedings{dalpiaz-et-al:apccm14,
abstract = {Goal models have been used in Requirements Engineering (RE) to elicit, model and analyse stakeholder requirements. In a goal model, stakeholder requirements are represented as root-level goals that are iteratively refined through AND/OR-refinements to eventually yield a specification consisting of functions the system-to-be needs to implement, as well non-functional requirements and domain assumptions. The association of a function to a goal is called operationalization in the sense that the function specifies how a goal can be made operational. We focus on the concept of operationalization and propose several extensions to account for operationalizations of non-functional and adaptation requirements, as well as behavioural specifications.},
address = {Auckland, New Zealand},
annote = {Short paper},
author = {Dalpiaz, Fabiano and Souza, V{\'{i}}tor E. S. and Mylopoulos, John},
booktitle = {Proc. of the 10th Asia-Pacific Conference on Conceptual Modelling},
file = {:Users/vitor/Mendeley/Dalpiaz, Souza, Mylopoulos - 2014 - The many faces of operationalization in goal-oriented requirements engineering.pdf:pdf},
keywords = {bibtex,export,goal model,goal-oriented requirements engineering,operationalization},
mendeley-tags = {bibtex,export},
month = {jan},
pages = {3--7},
publisher = {Australian Computer Society},
title = {{The many faces of operationalization in goal-oriented requirements engineering}},
url = {http://dl.acm.org/citation.cfm?id=2667692},
volume = {154},
year = {2014}
}
@inproceedings{dancy-cordy:cascon06,
abstract = {One aspect of autonomic computing is the ability to identify, separate and automatically tune parameters related to performance, security, robustness and other properties of a software system. Often the response to events affecting these properties consists of adjusting tuneable system parameters such as table sizes, timeout limits, restart checks and so on. In many ways these tuneable parameters correspond to the switches and potentiometers on the control panel of many hardware devices. While modern software systems designed for autonomic control may make these parameters easily accessible, in legacy systems they are often scattered or deeply hidden in the software source.In this paper we introduce Software Tuning Panels for Autonomic Control (STAC), a system for automatically re-architecting legacy software systems to facilitate autonomic control. STAC works to isolate tuneable system parameters into one visible area of a system, producing a resulting architecture that can be used in conjunction with an autonomic controller for self-maintenance and tuning. A proof-of-concept implementation of STAC using source transformation is presented along with its application to the automatic re-architecting of two open source Java programs. Use of the new architecture in monitoring and autonomic control is demonstrated on these examples.},
address = {Markham, ON, Canada},
author = {Dancy, Elizabeth and Cordy, James R.},
booktitle = {Proc. of the 2006 Conference of the Center for Advanced Studies on Collaborative Research},
doi = {10.1145/1188966.1188982},
file = {:Users/vitor/Mendeley/Dancy, Cordy - 2006 - STAC Software Tuning Panels For Autonomic Control.pdf:pdf},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {nov},
pages = {12},
publisher = {ACM},
title = {{STAC: Software Tuning Panels For Autonomic Control}},
url = {http://portal.acm.org/citation.cfm?doid=1188966.1188982},
year = {2006}
}
@article{dardenne-et-al:scp93,
abstract = {Requirements analysis includes a preliminary acquisition step where a global model for the specification of the system and its environment is elaborated. This model, called requirements model, involves concepts that are currently not supported by existing formal specification languages, such as goals to be achieved, agents to be assigned, alternatives to be negotiated, etc. The paper presents an approach to requirements acquisition which is driven by such higher-level concepts. Requirements models are acquired as instances of a conceptual meta-model. The latter can be represented as a graph where each node captures an abstraction such as, e.g., goal, action, agent, entity, or event, and where the edges capture semantic links between such abstractions. Well-formedness properties on nodes and links constrain their instances - that is, elements of requirements models. Requirements acquisition processes then correspond to particular ways of traversing the meta-model graph to acquire appropriate instances of the various nodes and links according to such constraints. Acquisition processes are governed by strategies telling which way to follow systematically in that graph; at each node specific tactics can be used to acquire the corresponding instances. The paper describes a significant portion of the meta-model related to system goals, and one particular acquisition strategy where the meta-model is traversed backwards from such goals. The meta-model and the strategy are illustrated by excerpts of a university library system.},
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Dardenne, Anne and van Lamsweerde, Axel and Fickas, Stephen},
doi = {10.1016/0167-6423(93)90021-G},
file = {:Users/vitor/Mendeley/Dardenne, van Lamsweerde, Fickas - 1993 - Goal-directed Requirements Acquisition.pdf:pdf},
issn = {01676423},
journal = {Science of Computer Programming},
keywords = {bibtex,conceptual modeling,domain analysis,meta-level inference,nonfunctional requirements,not-commented,requirements engineering,specification acquisition,specification reuse},
mendeley-tags = {bibtex,not-commented},
month = {apr},
number = {1-2},
pages = {3--50},
publisher = {Elsevier},
title = {{Goal-directed Requirements Acquisition}},
url = {http://www.sciencedirect.com/science/article/pii/016764239390021G},
volume = {20},
year = {1993}
}
@article{dasgupta:cim06,
abstract = {During the last decade, the field of Artificial Immune System (AIS) is progressing slowly and steadily as a branch of Computational Intelligence (CI) as shown in Figure 1.There has been increasing interest in the development of computa- tional models inspired by several immunological principles. In particular, some are building models mimicking the mechanisms in the biological immune system (BIS) to better understand its natural processes and simulate its dynamical behavior in the presence of antigens/pathogens. Most of the AIS models, however, emphasize designing arti- facts–computational algorithms, techniques using simplified models of various immunological processes and functionalities. Like other biologically-inspired tech- niques, such as artificial neural networks, genetic algorithms, and cellular automata, AISs also try to extract ideas from the BIS in order to develop computational tools for solving science and engineering problems. Although still relative- ly young, the Artificial Immune System (AIS) is emerging as an active and attractive field involving models, techniques and applications of greater diversity.},
author = {Dasgupta, Dipankar},
doi = {10.1109/MCI.2006.329705},
file = {:Users/vitor/Mendeley/Dasgupta - 2006 - Advances in Artificial Immune Systems.pdf:pdf},
issn = {1556-603X},
journal = {IEEE Computational Intelligence Magazine},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {nov},
number = {4},
pages = {40--49},
publisher = {IEEE},
title = {{Advances in Artificial Immune Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4129847},
volume = {1},
year = {2006}
}
@inproceedings{dastani-et-al:aamas06,
abstract = {This paper discusses three types of declarative goals and motivates their integration in logic-based agent-oriented programming languages. These goal types are perform goals, achieve goals, and maintain goals. A goal type is considered as a specific agent attitude towards goals. The semantics for each goal type is explained from an operational perspective. It is argued that the suggested semantics of the goal types ensure some desirable and expected properties.},
address = {Hakodate, Japan},
author = {Dastani, Mehdi and van Riemsdijk, M. Birna and Meyer, John-Jules C.},
booktitle = {Proc. of the 5th International Joint Conference on Autonomous Agents and Multiagent Systems},
doi = {10.1145/1160633.1160867},
file = {:Users/vitor/Mendeley/Dastani, van Riemsdijk, Meyer - 2006 - Goal Types in Agent Programming.pdf:pdf},
isbn = {1595933034},
keywords = {agent programming languages,agent types,bibtex,declarative goals,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {may},
pages = {1285--1287},
publisher = {ACM},
title = {{Goal Types in Agent Programming}},
url = {http://portal.acm.org/citation.cfm?doid=1160633.1160867},
year = {2006}
}
@book{delemos-et-al:book13,
abstract = {The complexity of current software-based systems has led the software engineer- ing community to look for inspiration in diversely related fields (e.g., robotics and control theory) as well as other areas (e.g., biology) to find innovative approaches for building, running, and managing software systems and services. Therefore, self-adaptation—systems that are able to adjust their behavior or structure at run-time in response to their perception of the environment and the system itself – has become a hot topic within the software engineering community. This book is one of the outcomes of Dagstuhl Seminar 10431 on “Software En- gineering for Self-Adaptive Systems” held in October 2010. It is the second book in the series and comprises a research roadmap, four working group papers, and invited papers from recognized experts in the field. The research roadmap, com- plemented by four group papers that detail the issues covered by the roadmap, summarizes the Dagstuhl Seminar discussions and provides insights into key features of self-adaptive software systems. All the papers in this book are peer- reviewed, with the exception of the roadmap paper, which was written in several iterations over the past two years by the participants of this Dagstuhl Seminar. The book consists of four parts: “Research Roadmap,” “Requirements and Poli- cies,” “Design Issues,” and “Applications.”},
editor = {de Lemos, Rog{\'{e}}rio and Giese, Holger and M{\"{u}}ller, Hausi A. and Shaw, Mary},
file = {:Users/vitor/Mendeley/Unknown - 2013 - Software Engineering for Self-Adaptive Systems II.pdf:pdf},
isbn = {978-3-642-35812-8},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Software Engineering for Self-Adaptive Systems II}},
url = {http://link.springer.com/book/10.1007/978-3-642-35813-5},
volume = {7475},
year = {2013}
}
@book{seams10,
abstract = {An emerging requirement for a software-based system is the ability to self-manage by adapting itself at run time to handle such things, as changing user needs, system intrusions or faults, a changing operational environment, and resource variability. Such a system must configure and reconfigure itself, augment its functionality, continually optimize itself, protect itself, and recover itself, while keeping its complexity hidden from the user. Self-adaptive and self-managing systems have been studied by various communities, including software architecture, fault-tolerant computing, robotics, control systems, programming languages, autonomic computing, and biologically-inspired computing. SEAMS workshop brings together researchers and practitioners from many of these diverse areas to discuss the fundamental principles, state-of-the-art, and critical challenges of self-adaptive and self-managing systems. Specifically, SEAMS addresses the software engineering aspects, including the methods, architectures, algorithms, techniques, and tools that can be used to support dynamic adaptive behavior. Self-adaptation in self-managing systems represents a major step ahead for software engineering. While in the past methods, tools, and notations have focused on the problem of preventing problems from occurring in our deployed systems, increasingly this is not enough. In addition to preventing a subset of problems, systems must take a much more aggressive role in detecting, analyzing and fixing the run time problems. A central concern then becomes the engineering mechanisms that can support self-adaptation. Too often today's systems achieve run-time flexibility only by hard wiring in special-purpose, low-level code (like exceptions and time outs) that is difficult to change, reuse, or analyze. The ICSE 2010 SEAMS workshop will be a continuation of an effort, which started at ICSE 2006 SEAMS to integrate a number of successful workshops in the area of adaptive and self-managing systems held at ICSE and FSE in recent years. The objective is to consolidate the interest in the software engineering community on these topics through this integrated SEAMS workshop.},
address = {Cape Town, South Africa},
editor = {de Lemos, Rog{\`{e}}rio and Pezz{\`{e}}, Mauro},
isbn = {978-1-60558-971-8},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {ACM},
title = {{Proceedings of the 2010 ICSE Workshop on Software Engineering for Adaptive and Self-Managing Systems}},
url = {http://portal.acm.org/citation.cfm?id=1808984},
year = {2010}
}
@inproceedings{desouza-schwabe:icwe11,
abstract = {In this paper, show how Linked Data Applications (LDAs) can be designed and implemented using an evolution of the Semantic Hypermedia Design Method, SHDM, and a new development environment supporting it, Synth. Using them, it is possible to take any RDF data available on the Linked Data cloud, extend it with one's own data, and provide a Web application that exposes and manipulates this data to perform a given set of tasks, including not only navigation, but also general business logic. In most cases, the only code that needs to be written is for the Business Logic; the remainder code is automatically generated by Synth based on the SHDM models.},
address = {Paphos, Cyprus},
author = {{de Souza Bomfim}, Mauricio Henrique and Schwabe, Daniel},
booktitle = {Proc. of the 11th International Conference on Web Engineering},
doi = {10.1007/978-3-642-22233-7_9},
keywords = {bibtex,design method,linked data,linked data applications,model driven development,rdf,semantic web},
mendeley-tags = {bibtex},
month = {jun},
pages = {121--136},
publisher = {Springer},
title = {{Design and Implementation of Linked Data Applications Using SHDM and Synth}},
url = {http://link.springer.com/10.1007/978-3-642-22233-7{\_}9},
year = {2011}
}
@article{delgado-et-al:tse04,
abstract = {A goal of runtime software-fault monitoring is to observe software behavior to determine whether it complies with its intended behavior. Monitoring allows one to analyze and recover from detected faults; providing additional defense against catastrophic failure. Although runtime monitoring has been in use for over 30 years; there is renewed interest in its application to fault detection and recovery; largely because of the increasing complexity and ubiquitous nature of software systems. We present taxonomy that developers and researchers can use to analyze and differentiate recent developments in runtime software fault-monitoring approaches. The taxonomy categorizes the various runtime monitoring research by classifying the elements that are considered essential for building a monitoring system; i.e.; the specification language used to define properties; the monitoring mechanism that oversees the program's execution; and the event handler that captures and communicates monitoring results. After describing the taxonomy; the paper presents the classification of the software-fault monitoring systems described in the literature.},
author = {Delgado, N. and Gates, A.Q. and Roach, S.},
doi = {10.1109/TSE.2004.91},
file = {:Users/vitor/Mendeley/Delgado, Gates, Roach - 2004 - A taxonomy and catalog of runtime software-fault monitoring tools.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {assertion checkers,bibtex,commented,program verification,runtime monitors,software verification,specification,specification language,survey},
mendeley-tags = {bibtex,commented},
month = {dec},
number = {12},
pages = {859--872},
publisher = {IEEE},
title = {{A taxonomy and catalog of runtime software-fault monitoring tools}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1377185},
volume = {30},
year = {2004}
}
@misc{demichiel-shannon:website13,
author = {DeMichiel, Linda and Shannon, Bill},
file = {:Users/vitor/Mendeley/DeMichiel, Shannon - 2013 - JSR 342 Java(TM) Platform, Enterprise Edition 7 (Java EE 7) Specification, httpsjcp.orgenjsrdetailid=342 (la.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{JSR 342: Java(TM) Platform, Enterprise Edition 7 (Java EE 7) Specification, https://jcp.org/en/jsr/detail?id=342 (last access: April 29th, 2015)}},
url = {https://jcp.org/en/jsr/detail?id=342},
year = {2013}
}
@article{devedzic:cacm02,
abstract = {Ontological engineering has garnered increasing attention over the last few years, as researchers have recognized ontologies are not just for knowledge-based systems---all software needs models of the world, and hence can make use of ontologies at design time [1]. A recent survey of the field [4] suggests developers of practical AI systems may especially benefit from their use. This survey earmarked several application classes that benefit from using ontologies, including natural language processing, intelligent information retrieval (especially from the Internet), virtual organizations, and simulation and modeling.},
author = {Devedzi{\'{c}}, Vladan},
doi = {10.1145/505248.506002},
file = {:Users/vitor/Mendeley/Devedzi{\'{c}} - 2002 - Understanding ontological engineering.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
number = {4},
pages = {136--144},
publisher = {ACM},
title = {{Understanding ontological engineering}},
url = {http://portal.acm.org/citation.cfm?doid=505248.506002},
volume = {45},
year = {2002}
}
@inproceedings{dey-et-al:iswc99,
abstract = {We describe the Conference Assistant, a prototype mobile, context-aware application that assists conference attendees. We discuss the strong relationship between context-awareness and wearable computing and apply this relationship in the Conference Assistant. The application uses a wide variety of contexts and enhances user interactions with both the environment and other users. We describe how the application is used and the context-aware architecture on which it is based.},
address = {San Francisco, CA, USA},
author = {Dey, A.K. and Salber, D. and Abowd, G.D. and Futakawa, M.},
booktitle = {Proc. of the 3rd International Symposium on Wearable Computers},
doi = {10.1109/ISWC.1999.806639},
file = {:Users/vitor/Mendeley/Dey et al. - 1999 - The Conference Assistant combining context-awareness with wearable computing.pdf:pdf},
isbn = {0-7695-0428-0},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {oct},
pages = {21--28},
publisher = {IEEE},
title = {{The Conference Assistant: combining context-awareness with wearable computing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=806639},
year = {1999}
}
@article{dinitto-et-al:ase08,
abstract = {Future software systems will operate in a highly dynamic world. Systems will need to operate correctly despite of unespected changes in factors such as environmental conditions, user requirements, technology, legal regulations, and market opportunities. They will have to operate in a constantly evolving environment that includes people, content, electronic devices, and legacy systems. They will thus need the ability to continuously adapt themselves in an automated manner to react to those changes. To realize dynamic, self-adaptive systems, the service concept has emerged as a suitable abstraction mechanism. Together with the concept of the service-oriented architecture (SOA), this led to the development of technologies, standards, and methods to build service-based applications by flexibly aggregating individual services. This article discusses how those concepts came to be by taking two complementary viewpoints. On the one hand, it evaluates the progress in software technologies and methodologies that led to the service concept and SOA. On the other hand, it discusses how the evolution of the requirements, and in particular business goals, influenced the progress towards highly dynamic self-adaptive systems. Finally, based on a discussion of the current state of the art, this article points out the possible future evolution of the field.},
annote = {10.1007/s10515-008-0032-x},
author = {{Di Nitto}, Elisabetta and Ghezzi, Carlo and Metzger, Andreas and Papazoglou, Mike and Pohl, Klaus},
doi = {10.1007/s10515-008-0032-x},
file = {:Users/vitor/Mendeley/Di Nitto et al. - 2008 - A journey to highly dynamic, self-adaptive service-based applications.pdf:pdf},
issn = {0928-8910},
journal = {Automated Software Engineering},
keywords = {adaptive systems,bibtex,commented,self-adaptation,service-oriented computing,services},
mendeley-tags = {bibtex,commented},
number = {3},
pages = {313--341},
publisher = {Springer},
title = {{A journey to highly dynamic, self-adaptive service-based applications}},
url = {http://www.springerlink.com/content/v803458l2315gr70/},
volume = {15},
year = {2008}
}
@article{dijkstra:cacm72,
author = {Dijkstra, Edsger W.},
doi = {10.1145/355604.361591},
file = {:Users/vitor/Mendeley/Dijkstra - 1972 - The humble programmer.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {oct},
number = {10},
pages = {859--866},
publisher = {ACM},
title = {{The humble programmer}},
url = {http://portal.acm.org/citation.cfm?doid=355604.361591},
volume = {15},
year = {1972}
}
@inproceedings{dinkelaker-et-al:wcv10,
abstract = {Dynamic software product lines (DSPLs) are software product lines, which support late variability that is built into the system to address requirements that change at runtime. But it is difficult to ensure at runtime that all possible adaptations lead to a correct configuration. In this paper, we propose a novel approach for DSPLs that uses a dynamic feature model to describe the variability in the DSPLs and that uses a domain-specific language for declaratively implementing variations and their constraints. The approach combines several trends in aspect-oriented programming for DSPLs, namely dynamic aspects, runtime models of aspects, as well as detection and resolution of aspect interactions. The advantage is, that reconfigurations must not be specified for every feature combination, but only for interacting features. We have validated the approach in an example dynamic software product line from industry and preliminarily evaluated the approach.},
address = {Rennes {\&} Saint Malo, France},
author = {Dinkelaker, Tom and Mitschke, Ralf and Fetzer, Karin and Mezini, Mira},
booktitle = {Proc. of the 1st International Workshop on Composition: Objects, Aspects, Components, Services and Product Lines},
file = {:Users/vitor/Mendeley/Dinkelaker et al. - 2010 - A Dynamic Software Product Line Approach Using Aspect Models at Runtime.pdf:pdf},
keywords = {bibtex,domain-specific languages,dynamic feature models,dynamic software product line engineering,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {mar},
pages = {11--18},
publisher = {CEUR},
title = {{A Dynamic Software Product Line Approach Using Aspect Models at Runtime}},
url = {http://ceur-ws.org/Vol-564/},
year = {2010}
}
@book{icac09,
abstract = {On behalf of the steering and program committees, it is our pleasure to welcome you to the Sixth International Conference on Autonomic Computing and Communications, being held on the lovely campus of the Universitat Polit{\`{e}}cnica de Catalunya, Barcelona, Spain. By the standards of the field, ICAC is an established conference. Nonetheless over the last six years the landscape of autonomic systems research has changed, and we have changed the format of the conference to match. The most obvious change is the explicit recognition of autonomic communications in our title. The potential for autonomic techniques in networking was first recognized in Europe, and so it is fitting that ICAC has included it explicitly at what is only the conference's second visit to Europe (after Dublin in 2006). The European theme is continued by our inclusion of a special session showcasing some of the large-scale research and development projects in autonomic systems being conducted across the continent, which we hope will act as a way to build trans-Atlantic (and indeed trans-Pacific) collaborations as we move on to tackle larger problems with autonomic systems. We have, of course, retained -- and indeed strengthened -- ICAC's focus on presenting strong papers on exciting science. This year we accepted 15 full papers from an exceptionally strong field of 97 reviewed full paper submissions. An additional 16 papers were accepted as short presentations and posters to highlight new ideas, and four industrial demonstrations of working tools that are finding industrial acceptance. We are delighted to welcome three keynote speakers from academia and industry, who have kindly given up their time to share their visions for the future of the area. We are equally delighted to host six satellite workshops covering a range of specialized topics including network management, cloud and green computing, all of which are increasingly critical in the modern enterprise world.},
address = {Barcelona, Spain},
editor = {Dobson, Simon and Strassner, John and Parashar, Manish and Shehory, Onn},
isbn = {978-1-60558-564-2},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {ACM},
title = {{Proceedings of the 6th International Conference on Autonomic Computing}},
year = {2009}
}
@article{dobson-et-al:taas06,
abstract = {Autonomic communications seek to improve the ability of network and services to cope with un- predicted change, including changes in topology, load, task, the physical and logical characteristics of the networks that can be accessed, and so forth. Broad-ranging autonomic solutions require designers to account for a range of end-to-end issues affecting programming models, network and contextual modeling and reasoning, decentralised algorithms, trust acquisition and maintenance— issues whose solutionsmay drawonapproaches and results from a surprisingly broad range of disci- plines.We survey the current state of autonomic communications research and identify significant emerging trends and techniques.},
author = {Dobson, Simon and Zambonelli, Franco and Denazis, Spyros and Fern{\'{a}}ndez, Antonio and Ga{\"{i}}ti, Dominique and Gelenbe, Erol and Massacci, Fabio and Nixon, Paddy and Saffre, Fabrice and Schmidt, Nikita},
doi = {10.1145/1186778.1186782},
file = {:Users/vitor/Mendeley/Dobson et al. - 2006 - A Survey of Autonomic Communications.pdf:pdf},
issn = {15564665},
journal = {ACM Transactions on Autonomous and Adaptive Systems},
keywords = {algorithms,autonomic communication,bibtex,design,management,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {dec},
number = {2},
pages = {223--259},
publisher = {ACM},
title = {{A Survey of Autonomic Communications}},
url = {http://portal.acm.org/citation.cfm?doid=1186778.1186782},
volume = {1},
year = {2006}
}
@book{doyle-et-al:book92,
abstract = {An excellent introduction to feedback control system design, this book offers a theoretical approach that captures the essential issues and can be applied to a wide range of practical problems. Its explorations of recent developments in the field emphasize the relationship of new procedures to classical control theory. 1992 edition.},
author = {Doyle, John C. and Francis, Bruce A. and Tannenbaum, Allen R.},
file = {:Users/vitor/Mendeley/Doyle, Francis, Tannenbaum - 1992 - Feedback Control Theory.pdf:pdf},
isbn = {978-0023300110},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Macmillan Coll Div},
title = {{Feedback Control Theory}},
url = {http://www.amazon.com/Feedback-Control-Theory-John-Doyle/dp/0023300116},
year = {1992}
}
@inproceedings{duan:iciecs09,
abstract = {The main problem of enterprise application evolution is how to capture requirements and then propagate requirement changes to application. Effectively evolving enterprise application with the frequently changing requirements is still a challenge to software engineering. Requirement is the root causes of evolution of enterprise applications in many cases. Refactoring has given guidance to gradual evolution of object-oriented software. This paper presents a tool - Revolution2 - for designer to evolve enterprise applications. The tool is implemented based on a requirement-driven approach which uses refined use cases to capture the requirements and changes, and propagates the changes through refactoring mappings between requirements and models. The tool helps to effectively maintain model and other parts of the application, which smoothes the evolution process of enterprise applications.},
address = {Wuhan, China},
author = {Duan, Jinan},
booktitle = {Proc. of the 2009 International Conference on Information Engineering and Computer Science},
doi = {10.1109/ICIECS.2009.5365837},
file = {:Users/vitor/Mendeley/Duan - 2009 - Revolution2 A Tool for Enterprise Application Evolution Based on Requirement-Driven Approach.pdf:pdf},
isbn = {978-1-4244-4994-1},
keywords = {bibtex,enterprise application,evolution tool,not-commented,refactoring,refined use cases},
mendeley-tags = {bibtex,not-commented},
month = {dec},
pages = {1--4},
publisher = {IEEE},
title = {{Revolution2: A Tool for Enterprise Application Evolution Based on Requirement-Driven Approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5365837},
year = {2009}
}
@techreport{duarte-pg14,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Duarte, Bruno B.},
file = {:Users/vitor/Mendeley/Duarte - 2014 - Aplica{\c{c}}{\~{a}}o do M{\'{e}}todo FrameWeb no Desenvolvimento de um Sistema de Informa{\c{c}}{\~{a}}o na Plataforma Java EE 7.pdf:pdf},
institution = {Projeto de Gradua{\c{c}}{\~{a}}o, Departamento de Inform{\'{a}}tica, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{Aplica{\c{c}}{\~{a}}o do M{\'{e}}todo FrameWeb no Desenvolvimento de um Sistema de Informa{\c{c}}{\~{a}}o na Plataforma Java EE 7}},
year = {2014}
}
@inproceedings{duarte-et-al:fois16,
abstract = {The use of Requirements at Runtime (RRT) is an emerging research area. Many methodologies and frameworks that make use of requirements models during the execution of software can be found in the literature, but very few of them use ontologies to ground the models that are used at runtime. In this paper, we introduce the Runtime Requirements Ontology (RRO), a domain ontology that intends to represent the nature and context of RRT. Following a well-known Ontology Engineering method, we evaluate RRO using verification and validation techniques.},
address = {Annecy, France},
author = {Duarte, Bruno B. and Souza, V{\'{i}}tor E. S. and Leal, Andr{\'{e}} Luiz de C. and Falbo, Ricardo A. and Guizzardi, Giancarlo and Guizzardi, Renata S. S.},
booktitle = {Proc. of the 9th International Conference on Formal Ontology in Information Systems},
doi = {10.3233/978-1-61499-660-6-255},
file = {:Users/vitor/Mendeley/Duarte et al. - 2016 - Towards an Ontology of Requirements at Runtime.pdf:pdf},
keywords = {bibtex,export,ontology,requirements,rro,runtime,ufo},
mendeley-tags = {bibtex,export},
month = {jul},
pages = {255--268},
publisher = {IOS Press},
title = {{Towards an Ontology of Requirements at Runtime}},
url = {http://ebooks.iospress.nl/volumearticle/44252},
volume = {283},
year = {2016}
}
@inproceedings{dwyer-et-al:icse99,
abstract = {Model checkers and other finite-state verification tools allow developers to detect certain kinds of errors automatically. Nevertheless, the transition of this technology from research to practice has been slow. While there are a number of potential causes for reluctance to adopt such formal methods, we believe that a primary cause is that practitioners are unfamiliar with specification processes, notations, and strategies. In a recent paper, we proposed a pattern-based approach to the presentation, codification and reuse of property specifications for finite-state verification. Since then, we have carried out a survey of available specifications, collecting over 500 examples of property specifications. We found that most are instances of our proposed patterns. Furthermore, we have updated our pattern system to accommodate new patterns and variations of existing patterns encountered in this survey. This paper reports the results of the survey and the current status of our pattern system.},
address = {Los Angeles, CA, USA},
author = {Dwyer, Matthew B. and Avrunin, George S. and Corbett, James C.},
booktitle = {Proc. of the 21st International Conference on Software Engineering},
doi = {10.1145/302405.302672},
file = {:Users/vitor/Mendeley/Dwyer, Avrunin, Corbett - 1999 - Patterns in Property Specifications for Finite-State Verification.pdf:pdf},
isbn = {1581130740},
keywords = {bibtex,concurrent systems,finite-state verification,formal specification,not-commented,patterns},
mendeley-tags = {bibtex,not-commented},
month = {may},
pages = {411--420},
publisher = {ACM},
title = {{Patterns in Property Specifications for Finite-State Verification}},
url = {http://dl.acm.org/citation.cfm?doid=302405.302672},
year = {1999}
}
@misc{easterbrook-aranda:tutorial06,
address = {Shanghai, China},
author = {Easterbrook, Steve and Aranda, Jorge},
file = {:Users/vitor/Mendeley/Easterbrook, Aranda - 2006 - Case Studies for Software Engineers, tutorial presented at the 28th International Conference on Software En.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{Case Studies for Software Engineers, tutorial presented at the 28th International Conference on Software Engineering}},
year = {2006}
}
@inproceedings{ebert-deman:icse05,
abstract = {Practically all industry studies on software project results conclude that good requirements engineering plays a pivotal role for successful projects. A key reason for project failures is insufficient management of changing requirements during all stages of the project life cycle. This article investigates one of the root causes for changing requirements, namely requirements uncertainty. In an experimental field study we looked into four underlying drivers for requirements uncertainty. We found several techniques must be used simultaneously to see tangible success. Using only one such technique in isolation doesn't make a difference. The field study is supported by extensive data from well over 200 projects stemming from very different business areas of Alcatel over a period of two years. Results are presented with practical experiences to allow effective transfer.},
address = {St. Louis, MO, USA},
author = {Ebert, Christof and {De Man}, Jozef},
booktitle = {Proc. of the 27th International Conference on Software Engineering},
doi = {10.1145/1062455.1062554},
file = {:Users/vitor/Mendeley/Ebert, De Man - 2005 - Requirements Uncertainty Influencing Factors and Concrete Improvements.pdf:pdf},
isbn = {1595939632},
keywords = {bibtex,commented,management,process improvement,product life cycle,product management,requirements engineering,requirements uncertainty},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {553--560},
publisher = {ACM},
title = {{Requirements Uncertainty: Influencing Factors and Concrete Improvements}},
url = {http://portal.acm.org/citation.cfm?doid=1062455.1062554},
year = {2005}
}
@inproceedings{elahi-yu:sac11,
abstract = {Simultaneously satisfying multiple interacting and possibly conflicting software requirements is challenging. Quantitative cost-benefit analysis of alternative solutions is often hard or biased, and early decisions based on numerical estimates of requirements satisfaction are thus unreliable. We propose a trade-off analysis method that assists decision making in the absence of numerical data. We structure the requirements trade-off problem in terms of a goal model containing alternative design solutions and decision criteria. We propose a trade-off analysis algorithm that takes pair-wise comparisons of alternatives and determines the best solution among alternatives. The optimum alternative is decided by using a heuristic method, which may need to consult with domain experts. We take advantage of the Even Swaps method [1] to incorporate stakeholders' preferences into the decision analysis. The algorithm is implemented in a prototype tool and evaluated in an industrial case study.},
address = {Taichung, Taiwan},
author = {Elahi, Golnaz and Yu, Eric S. K.},
booktitle = {Proc. of the 2011 ACM Symposium on Applied Computing},
doi = {10.1145/1982185.1982331},
file = {:Users/vitor/Mendeley/Elahi, Yu - 2011 - Requirements Trade-offs Analysis in the Absence of Quantitative Measures A Heuristic Method.pdf:pdf},
isbn = {9781450301138},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {mar},
pages = {651--658},
publisher = {ACM},
title = {{Requirements Trade-offs Analysis in the Absence of Quantitative Measures: A Heuristic Method}},
url = {http://portal.acm.org/citation.cfm?doid=1982185.1982331},
year = {2011}
}
@inproceedings{elkhordary-et-al:mrt09,
abstract = {In traditional software families, feature-orientation has been shown effective for bridging the semantic gap between a software system's requirements and its architecture. Over the past few years, the emergence of self-adaptive software systems, which are significantly more challenging to build than traditional systems, has gained the attention of the software engineering research community. In this paper, we show that using features at runtime could alleviate some of the key challenges of building such systems. The underlying insights are that: (1) features allow representation of the engineer's knowledge about some facets of the system that can be used to enhance the adaptation logic, and (2) features can serve as an abstraction to deal with the heterogeneity of the underlying architectural models, analytical algorithms, and implementation platforms. We describe the role of features in a self-adaptive framework that we have developed, entitled FeatUre-oriented Self-adaptatION (FUSION). We also report on our preliminary experience with FUSION that demonstrates the benefits of using features in different stages of self-adaptation.},
address = {Denver, CO, USA},
author = {Elkhodary, Ahmed and Malek, Sam and Esfahani, Naeem},
booktitle = {4th International Workshop on Models@run.time},
file = {:Users/vitor/Mendeley/Elkhodary, Malek, Esfahani - 2009 - On the Role of Features in Analyzing the Architecture of Self-Adaptive Software Systems.pdf:pdf},
keywords = {bibtex,commented,feature-oriented modeling,qos analysis,self-adaptive systems},
mendeley-tags = {bibtex,commented},
month = {oct},
title = {{On the Role of Features in Analyzing the Architecture of Self-Adaptive Software Systems}},
url = {http://www.comp.lancs.ac.uk/{\%}7Ebencomo/MRT09/modelsatruntime09{\_}Summary.pdf},
year = {2009}
}
@article{english-et-al:puc06,
abstract = {The requirement for spontaneous interaction in ubiquitous computing creates security issues over and above those present in other areas of computing, deeming traditional approaches ineﬀective. As a result, to support secure collaborations entities must implement self-protective measures. Trust management is a solution well suited to this task as reasoning about future interactions is based on the outcome of past ones. This requires monitoring of interactions as they take place. Such monitoring also allows us to take corrective action when interactions are proceeding unsatisfactorily. In this vein, we ﬁrst present a trust-based model of interaction based on event structures. We then describe our ongoing work in the development of a monitor architecture which enables self-protective actions to be carried out at critical points during principal interaction. Finally, we discuss some potential directions for future work.},
author = {English, Colin and Terzis, Sotirios and Nixon, Paddy},
doi = {10.1007/s00779-005-0030-y},
file = {:Users/vitor/Mendeley/English, Terzis, Nixon - 2006 - Towards self-protecting ubiquitous systems monitoring trust-based interactions.pdf:pdf},
issn = {1617-4909},
journal = {Personal and Ubiquitous Computing},
keywords = {bibtex,commented,interaction monitoring,self-protection,trust},
mendeley-tags = {bibtex,commented},
month = {feb},
number = {1},
pages = {50--54},
publisher = {Springer},
title = {{Towards self-protecting ubiquitous systems: monitoring trust-based interactions}},
url = {http://www.springerlink.com/content/r77124643176k187/},
volume = {10},
year = {2006}
}
@inproceedings{ernst-et-al:re11,
abstract = {This paper investigates aspects of the problem of software evolution resulting from top-level requirements change. In particular, while most research on design for software focuses on finding some correct solution, this ignores that such a solution is often only correct in a particular, and often short-lived, context. Using a logic-based goal-oriented requirements modeling language, the paper poses the problem of finding desirable solutions as the requirements change. Among other possible criteria of desirability, we consider minimizing the effort required to implement the new solution, which involves reusing parts of the old solution. In general, the solution of requirements problems is viewed as an exploration using a “requirements engineering knowledge base” (REKB), whose specification is formalized. The paper reports on experience implementing the REKB on top of a so-called “reason-maintenance system”, and provides evidence that incremental solution finding is indeed more efficient.},
address = {Trento, Italy},
author = {Ernst, Neil A. and Borgida, Alex and Jureta, Ivan J.},
booktitle = {Proc. of the 19th International Requirements Engineering Conference},
doi = {10.1109/RE.2011.6051656},
file = {:Users/vitor/Mendeley/Ernst, Borgida, Jureta - 2011 - Finding Incremental Solutions for Evolving Requirements.pdf:pdf},
isbn = {978-1-4577-0921-0},
keywords = {bibtex,commented,evolution,incremental,knowledge-level,requirements},
mendeley-tags = {bibtex,commented},
month = {aug},
pages = {15--24},
publisher = {IEEE},
title = {{Finding Incremental Solutions for Evolving Requirements}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6051656},
year = {2011}
}
@inproceedings{ernst-et-al:iwpseevol11,
abstract = {Changes to software should be made with reference to the requirements of that software, as these requirements provide the reasons for a change. Requirements serve to tie the implementation world of the developers to the problem world of the stakeholders. Most empirical studies of requirements have shown that misunderstood and changing requirements cause the majority of failures and costs in software. However, research in software evolution has typically focused on how to evolve software and not why. In our view, evolving software is about solving requirements problems, that is, finding new implementations which will satisfy the requirements while respecting domain assumptions. We argue that by describing this relationship, an implementation choice that best meets stakeholder needs can be made. We describe a tool that models requirements problems. This tool can find incremental solutions to evolving requirements problems quickly.},
address = {Szeged, Hungary},
author = {Ernst, Neil A. and Borgida, Alex and Mylopoulos, John},
booktitle = {Proc. of the 12th International Workshop on Principles of Software Evolution and the 7th annual ERCIM Workshop on Software Evolution},
doi = {10.1145/2024445.2024450},
file = {:Users/vitor/Mendeley/Ernst, Borgida, Mylopoulos - 2011 - Requirements Evolution Drives Software Evolution.pdf:pdf},
isbn = {9781450308489},
keywords = {bibtex,commented,goal-oriented modeling,requirements evolution,unanticipated change},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {16--20},
publisher = {ACM},
title = {{Requirements Evolution Drives Software Evolution}},
url = {http://dl.acm.org/citation.cfm?doid=2024445.2024450},
year = {2011}
}
@inproceedings{ernst-et-al:caise12,
address = {Gda{\'{n}}sk, Poland},
author = {Ernst, Neil A. and Borgida, Alex and Mylopoulos, John and Jureta, Ivan J.},
booktitle = {Proc. of the 24th International Conference on Advanced Information Systems Engineering (to appear)},
keywords = {bibtex,not-commented,to-appear},
mendeley-tags = {bibtex,not-commented,to-appear},
month = {jun},
title = {{Agile Requirements Evolution via Paraconsistent Reasoning}},
year = {2012}
}
@incollection{ernst-et-al:er10,
abstract = {Of particular concern in requirements engineering is the selection of requirements to implement in the next release of a system. To that end, there has been recent work on multi-objective optimization and user-driven prioritization to support the analysis of requirements trade-offs. Such work has focused on simple, linear models of requirements; in this paper, we work with large models of interacting requirements. We present techniques for selecting sets of solutions to a requirements problem consisting of mandatory and optional goals, with preferences among them. To find solutions, we use a modified version of the framework from Sebastiani et al.[1] to label our requirements goal models. For our framework to apply to a problem, no numeric valuations are necessary, as the language is qualitative. We conclude by introducing a local search technique for navigating the exponential solution space. The algorithm is scalable and approximates the results of a naive but intractable algorithm.},
annote = {10.1007/978-3-642-16373-9{\_}9},
author = {Ernst, Neil A. and Mylopoulos, John and Borgida, Alex and Jureta, Ivan J.},
booktitle = {Conceptual Modeling -- ER 2010},
doi = {10.1007/978-3-642-16373-9_9},
editor = {Parsons, Jeffrey and Saeki, Motoshi and Shoval, Peretz and Woo, Carson and Wand, Yair},
file = {:Users/vitor/Mendeley/Ernst et al. - 2010 - Reasoning with Optional and Preferred Requirements.pdf:pdf},
isbn = {978-3-642-16372-2},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {118--131},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Reasoning with Optional and Preferred Requirements}},
url = {http://www.springerlink.com/content/74107416737x0h07/},
volume = {6412},
year = {2010}
}
@incollection{ernst-et-al:dretyp09,
abstract = {Requirements evolution is a research problem that has received little attention hitherto, but deserves much more. For systems to survive in a volatile world, where business needs, government regulations and computing platforms keep changing, software systems must evolve too in order to survive. We discuss the state-of-the-art for research on the topic, and predict some of the research problems that will need to be addressed in the next decade. We conclude with a concrete proposal for a run-time monitoring framework based on (requirements) goal models.},
author = {Ernst, Neil A. and Mylopoulos, John and Wang, Yiqiao},
booktitle = {Design Requirements Engineering: A Ten-Year Perspective},
doi = {10.1007/978-3-540-92966-6_11},
editor = {Lyytinen, Kalle and Loucopoulos, Pericles and Mylopoulos, John and Robinson, Bill},
file = {:Users/vitor/Mendeley/Ernst, Mylopoulos, Wang - 2009 - Requirements Evolution and What (Research) to Do about It.pdf:pdf},
keywords = {bibtex,evolution,monitoring,not-commented,requirements,satisfiability},
mendeley-tags = {bibtex,not-commented},
pages = {186--214},
publisher = {Springer},
title = {{Requirements Evolution and What (Research) to Do about It}},
url = {http://www.springerlink.com/content/gp82937763526545/},
year = {2009}
}
@inproceedings{falbo:ontocomodise14,
abstract = {his paper presents the new version of SABiO - a Systematic Ap- proach for Building Ontologies. SABiO focus on the development of domain ontologies, and also propose support processes. SABiO distinguishes between reference and operational ontologies, providing activities that apply to the de- velopment of both types of domain ontologies.},
address = {Rio de Janeiro, RJ, Brasil},
author = {Falbo, Ricardo A.},
booktitle = {Proc. of the Proceedings of the 1st Joint Workshop ONTO.COM / ODISE on Ontologies in Conceptual Modeling and Information Systems Engineering},
editor = {Guizzardi, Giancarlo and Pastor, Oscar and Wand, Yair and de Cesare, Sergio and Gailly, Frederik and Lycett, Mark and Partridge, Chris},
file = {:Users/vitor/Mendeley/Falbo - 2014 - SABiO Systematic Approach for Building Ontologies.pdf:pdf},
keywords = {bibtex,commented,domain ontology,ontology development,ontology engineering},
mendeley-tags = {bibtex,commented},
month = {sep},
publisher = {CEUR},
title = {{SABiO: Systematic Approach for Building Ontologies}},
url = {http://ceur-ws.org/Vol-1301/},
year = {2014}
}
@inproceedings{falbo-et-al:seke02,
abstract = {Domain engineering aims to support systematic reuse, focusing on modeling common knowledge in a problem domain. Ontologies have also been pointed as holding great promise for software reuse. In this paper, we present ODE (Ontology-based Domain Engineering), an ontological approach for domain engineering that aims to join ontologies and object-oriented technology.},
address = {Ischia, Italy},
author = {Falbo, Ricardo A. and Guizzardi, Giancarlo and Duarte, Katia C.},
booktitle = {Proc. of the 14th international conference on Software engineering and knowledge engineering},
doi = {10.1145/568760.568822},
file = {:Users/vitor/Mendeley/Falbo, Guizzardi, Duarte - 2002 - An ontological approach to domain engineering.pdf:pdf},
isbn = {1581135564},
keywords = {bibtex,ontology,software reuse},
mendeley-tags = {bibtex},
month = {jul},
pages = {351--358},
publisher = {ACM},
title = {{An ontological approach to domain engineering}},
url = {http://portal.acm.org/citation.cfm?doid=568760.568822},
year = {2002}
}
@inproceedings{favre:lemdsd05,
abstract = {Model Driven Engineering (MDE) received a lot of attention in the last years, both from academia and industry. However, there is still a debate on which basic concepts form the foundation of MDE. The Model Driven Architecture (MDA) from the OMG does not provided clear answers to this question. This standard instead provides a complex set of interdependent technologies. This paper is the first of a series aiming at defining the foundations of MDE independently from a particular technology. A megamodel is introduced in this paper and incrementally refined in further papers from the series. This paper is devoted to a single concept, the concept of model, and to a single relation, the RepresentationOf relation. The lack of strong foundations for the MDA 4-layers meta-pyramid leads to a common mockery: ``So, MDA is just about Egyptology?!''. This paper is the pilot of the series called ``From Ancient Egypt to Model Driven Engineering''. The various episodes of this series show that Egyptology is actually a good model to study MDE.},
address = {Dagstuhl, Germany},
annote = {Keywords: models, reverse engineering, transformations},
author = {Favre, Jean-Marie},
booktitle = {Language Engineering for Model-Driven Software Development},
editor = {Bezivin, Jean and Heckel, Reiko},
file = {:Users/vitor/Mendeley/Favre - 2005 - Foundations of Model (Driven) (Reverse) Engineering Models -- Episode I Stories of The Fidus Papyrus and of The Solarus.pdf:pdf},
issn = {1862-4405},
keywords = {bibtex},
mendeley-tags = {bibtex},
number = {04101},
publisher = {IBFI},
series = {Dagstuhl Seminar Proceedings},
title = {{Foundations of Model (Driven) (Reverse) Engineering : Models -- Episode I: Stories of The Fidus Papyrus and of The Solarus}},
url = {http://drops.dagstuhl.de/opus/volltexte/2005/13},
year = {2005}
}
@inproceedings{feather-et-al:iwssd98,
abstract = {This paper considers the problem of runtime system deviations from requirements speciﬁcations. Such deviations may arise from lack of anticipation of possible behaviors of environment agents at speciﬁcation time, or from evolving conditions in this environment. We discuss an architecture and a development process for monitoring system requirements at runtime to reconcile the requirements and the system's runtime behavior. This process is deployed on three scenarios of requirexXXments-execution reconciliation for the Meeting Scheduler system. The work builds on our previous work on goal-driven requirements engineering and on runtime requirements monitoring.},
address = {Ise-shima, Japan},
author = {Feather, M.S. and Fickas, Stephen and van Lamsweerde, Axel and Ponsard, Christophe},
booktitle = {Proc. of the 9th International Workshop on Software Specification and Design},
doi = {10.1109/IWSSD.1998.667919},
file = {:Users/vitor/Mendeley/Feather et al. - 1998 - Reconciling system requirements and runtime behavior.pdf:pdf},
isbn = {0-8186-8439-9},
keywords = {bibtex,deviation analysis,goal-driven requirements engineering,inconsistency management,obstacles,requirements monitoring,self-adapting systems,summarized,system customization,x-commented},
mendeley-tags = {bibtex,summarized,x-commented},
month = {apr},
pages = {50--59},
publisher = {IEEE},
title = {{Reconciling system requirements and runtime behavior}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=667919},
year = {1998}
}
@inproceedings{feng:fskd10,
abstract = {Knowledge discovery is the non-trivial process of identifying valid, novel, potentially useful and ultimately understandable patterns in data. The complicated computational environment with ultra-large-scale, heterogeneous, highly-dynamic, and semantic-implicit data in the 21st century puts forward new problems and challenges for traditional knowledge discovery. As a solution, Semantic Web and Cloud Computing addresses the problem of semantic interoperability and large-scale resources sharing, thus making it a proper environment for future's knowledge discovery and data mining. As a probing research, this paper aims to answer the question: “what is knowledge discovery in Semantic era”. We discuss the virtual organization of knowledge discovery in Semantic Era, and introduce five roles in this environment. Moreover, we emphasize four distinguishing characteristics of knowledge discovery in Semantic era: 1) the dynamic semantic extension and self-description of algorithm; 2) the semantic integration of heterogeneous data; 3) the enablement of high-level semantic reasoning and knowledge discovery; 4) the circular refinement of knowledge and semantics. Considering the approaching era of Semantic Web and Cloud Computing, the walking towards knowledge discovery in Semantic era could be expected.},
address = {Yantai, China},
author = {Feng, Yi},
booktitle = {Proc. of the 7th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD '10)},
doi = {10.1109/FSKD.2010.5569697},
file = {:Users/vitor/Mendeley/Feng - 2010 - Towards knowledge discovery in Semantic era.pdf:pdf},
isbn = {978-1-4244-5931-5},
keywords = {bibtex,cloud computing,commented,knowledge discovery,semantic web},
mendeley-tags = {bibtex,commented},
month = {aug},
pages = {2071--2075},
publisher = {IEEE},
title = {{Towards knowledge discovery in Semantic era}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5569697},
volume = {5},
year = {2010}
}
@inproceedings{ferrario-oltramari:ac2005,
abstract = {The main goal of this paper is a preliminary characterization of the categories of the realm of the mental, able to fit and integrate the foundational ontology DOLCE (a Descriptive Ontology for Linguistic and Cognitive Engineering); we call this module COM (Computational Ontology of Mind). The idea of COM emerges from the need of a conceptual clarification from the standpoint of formal ontology of the entities that play a role in agent technologies for information systems. Based on philosophical tradition, we have singled out a central relation in the realm of the mental: aboutness. In our proposal aboutness connects a mental state with a mental object, at a certain time, and with respect to a given intentional agent. Furthermore, we envisage a generalization of this framework to mental processes and events. Thus, in the paper we give a first analysis of these entities, mainly focused on mental objects and their characteristics. We are also specifying the basic features of mental states and intentional agents, exploiting ontological categories and relations implemented in DOLCE},
address = {Big Sky, MT, USA},
author = {Ferrario, Roberta and Oltramari, Alessandro},
booktitle = {Proc. of the 2005 IEEE Aerospace Conference},
doi = {10.1109/AERO.2005.1559636},
file = {:Users/vitor/Mendeley/Ferrario, Oltramari - 2005 - Towards a computational ontology of mind.pdf:pdf},
isbn = {0780388704},
issn = {1095323X},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {mar},
pages = {1--9},
publisher = {IEEE},
title = {{Towards a computational ontology of mind}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1559636{\&}tag=1},
volume = {2005},
year = {2005}
}
@inproceedings{ferro-et-al:wi08,
abstract = {Business Activity Monitoring (BAM) and Business Intelligence (BI) solutions are both intended to provide insight into the activities and performance of the enterprise. Deployment of such systems requires extensive tailoring to the enterprise, best left to experts. The dynamics of the enterprise demands a solution to the maintenance of BAM/BI solutions. This paper presents an Ontology-based BAM-Agent, called OBAMA that supports the maintenance of the system in light of changing business processes. Furthermore, for the formulation of aspects and properties to be monitored, it combines the expressive power of SQL, and TTL (a temporal trace language of first order logic). OBAMA helps in the preparation of regular assessment reports on the enterprise, taking into account key performance indicators as set by its operation manager. The paper describes the architecture, the combination of SQL, and TTL techniques for monitoring, and provides description of its kernel processes. OBAMA's performance in a surveillance company is presented.},
address = {Sydney, Australia},
author = {Ferro, Duco N. and Hoogendoorn, Mark and Jonker, Catholijn M.},
booktitle = {Proc. of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
doi = {10.1109/WIIAT.2008.140},
file = {:Users/vitor/Mendeley/Ferro, Hoogendoorn, Jonker - 2008 - Ontology-based Business Activity Monitoring Agent.pdf:pdf},
isbn = {978-0-7695-3496-1},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {dec},
pages = {491--495},
publisher = {IEEE},
title = {{Ontology-based Business Activity Monitoring Agent}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4740671},
year = {2008}
}
@inproceedings{fickas-feather:re95,
abstract = {We propose requirements monitoring to aid in the maintenance of systems that reside in dynamic environments. By requirements monitoring we mean the insertion of code into a running system to gather information from which it can he determined whether, and to what degree, that running system is meeting its requirements. Monitoring is a commonly applied technique in support of performance tuning, but the focus therein is primarily on computational performance requirements in short runs of systems. We wish to address systems that operate in a long lived, ongoing fashion in nonscientific enterprise applications. We argue that the results of requirements monitoring can be of benefit to the designers, maintainers and users of a system-alerting them when the system is being used in an environment for which it was not designed, and giving them the information they need to direct their redesign of the system. Studies of two commercial systems are used to illustrate and justify our claims.},
address = {York, UK},
author = {Fickas, Stephen and Feather, Martin S.},
booktitle = {Proc. of the 2nd IEEE International Symposium on Requirements Engineering},
doi = {10.1109/ISRE.1995.512555},
file = {:Users/vitor/Mendeley/Fickas, Feather - 1995 - Requirements Monitoring in Dynamic Environments(2).pdf:pdf},
isbn = {0-8186-7017-7},
keywords = {bibtex,summarized,x-commented},
mendeley-tags = {bibtex,summarized,x-commented},
month = {mar},
pages = {140--147},
publisher = {IEEE},
title = {{Requirements Monitoring in Dynamic Environments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=512555},
year = {1995}
}
@inproceedings{filieri-et-al:ase11,
abstract = {This paper investigates a novel approach to derive self-adaptive software by automatically modifying the model of the application using a control-theoretical approach. Self adaptation is achieved at the model level to assure that the model-which lives alongside the application at run-time- continues to satisfy its reliability requirements, despite changes in the environment that might lead to a violation. We assume that the model is given in terms of a Discrete Time Markov Chain (DTMC). DTMCs can express reliability concerns by modeling possible failures through transitions to failure states. Reliability requirements may be expressed as reachability properties that constrain the probability to reach certain states, denoted as failure states. We assume that DTMCs describe possible variant behaviors of the adaptive system through transitions exiting a given state that represent alternative choices, made according to certain probabilities. Viewed from a control-theory standpoint, these probabilities correspond to the input variables of a controlled system-i.e., in the control theory lexicon, "control variables". Adopting the same lexicon, such variables are continuously modified at run-time by a feedback controller so as to ensure continuous satisfaction of the requirements despite disturbances, i.e., changes in the environment. Changes at the model level may then be automatically transferred to changes in the running implementation. The approach is methodologically described by providing a translation scheme from DTMCs to discrete-time dynamic systems, the formalism in which the controllers are derived. An initial empirical assessment is described for a case study. Conjectures for extensions to other models and other requirements.},
address = {Lawrence, KS, USA},
author = {Filieri, Antonio and Ghezzi, Carlo and Leva, Alberto and Maggio, Martina},
booktitle = {Proc. of the 26th IEEE/ACM International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2011.6100064},
file = {:Users/vitor/Mendeley/Filieri et al. - 2011 - Self-Adaptive Software Meets Control Theory A Preliminary Approach Supporting Reliability Requirements.pdf:pdf},
isbn = {978-1-4577-1639-3},
keywords = {adaptive software,bibtex,commented,control theory,dynamics system,non-functional requirements,reliability,run-time verification},
mendeley-tags = {bibtex,commented},
month = {nov},
pages = {283--292},
publisher = {IEEE},
title = {{Self-Adaptive Software Meets Control Theory: A Preliminary Approach Supporting Reliability Requirements}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6100064},
year = {2011}
}
@inproceedings{filieri-et-al:seams12,
abstract = {We are concerned with software that can self-adapt to satisfy certain reliability requirements, in spite of adverse changes affecting the environment in which it is embedded. Self-adapting software architectures are heavily based on dynamic binding. The bindings among components are dynamically set as the conditions that require a self-adaptation are discovered during the system's lifetime. By adopting a suitable modeling approach, the dynamic binding problem can be formulated as a discrete-time feedback control problem, and solved with very simple techniques based on linear blocks. Doing so, reliability objectives are in turn formulated as set point tracking ones in the presence of disturbances, and attained without the need for optimization. At design time, the proposed formulation has the advantage of naturally providing system sizing clues, while at operation time, the inherent computational simplicity of the obtained controllers results in a low overhead. Finally, the formulation allows for a rigorous assessment of the achieved results in both nominal and off-design conditions for any desired operation point.},
address = {Zurich, Switzerland},
author = {Filieri, Antonio and Ghezzi, Carlo and Leva, Alberto and Maggio, Martina},
booktitle = {Proc. of the 7th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1109/SEAMS.2012.6224390},
file = {:Users/vitor/Mendeley/Filieri et al. - 2012 - Reliability-driven dynamic binding via feedback control.pdf:pdf},
isbn = {978-1-4673-1787-0},
keywords = {bibtex,commented,discrete-time feedback control,dynamic binding,reliability requirements,self-adaptive software},
mendeley-tags = {bibtex,commented},
month = {jun},
pages = {43--52},
publisher = {IEEE},
title = {{Reliability-driven dynamic binding via feedback control}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6224390},
year = {2012}
}
@techreport{finkelstein:report93,
address = {London, UK},
author = {Finkelstein, Anthony},
file = {:Users/vitor/Mendeley/Finkelstein - 1993 - Report of the inquiry into the London Ambulance Service (Electronic Version).pdf:pdf},
institution = {South West Thames Regional Health Authority},
isbn = {0-9051-3370-6},
keywords = {bibtex,x-commented},
mendeley-tags = {bibtex,x-commented},
title = {{Report of the inquiry into the London Ambulance Service (Electronic Version)}},
year = {1993}
}
@misc{finkelstein:website11,
author = {Finkelstein, Anthony},
file = {:Users/vitor/Mendeley/Finkelstein - Unknown - London Ambulance Service Computer Aided Despatch System, httpwww.cs.ucl.ac.ukstaffa.finkelsteinlas.html (last ac.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{London Ambulance Service Computer Aided Despatch System, http://www.cs.ucl.ac.uk/staff/a.finkelstein/las.html (last access: July 13th, 2011)}},
url = {http://www.cs.ucl.ac.uk/staff/a.finkelstein/las.html}
}
@inproceedings{finkelstein-dowell:iwssd96,
abstract = {This paper provides an introduction to the IWSSD-8 (8th International Workshop on Software Specification and Design) case study-the “Report of the Inquiry Into the London Ambulance Service”. The paper gives an overview of the case study and provides a brief summary. It considers how the case study can be used to orient discussion at the workshop and provide a bridge between the various contributions.},
address = {Schloss Velen, Germany},
author = {Finkelstein, Anthony and Dowell, John},
booktitle = {Proc. of the 8th International Workshop on Software Specification and Design},
doi = {10.1109/IWSSD.1996.501141},
file = {:Users/vitor/Mendeley/Finkelstein, Dowell - 1996 - A Comedy of Errors the London Ambulance Service case study.pdf:pdf},
isbn = {0-8186-7361-3},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {2--4},
publisher = {IEEE},
title = {{A Comedy of Errors: the London Ambulance Service case study}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=501141},
year = {1996}
}
@inproceedings{flake:seke04,
abstract = {The textual Object Constraint Language (OCL) is an official part of the Unified Modeling Language (UML). A new concept in the recently adopted OCL version 2.0 is the notion of OCL messages that enable modelers to put restrictions on messages sent. However, this concept shows some shortcomings with respect to the existing OCL language concepts. On the one hand, the proposed syntax does not quite conform to the established notation of OCL. On the other hand, the formal OCL semantics still lacks an integration of OCL messsages. This article reviews the syntax and semantics of OCL messages and presents a new approach to better integrate this concept with the rest of OCL 2.0.},
address = {Banff, Canada},
author = {Flake, Stephan},
booktitle = {Proc. of the 16th International Conference on Software Engineering and Knowledge Engineering},
file = {:Users/vitor/Mendeley/Flake - 2004 - Enhancing the Message Concept of the Object Constraint Language.pdf:pdf},
isbn = {1-891706-14-4},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {jun},
pages = {161--166},
title = {{Enhancing the Message Concept of the Object Constraint Language}},
url = {http://www.ksi.edu/seke/tocs/seke2004toc.pdf},
year = {2004}
}
@incollection{fleurey-et-al:mse09,
abstract = {This paper discusses preliminary work on modeling and validation dynamic adaptation. The proposed approach is on the use of aspect-oriented modeling (AOM) and models at runtime. Our approach covers design and runtime phases. At design-time, a base model and different variant architecture models are designed and the adaptation model is built. Crucially, the adaptation model includes invariant properties and constraints that allow the validation of the adaptation rules before execution. During runtime, the adaptation model is processed to produce a correct system configuration that can be executed.},
author = {Fleurey, Franck and Dehlen, Vegard and Bencomo, Nelly and Morin, Brice and J{\'{e}}z{\'{e}}quel, Jean-Marc},
booktitle = {Models in Software Engineering},
doi = {10.1007/978-3-642-01648-6_11},
isbn = {9783642016486},
keywords = {bibtex},
mendeley-tags = {bibtex},
pages = {97--108},
publisher = {Springer},
title = {{Modeling and Validating Dynamic Adaptation}},
url = {http://link.springer.com/10.1007/978-3-642-01648-6{\_}11},
year = {2009}
}
@techreport{fonseca-pg15,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Fonseca, Alexandre B.},
file = {:Users/vitor/Mendeley/Fonseca - 2015 - Programa de Designa{\c{c}}{\~{o}}es da Escola do Minist{\'{e}}rio Teocr{\'{a}}tico - PDEMT.pdf:pdf},
institution = {Projeto de Gradua{\c{c}}{\~{a}}o, Departamento de Inform{\'{a}}tica, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{Programa de Designa{\c{c}}{\~{o}}es da Escola do Minist{\'{e}}rio Teocr{\'{a}}tico - PDEMT}},
year = {2015}
}
@incollection{forbus:csh08,
abstract = {Qualitative reasoning is the area of AI which creates representations for continuous aspects of the world, such as space, time, and quantity, which support reasoning with very little information. Typically it has focused on scientific and engineering domains, hence its other name, qualitative physics. It is motivated by two observations. First, people draw useful and subtle conclusions about the physical world without differential equations. In our daily lives we figure out what is happening around us and how we can affect it, working with far less data, and less precise data, than would be required to use traditional, purely quantitative methods. Creating software for robots that operate in unconstrained environments and modeling human cognition requires understanding how this can be done. Second, scientists and engineers appear to use qualitative reasoning when initially understanding a problem, when setting up more formal methods to solve particular problems, and when interpreting the results of quantitative simulations, calculations, or measurements. Thus advances in qualitative physics should lead to the creation of more flexible software that can help engineers and scientists. Qualitative physics began with de Kleer's investigation on how qualitative and quantitative knowledge interacted in solving a subset of simple textbook mechanics problems [de Kleer, 1977]. After roughly a decade of initial explorations, the potential for important industrial applications led to a surge of interest in the mid-1980s, and the area has been growing steadily, with rapid progress. Qualitative representations have made their way into commercial supervisory control software for curing composite materials, and the first product known to have been designed using qualitative physics techniques appeared on the market in 1994 [Shimomura et al., 1995]. Given the strong potential for industrial applications that is only starting to be realized, and its potential importance in understanding human cognition, work in qualitative modeling is likely to remain an important area in Artificial Intelligence. This article first surveys the state of the art in qualitative representations and in qualitative reasoning techniques. The application of these techniques to various problems is discussed next.},
author = {Forbus, Kenneth D.},
booktitle = {Computer Science Handbook},
chapter = {62},
edition = {2nd},
file = {:Users/vitor/Mendeley/Forbus - 2004 - Qualitative Reasoning.pdf:pdf},
isbn = {9781584883609},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
pages = {62.1--62.19},
publisher = {Chapman and Hall/CRC},
title = {{Qualitative Reasoning}},
url = {http://www.crcpress.com/product/isbn/9781584883609},
year = {2004}
}
@incollection{foster-et-al:wesoa07,
abstract = {A self-managed system is both self-assembling and self-healing. Service-oriented Computing (SoC) architectures, such as a Web Services Architecture (WS-A)illustrate a highly distributed, potentially dynamic,domain for component configurations. We propose the use of component architecture ”modes” to facilitate the self-management of services within a SoC environment. A mode abstracts a set of services that are composed to complete a given task. Our approach, named ”SelfSoC” includes designing and implementing key parts of a self-managed system specifically aimed at supporting a dynamic services architecture. We extend Darwin component models, Alloy constraint models and distributed system management policies to specify the mode architectures. We also propose the generation of dynamic orchestrations for service compositions to coordinate different modes of an automotive services platform.},
address = {Vienna, Austria},
annote = {10.1007/978-3-540-93851-4{\_}34},
author = {Foster, Howard and Uchitel, Sebastian and Kramer, Jeff and Magee, Jeff},
booktitle = {Service-Oriented Computing - ICSOC 2007 Workshops},
doi = {10.1007/978-3-540-93851-4_34},
editor = {{Di Nitto}, Elisabetta and Ripeanu, Matei},
file = {:Users/vitor/Mendeley/Foster et al. - 2009 - Towards Self-management in Service-Oriented Computing with Modes.pdf:pdf},
isbn = {978-3-540-93850-7},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
pages = {338--350},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Towards Self-management in Service-Oriented Computing with Modes}},
url = {http://www.springerlink.com/content/n118494p41595800/},
volume = {4907},
year = {2009}
}
@inproceedings{fox-et-al:fudico04,
abstract = {It is by now motherhood-and-apple-pie that complex distributed Internet services form the basis not only of e-commerce but increasingly of mission-critical network-based applications. What is new is that the workload and internal architecture of three-tier enterprise applications presents a unique opportunity to use statistical approaches to anomaly detection and localization to keep these systems running. We propose three speciﬁc extensions to prior work in this area. First, we propose anomaly detection and pattern mining not only for time-based operational statistics such as response time, but also for structural behaviors of the system — what parts of the system, in what combinations, are being exercised in response to different kinds of external stimuli. Second, rather than building baseline models a priori, we extract them by observing the behavior of the system over a short period of time during normal operation. Third, we combine these detection and analysis techniques with low- cost, predictable control points that can be activated in response to a suspected-anomalous event; these control points are designed so that the cost of activating them is low enough to tolerate the inevitable false positives that result from the application of statistical techniques. We explain why the assumptions necessary for this to work can be addressed by new systems research, report on some early successes using the approach, describe beneﬁts of the approach that make it competitive as a path toward self-managing systems, and outline some research challenges.},
address = {Bertinoro, Italy},
author = {Fox, Armando and Kiciman, Emre and Patterson, David and Katz, Randy and Jordan, Michael and Stoica, Ion and Tygar, Doug},
booktitle = {Proc. of the 2nd Bertinoro Workshop on Future Directions in Distributed Computing},
file = {:Users/vitor/Mendeley/Fox et al. - 2004 - Statistical Monitoring Predictable Recovery = Self-.pdf:pdf},
keywords = {bibtex,not-commented,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
month = {jun},
title = {{Statistical Monitoring + Predictable Recovery = Self-*}},
url = {http://www.cs.utexas.edu/users/lorenzo/sos/program.html},
year = {2004}
}
@article{frakes-kang:tse05,
abstract = {This paper briefly summarizs software reuse research, discusses major research contributions and unsolved problems, provides pointers to key publications...},
author = {Frakes, William B. and Kang, Kyo},
doi = {10.1109/TSE.2005.85},
file = {:Users/vitor/Mendeley/Frakes, Kang - 2005 - Software reuse research Status and future.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Architectures,Domain engineering,Finance,Generators,Metrics,Research,Software reuse,bibtex},
mendeley-tags = {bibtex},
number = {7},
pages = {529--536},
publisher = {IEEE},
title = {{Software reuse research: Status and future}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1492369},
volume = {31},
year = {2005}
}
@inproceedings{fu-et-al:re12,
abstract = {Socio-technical systems consist of human, hardware and software components that work in tandem to fulfill stakeholder requirements. By their very nature, such systems operate under uncertainty as components fail, humans act in unpredictable ways, and the environment of the system changes. Self-repair refers to the ability of such systems to restore fulfillment of their requirements by relying on monitoring, reasoning, and diagnosing on the current state of individual requirements. Self-repair is complicated by the multi-agent nature of socio-technical systems, which demands that requirements monitoring and self-repair be done in a decentralized fashion. In this paper, we propose a stateful requirements monitoring approach by maintaining an instance of a state machine for each requirement, represented as a goal, with runtime monitoring and compensation capabilities. By managing the interactions between the state machines, our approach supports hierarchical goal reasoning in both upward and downward directions. We have implemented a customizable Java framework that supports experimentation by simulating a socio-technical system. Results from our experiments suggest effective and precise support for a wide range of self-repairing decisions in a socio-technical setting.},
address = {Chicago, IL, USA},
author = {Fu, Lingxiao and Peng, Xin and Yu, Yijun and Mylopoulos, John and Zhao, Wenyun},
booktitle = {Proc. of the 20th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2012.6345796},
file = {:Users/vitor/Mendeley/Fu et al. - 2012 - Stateful requirements monitoring for self-repairing socio-technical systems.pdf:pdf},
isbn = {978-1-4673-2785-5},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {sep},
pages = {121--130},
publisher = {IEEE},
title = {{Stateful requirements monitoring for self-repairing socio-technical systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6345796},
year = {2012}
}
@inproceedings{fu-et-al:icebe05,
abstract = {Business performance monitoring is to observe, analyze, and possibly control the execution of business operations. Often in the information technology implementation environment, dynamic events are generated to indicate the states of the business processes. These isolated and heterogeneous low-level events create needs for adaptation and standardization, before the events can be handled by a central mediation engine, which filters, sorts and correlates events into key performance indicators relating to business goals. In this paper, we propose an intelligent event adaptation mechanism for capturing, analyzing, enriching and transforming application- dependent IT-level events into a standard event format called the Common Base Event1. The resulting event adapter can capture and process low-level events and forward only business related events to the central mediation engine. We select the SAP system as a reference application, and illustrate the configuration issues between the application and its adapter. The architecture and functionality of the proposed event adaptation mechanism are explained with practical industry problems and scenarios.},
address = {Beijing, China},
author = {Fu, Shiwa S. and Chieu, Trieu C. and Yih, Jih-Shyr and Kumaran, Santhosh},
booktitle = {Proc. of the 2005 IEEE International Conference on e-Business Engineering},
doi = {10.1109/ICEBE.2005.29},
file = {:Users/vitor/Mendeley/Fu et al. - 2005 - An Intelligent Event Adaptation Mechanism for Business Performance Monitoring.pdf:pdf},
isbn = {0-7695-2430-3},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {oct},
pages = {558--563},
publisher = {IEEE},
title = {{An Intelligent Event Adaptation Mechanism for Business Performance Monitoring}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1552947},
year = {2005}
}
@article{ganek-corbi:ibm03,
abstract = {This issue of the IBM Systems Journal explores a broad set of ideas and approaches to autonomic computing—some ﬁrst steps in what we see as a journey to create more self- managing computing systems. Autonomic computing represents a collection and integration of technologies that enable the creation of an information technology computing infrastructure for IBM's agenda for the next era of computing— e-business on demand. This paper presents an overview of IBM's autonomic computing initiative. It examines the genesis of autonomic computing, the industry and marketplace drivers, the fundamental characteristics of autonomic systems, a framework for how systems will evolve to become more self- managing, and the key role for open industry standards needed to support autonomic behavior in heterogeneous system environments. Technologies explored in each of the papers presented in this issue are introduced for the reader.},
address = {Riverton, NJ, USA},
author = {Ganek, Alan G. and Corbi, Thomas A.},
doi = {10.1147/sj.421.0005},
file = {:Users/vitor/Mendeley/Ganek, Corbi - 2003 - The dawning of the autonomic computing era.pdf:pdf},
issn = {0018-8670},
journal = {IBM Systems Journal},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
number = {1},
pages = {5--18},
publisher = {IBM},
title = {{The dawning of the autonomic computing era}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5386835},
volume = {42},
year = {2003}
}
@article{gangemi-et-al:ai2003,
abstract = {Despite its original intended use, which was very different, WORDNET is used more and more today as an ontology, where the hyponym relation between word senses is interpreted as a subsumption relation between concepts. In this article, we discuss the general problems related to the semantic interpretation of WORDNET taxonomy in light of rigorous ontological principles inspired by the philosophical tradition. Then we introduce the DOLCE upper-level ontology, which is inspired by such principles but with a clear orientation toward language and cognition. We report the results of an experimental effort to align WORDNET'S upper level with DOLCE. We suggest that such alignment could lead to an "ontologically sweetened" WORD-NET, meant to be conceptually more rigorous, cognitively transparent, and efficiently exploitable in several applications.},
author = {Gangemi, Aldo and Guarino, Nicola and Masolo, Claudio and Oltramari, Alessandro},
doi = {10.1007/3-540-45810-7},
isbn = {978-3-540-44268-4},
issn = {0738-4602},
journal = {AI Magazine},
keywords = {bibtex},
mendeley-tags = {bibtex},
number = {3},
pages = {13--24},
publisher = {ACM},
title = {{Sweetening WordNet with DOLCE}},
url = {http://portal.acm.org/citation.cfm?id=958671.958673},
volume = {24},
year = {2003}
}
@article{garciamolina-salem:comad87,
abstract = {Long lived transactions (LLTs) hold on to database resources for relatively long periods of time, significantly delaying the termination of shorter and more common transactions. To alleviate these problems we propose the notion of a saga. A LLT is a saga if it can be written as a sequence of transactions that can be interleaved with other transactions. The database management system guarantees that either all the transactions in a saga are successfully completed or compensating transactions are run to amend a partial execution. Both the concept of saga and its implementation are relatively simple, but they have the potential to improve performance significantly. We analyze the various implementation issues related to sagas, including how they can be run on an existing system that does not directly support them. We also discuss techniques for database and LLT design that make it feasible to break up LLTs into sagas.},
author = {Garcia-Molina, Hector and Salem, Kenneth},
doi = {10.1145/38714.38742},
file = {:Users/vitor/Mendeley/Garcia-Molina, Salem - 1987 - Sagas.pdf:pdf},
issn = {01635808},
journal = {ACM SIGMOD Record},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {dec},
number = {3},
pages = {249--259},
publisher = {ACM},
title = {{Sagas}},
url = {http://portal.acm.org/citation.cfm?doid=38714.38742},
volume = {16},
year = {1987}
}
@article{garlan-et-al:computer04,
abstract = {While attractive in principle, architecture-based self-adaptation raises a number of research and engineering challenges. First, the ability to handle a wide variety of systems must be addressed. Second, the need to reduce costs in adding external control to a system must be addressed. Our rainbow framework attempts to address both problems. By adopting an architecture-based approach, it provides reusable infrastructure together with mechanisms for specializing that infrastructure to the needs of specific systems. The specialization mechanisms let the developer of self-adaptation capabilities choose what aspects of the system to model and monitor, what conditions should trigger adaptation, and how to adapt the system.},
author = {Garlan, David and Cheng, Shang-Wen and Huang, An-Cheng and Schmerl, Bradley and Steenkiste, Peter},
doi = {10.1109/MC.2004.175},
file = {:Users/vitor/Mendeley/Garlan et al. - 2004 - Rainbow Architecture-Based Self-Adaptation with Reusable Infrastructure.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
keywords = {bibtex,commented,highlight},
mendeley-tags = {bibtex,commented,highlight},
month = {oct},
number = {10},
pages = {46--54},
publisher = {IEEE},
title = {{Rainbow: Architecture-Based Self-Adaptation with Reusable Infrastructure}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1350726},
volume = {37},
year = {2004}
}
@incollection{garlan-et-al:ads03,
abstract = {One increasingly important technique for improving system dependability is to provide mechanisms for a system to adapt at run time in order to accommodate varying resources, system errors, and changing requirements. For such “self-repairing” systems one of the hard problems is determining when a change is needed, and knowing what kind of adaptation is required. In this paper we describe a partial solution in which stylized architectural design models are maintained at run time as a vehicle for automatically monitoring system behavior, for detecting when that behavior falls outside of acceptable ranges, and for deciding on a high-level repair strategy. The main innovative feature of the approach is the ability to specialize a generic run time adaptation framework to support particular architectural styles and properties of interest. Specifically, a formal description of an architectural style defines for a family of related systems the conditions under which adaptation should be considered, provides an analytic basis for detecting anomalies, and serves as a basis for developing sound repair strategies.},
annote = {10.1007/3-540-45177-3{\_}3},
author = {Garlan, David and Cheng, Shang-Wen and Schmerl, Bradley},
booktitle = {Architecting Dependable Systems},
doi = {10.1007/3-540-45177-3_3},
editor = {de Lemos, Rog{\'{e}}rio and Gacek, Cristina and Romanovsky, Alexander},
file = {:Users/vitor/Mendeley/Garlan, Cheng, Schmerl - 2003 - Increasing System Dependability through Architecture-Based Self-Repair.pdf:pdf},
isbn = {978-3-540-40727-0},
keywords = {bibtex,commented,highlight},
mendeley-tags = {bibtex,commented,highlight},
pages = {61--89},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Increasing System Dependability through Architecture-Based Self-Repair}},
url = {http://www.springerlink.com/content/ex14v412t672v376/},
volume = {2677},
year = {2003}
}
@article{garlan-et-al:pc02,
abstract = {The most precious resource in a computer system is no longer its processor, memory, disk, or network, but rather human attention. Aura aims to minimize distractions on a user's attention, creating an environment that adapts to the user's context and needs. Aura is specifically intended for pervasive computing environments involving wireless communication, wearable or handheld computers, and smart spaces. Human attention is an especially scarce resource in such environments, because the user is often preoccupied with walking, driving, or other real-world interactions. In addition, mobile computing poses difficult challenges such as intermittent and variable-bandwidth connectivity, concern for battery life, and the client resource constraints that weight and size considerations impose. To accomplish its ambitious goals, research in Aura spans every system level: from the hardware, through the operating system, to applications and end users. Underlying this diversity of concerns, Aura applies two broad concepts. First, it uses proactivity, which is a system layer's ability to anticipate requests from a higher layer. In today's systems, each layer merely reacts to the layer above it. Second, Aura is self-tuning: layers adapt by observing the demands made on them and adjusting their performance and resource usage characteristics accordingly. Currently, system-layer behavior is relatively static. Both of these techniques will help lower demand for human attention.},
author = {Garlan, David and Siewiorek, Dan P. and Smailagic, Asim and Steenkiste, Peter},
doi = {10.1109/MPRV.2002.1012334},
issn = {1536-1268},
journal = {IEEE Pervasive Computing},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {apr},
number = {2},
pages = {22--31},
publisher = {IEEE},
title = {{Project Aura: toward distraction-free pervasive computing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1012334},
volume = {1},
year = {2002}
}
@incollection{gat:aimr98,
author = {Gat, Erann},
booktitle = {Artificial Intelligence and Mobile Robots},
editor = {Kortenkamp, David and Bonasso, R. Peter and Murphy, Robin},
file = {:Users/vitor/Mendeley/Gat - 1998 - On Three-Layer Architectures.pdf:pdf},
isbn = {978-0-262-61137-4},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
pages = {195--210},
publisher = {MIT Press},
title = {{On Three-Layer Architectures}},
url = {http://mitpress.mit.edu/catalog/item/default.asp?tid=7163{\&}ttype=2},
year = {1998}
}
@article{gellmann:es88,
author = {Gell-Mann, Murray},
file = {:Users/vitor/Mendeley/Gell-Mann - 1988 - Simplicity and Complexity in the Description of Nature.pdf:pdf},
journal = {Engineering and Science},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
number = {3},
pages = {2--9},
publisher = {California Institute of Technology},
title = {{Simplicity and Complexity in the Description of Nature}},
volume = {57},
year = {1988}
}
@inproceedings{georgiadis-et-al:woss02,
abstract = {A self-organising software architecture is one in which components automatically configure their interaction in a way that is compatible with an overall architectural specification. The objective is to minimise the degree of explicit management necessary for construction and subsequent evolution whilst preserving the architectural properties implied by its specification. This paper examines the feasibility of using architectural constraints as the basis for the specification, design and implementation of self-organising architectures for distributed systems. Although we focus on organising the structure of systems, we show how component state can influence reconfiguration via interface attributes.},
address = {Charleston, SC, USA},
author = {Georgiadis, Ioannis and Magee, Jeff and Kramer, Jeff},
booktitle = {Proc. of the 1st Workshop on Self-healing Systems},
doi = {10.1145/582128.582135},
file = {:Users/vitor/Mendeley/Georgiadis, Magee, Kramer - 2002 - Self-Organising Software Architectures for Distributed Systems.pdf:pdf},
isbn = {1581136099},
keywords = {bibtex,commented,constraints,self-configuring,software architecture,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {nov},
pages = {33--38},
publisher = {ACM},
title = {{Self-Organising Software Architectures for Distributed Systems}},
url = {http://dl.acm.org/citation.cfm?id=582135},
year = {2002}
}
@inproceedings{georgiadis-et-al:woss02,
abstract = {A self-organising software architecture is one in which components automatically configure their interaction in a way that is compatible with an overall architectural specification. The objective is to minimise the degree of explicit management necessary for construction and subsequent evolution whilst preserving the architectural properties implied by its specification. This paper examines the feasibility of using architectural constraints as the basis for the specification, design and implementation of self-organising architectures for distributed systems. Although we focus on organising the structure of systems, we show how component state can influence reconfiguration via interface attributes.},
address = {Charleston, SC, USA},
author = {Georgiadis, Ioannis and Magee, Jeff and Kramer, Jeff},
booktitle = {Proc. of the 1st Workshop on Self-Healing Systems (WOSS '02)},
doi = {10.1145/582128.582135},
file = {:Users/vitor/Mendeley/Georgiadis, Magee, Kramer - 2002 - Self-organising software architectures for distributed systems(2).pdf:pdf},
isbn = {1581136099},
keywords = {bibtex,commented,constraints,self-configuring,software architecture},
mendeley-tags = {bibtex,commented},
month = {nov},
pages = {33--38},
publisher = {ACM},
title = {{Self-organising software architectures for distributed systems}},
url = {http://portal.acm.org/citation.cfm?doid=582128.582135},
year = {2002}
}
@article{gervasi-et-al:assen04,
abstract = {Requirements Engineering (RE) research is believed to be mature enough for the community to be able to make comparative evaluations of alternative tools, techniques, approaches and methods. Commonly used exemplars in RE that have emerged over the years all suffer from well-defined and widely accepted evaluation criteria which makes comparison of the effectiveness of different research outcomes impossible. The first International Workshop on Comparative Evaluation on Requirements Engineering was held in conjunction with the 11th IEEE International Requirements Engineering Conference in Monterey Bay, California. This workshop was conceived to address these issues and facilitate a community initiative in developing a common understanding of evaluation criteria and developing benchmarks for comparative evaluation in RE. Content, of course, is important.},
author = {Gervasi, Vincenzo and Zowghi, Didar and Easterbrook, Steve and Sim, Susan Elliott},
doi = {10.1145/979743.979751},
file = {:Users/vitor/Mendeley/Gervasi et al. - 2004 - Report on the First International Workshop on Comparative Evaluation in Requirements Engineering.pdf:pdf},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {benchmarking,bibtex,commented,evaluation,requirements},
mendeley-tags = {bibtex,commented},
month = {mar},
number = {2},
pages = {1--4},
publisher = {ACM},
title = {{Report on the First International Workshop on Comparative Evaluation in Requirements Engineering}},
url = {http://portal.acm.org/citation.cfm?doid=979743.979751},
volume = {29},
year = {2004}
}
@book{seams11,
abstract = {Aloha and Welcome to Hawaii and SEAMS-2011, the 6th International Symposium on Software Engineering for Adaptive and Self-Managing Systems, an ICSE co-located event. An increasingly important requirement for a software-based system is the ability to self-manage by adapting itself at run time to handle changing user needs, system intrusions or faults, a changing operational environment, and resource variability. Such a system must configure and reconfigure itself, augment its functionality, continually optimize itself, protect itself, and recover itself, while keeping its complexity hidden from the user. The topic of self-adaptive and self-managing systems has been studied in a large number of specific areas, including software architectures, fault-tolerant computing, robotics, control systems, programming languages, and biologically-inspired computing. The objective of this symposium is to bring together researchers and practitioners from many of these diverse areas to engage in stimulating dialogue regarding the fundamental principles, state of the art, and critical challenges of self-adaptive systems. Specifically, the symposium focuses on the software engineering aspects, including the methods, architectures, algorithms, techniques, and tools that can be used to support dynamic adaptive behavior that includes self-adaptive, self-managing, self-healing, self-optimizing, and self-configuring, and autonomic software. While this year is the first for SEAMS as a symposium, the SEAMS community has been steadily growing for the past 6 years, originally starting as an ICSE Workshop. It is particularly noteworthy that SEAMS has continued to attract and retain researchers and practitioners from a variety of adaptive systems-related areas, including interesting application areas that pose wonderful research challenges for the community. We received 77 submissions, where 21 full papers and 5 position papers were accepted for inclusion in the symposium. Each paper was reviewed by at least 3 program committee members. In short, the quality of the submissions was quite high, with a tough selection process, all of which have yielded a high-quality program. This year we have a program that illustrates on the one hand, the maturity of the field with sessions on programming language, modeling, and framework support for the development of adaptive systems, while on the other hand, we are clearly making significant advances in techniques that provide true run-time support for adaptive activities, such as monitoring, automatic reconfiguration, and service composition. We also have a great collection of position papers that describe exciting and promising work for the adaptive systems area. As adaptive systems become more prevalent, particularly in high-assurance applications, the need for explicitly addressing assurance in adaptive systems becomes paramount. It has become clear that many of the traditional software engineering techniques cannot be directly applied to adaptive systems due to the added level of complexity posed by the run-time requirements. As such, this year, we have a special focus on Assurance for Adaptive Systems. We launch this focus with a keynote by Professor Carlo Ghezzi (Politecnico di Milano) who will share his work and vision in this area. We follow it by a paper session comprising several papers that describe assurance techniques ranging from testing to model-driven techniques. Finally, Professor David Garlan (Carnegie Mellon University) will moderate a session comprising several researchers working on assurance for adaptive systems who will provide insight to the research challenges in this area and a preview of promising future directions.},
address = {Honolulu, HI, USA},
editor = {Giese, Holger and Cheng, Betty H. C.},
isbn = {978-1-4503-0575-4},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {ACM},
title = {{Proceedings of the 6th International Symposium on Software Engineering for Adaptive and Self-Managing Systems}},
url = {http://dl.acm.org/citation.cfm?id=1988008},
year = {2011}
}
@incollection{giorgini-et-al:er02,
abstract = {Over the past decade, goal models have been used in Computer Science in order to represent software requirements, business objectives and design qualities. Such models extend traditional AI planning techniques for representing goals by allowing for partially defined and possibly inconsistent goals. This paper presents a formal framework for reasoning with such goal models. In particular, the paper proposes a qualitative and a numerical axiomatization for goal modeling primitives and introduces label propagation algorithms that are shown to be sound and complete with respect to their respective axiomatizations. In addition, the paper reports on preliminary experimental results on the propagation algorithms applied to a goal model for a US car manufacturer.},
annote = {10.1007/3-540-45816-6{\_}22},
author = {Giorgini, Paolo and Mylopoulos, John and Nicchiarelli, Eleonora and Sebastiani, Roberto},
booktitle = {Conceptual Modeling -- ER 2002},
doi = {10.1007/3-540-45816-6_22},
editor = {Spaccapietra, Stefano and March, Salvatore and Kambayashi, Yahiko},
file = {:Users/vitor/Mendeley/Giorgini et al. - 2003 - Reasoning with Goal Models.pdf:pdf},
isbn = {978-3-540-44277-6},
keywords = {bibtex,x-commented},
mendeley-tags = {bibtex,x-commented},
pages = {167--181},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Reasoning with Goal Models}},
url = {http://www.springerlink.com/content/qhqmunbl100y6upm/},
volume = {2503},
year = {2003}
}
@article{giorgini-et-al:eaai05,
abstract = {Tropos is an agent-oriented software methodology proposed in (J. Autonomous Agents Multi-Agent Syst. 8(3) (2004) 203; Inf. Syst. 27(6) (2002) 365). The methodology is founded on the notions of agent and goal, and goal analysis is used extensively to support software development during different phases. This paper adopts a formal goal model defined and analyzed in (J. Data Semantics 1 (2003); Proceedings of the International Conference on Advanced Information Systems Engineering, CAISE'04, vol. 3804 of LNCS, Springer, Berlin, 2004, pp. 20–33) to make the goal analysis process concrete through the use of forward and backward reasoning for goal models. The formal goal analysis is illustrated through examples, using an implemented goal reasoning tool.},
author = {Giorgini, Paolo and Mylopoulos, John and Sebastiani, Roberto},
doi = {10.1016/j.engappai.2004.11.017},
file = {:Users/vitor/Mendeley/Giorgini, Mylopoulos, Sebastiani - 2005 - Goal-oriented requirements analysis and reasoning in the Tropos methodology.pdf:pdf},
issn = {09521976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {mar},
number = {2},
pages = {159--171},
publisher = {Elsevier},
title = {{Goal-oriented requirements analysis and reasoning in the Tropos methodology}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0952197604001885},
volume = {18},
year = {2005}
}
@inproceedings{giorgini-et-al:dolap05,
abstract = {Several surveys indicate that a significant percentage of data warehouses fail to meet business objectives or are outright failures. One of the reasons for this is that requirement analysis is typically overlooked in real projects. In this paper we propose a goal-oriented approach to requirement analysis for data warehouses, based on the Tropos methodology. Two different perspectives are integrated for requirement analysis: organizational modeling, centered on stakeholders, and decisional modeling, focused on decision makers. Our approach can be employed within both a demand-driven and a mixed supply/demand-driven design framework: in the second case, while the operational sources are still explored to shape hierarchies, user requirements play a fundamental role in restricting the area of interest for analysis and in choosing facts, dimensions, and measures. The methodology proposed, supported by a prototype, is described with reference to a real case study.},
address = {Bremen, Germany},
author = {Giorgini, Paolo and Rizzi, Stefano and Garzetti, Maddalena},
booktitle = {Proc. of the 8th ACM International Workshop on Data Warehousing and OLAP},
doi = {10.1145/1097002.1097011},
file = {:Users/vitor/Mendeley/Giorgini, Rizzi, Garzetti - 2005 - Goal-Oriented Requirement Analysis for Data Warehouse Design.pdf:pdf},
isbn = {1595931627},
keywords = {bibtex,data warehouse design,not-commented,requirement analysis},
mendeley-tags = {bibtex,not-commented},
month = {oct},
pages = {47--56},
publisher = {ACM},
title = {{Goal-Oriented Requirement Analysis for Data Warehouse Design}},
url = {http://portal.acm.org/citation.cfm?doid=1097002.1097011},
year = {2005}
}
@article{giorgini-et-al:dss08,
abstract = {Several surveys indicate that a significant percentage of data warehouses fail to meet business objectives or are outright failures. One of the reasons for this is that requirement analysis is typically overlooked in real projects. In this paper we propose GRAnD, a goal-oriented approach to requirement analysis for data warehouses based on the Tropos methodology. Two different perspectives are integrated for requirement analysis: organizational modeling, centered on stakeholders, and decisional modeling, focused on decision makers. Our approach can be employed within both a demand-driven and a mixed supply/demand-driven design framework.},
author = {Giorgini, Paolo and Rizzi, Stefano and Garzetti, Maddalena},
doi = {10.1016/j.dss.2006.12.001},
file = {:Users/vitor/Mendeley/Giorgini, Rizzi, Garzetti - 2008 - GRAnD A goal-oriented approach to requirement analysis in data warehouses.pdf:pdf},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {apr},
number = {1},
pages = {4--21},
publisher = {Elsevier},
title = {{GRAnD: A goal-oriented approach to requirement analysis in data warehouses}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167923606002053},
volume = {45},
year = {2008}
}
@article{giunchiglia-et-al:aose03,
abstract = {Tropos is a novel agent-oriented software development metho- dology founded on two key features: (i) the notions of agent, goal, plan and various other knowledge level concepts are fundamental primitives used uniformly throughout the soft- ware development process; and (ii) a crucial role is assigned to requirements analysis and speci cation when the system- to-be is analyzed with respect to its intended environment. This paper provides a ( rst) detailed account of the Tropos methodology. In particular, we describe the basic concepts on which Tropos is founded and the types of models one builds out of them. We also specify the analysis process through which design ows from external to system actors through a goal analysis and delegation. In addition, we pro- vide an abstract syntax for Tropos diagrams and other lin- guistic constructs.},
address = {Berlin},
author = {Giunchiglia, Fausto and Mylopoulos, John and Perini, Anna},
chapter = {13},
doi = {10.1007/3-540-36540-0_13},
editor = {Giunchiglia, Fausto and Odell, James and Wei{\ss}, Gerhard},
file = {:Users/vitor/Mendeley/Giunchiglia, Mylopoulos, Perini - 2003 - The Tropos Software Development Methodology Processes, Models and Diagrams.pdf:pdf},
journal = {Agent-Oriented Software Engineering III},
keywords = {bibtex,x-commented},
mendeley-tags = {bibtex,x-commented},
pages = {162--173},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{The Tropos Software Development Methodology: Processes, Models and Diagrams}},
url = {http://www.springerlink.com/index/10.1007/3-540-36540-0{\_}13},
volume = {2585},
year = {2003}
}
@incollection{giunchiglia-et-al:jds07,
abstract = {We view match as an operator that takes two graph-like structures (e.g., classifications, XML schemas) and produces a mapping between the nodes of these graphs that correspond semantically to each other. Semantic matching is based on two ideas: (i) we discover mappings by computing semantic relations (e.g., equivalence, more general); (ii) we determine semantic relations by analyzing the meaning (concepts, not labels) which is codified in the elements and the structures of schemas. In this paper we present basic and optimized algorithms for semantic matching, and we discuss their implementation within the S-Match system. We evaluate S-Match against three state of the art matching systems, thereby justifying empirically the strength of our approach.},
author = {Giunchiglia, Fausto and Yatskevich, Mikalai and Shvaiko, Pavel},
booktitle = {Journal on Data Semantics IX},
doi = {10.1007/978-3-540-74987-5_1},
editor = {Spaccapietra, Stefano and Atzeni, Paolo and Fages, Fran{\c{c}}ois and Hacid, Mohand-Sa{\"{i}}d and Kifer, Michael and Mylopoulos, John and Pernici, Barbara and Shvaiko, Pavel and Trujillo, Juan and Zaihrayeu, Ilya},
file = {:Users/vitor/Mendeley/Giunchiglia, Yatskevich, Shvaiko - 2007 - Semantic Matching Algorithms and Implementation.pdf:pdf},
isbn = {9783540749820},
keywords = {bibtex,summarized},
mendeley-tags = {bibtex,summarized},
pages = {1--38},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Semantic Matching: Algorithms and Implementation}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-74987-5{\_}1},
volume = {4601},
year = {2007}
}
@phdthesis{glass:phdthesis11,
abstract = {Software systems are becoming increasingly complex. Common everyday applications like word processors and email clients often contain sophisticated algorithms for classifying inputs, suggesting improvements, adjusting to changing conditions, and predicting user intent. Even traditionally simple systems are increasingly adding adaptive components, in which the system learns and adapts its behavior over time. Despite this increasing sophistication, however, these systems typically provide little transparency into the computation and reasoning being performed. These complex systems are putting an increasing burden on end users to trust their reasoning and computation, but seldom provide the tools and interfaces necessary for building this trust. We investigate how context-sensitive explanatory information provided to users by adaptive systems can help to establish and build confidence in computational results and conclusions. We then describe the Integrated Cognitive Explanation Environment (ICEE), an explanation framework we designed and implemented that addresses the issues involved with interacting with adaptive systems. This framework provides a uniform approach for representing and explaining both provenance and inference information related to logical deduction, task processing, and machine learning. For this framework, there is particular emphasis on the information that systems need to provide in order to be considered "explainable." We also show how the framework can be used for a variety of computational tasks, using a single unified representation. Finally, we explore the implications of adaptive systems that support a complex context-sensitive explanation system. We focus primarily on how the use of explanations can be used to enhance machine learning in adaptive systems.},
author = {Glass, Alyssa},
file = {:Users/vitor/Mendeley/Glass - 2011 - Explanation of adaptive systems.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
school = {Stanford University},
title = {{Explanation of adaptive systems}},
url = {https://purl.stanford.edu/nw842xh8260},
year = {2011}
}
@inproceedings{goldsby-et-al:icac08,
abstract = {We describe an automated method to generating models of an autonomic system. Specifically, we generate UML state diagrams for a set of interacting objects, including the extension of existing state diagrams to support new behavior. The approach is based on digital evolution,a form of evolutionary computation that enables a designer to explore an enormous solution space for complex problems. In our application of this technology, an evolving population of digital organisms is subjected to natural selection, where organisms are rewarded for generating state diagrams that support key scenarios and satisfy critical properties as specified by the developer. To achieve this capability, we extended the AVIDA digital evolution platform to enable state diagram generation, and integrated AVIDA with third-party software engineering tools, e.g., the Spin model checker, to assess the generated state diagrams. To illustrate this approach, we successfully applied it to the generation of state diagrams describing the autonomous navigation behavior of a humanoid robot.},
address = {Chicago, IL, USA},
author = {Goldsby, Heather J. and Cheng, Betty H. C. and McKinley, Philip K. and Knoester, David B. and Ofria, Charles A.},
booktitle = {Proc. of the 2008 International Conference on Autonomic Computing},
doi = {10.1109/ICAC.2008.26},
file = {:Users/vitor/Mendeley/Goldsby et al. - 2008 - Digital Evolution of Behavioral Models for Autonomic Systems.pdf:pdf},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {jun},
pages = {87--96},
publisher = {IEEE},
title = {{Digital Evolution of Behavioral Models for Autonomic Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4550830},
year = {2008}
}
@inproceedings{goldsby-et-al:ecbs08,
abstract = {Self-adaptation is emerging as an increasingly important capability for many applications, particularly those deployed in dynamically changing environments, such as ecosystem monitoring and disaster management. One key challenge posed by dynamically adaptive systems (DASs) is the need to handle changes to the requirements and corresponding behavior of a DAS in response to varying environmental conditions. Berry et al. previously identified four levels of RE that should be performed for a DAS. In this paper, we propose the levels of RE for modeling that reify the original levels to describe RE modeling work done by DAS developers. Specifically, we identify four types of developers: the system developer, the adaptation scenario developer, the adaptation infrastructure developer, and the DAS research community. Each level corresponds to the work of a different type of developer to construct goal model(s) specifying their requirements. We then leverage the levels of RE for modeling to propose two complementary processes for performing RE for a DAS. We describe our experiences with applying this approach to GridStix, an adaptive flood warning system, deployed to monitor the River Ribble in Yorkshire, England.},
address = {Belfast, Northern Ireland},
author = {Goldsby, Heather J. and Sawyer, Pete and Bencomo, Nelly and Cheng, Betty H. C. and Hughes, Danny},
booktitle = {Proc. of the 15th Annual IEEE International Conference and Workshop on the Engineering of Computer Based Systems},
doi = {10.1109/ECBS.2008.22},
file = {:Users/vitor/Mendeley/Goldsby et al. - 2008 - Goal-Based Modeling of Dynamically Adaptive System Requirements.pdf:pdf},
isbn = {978-0-7695-3141-0},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {mar},
pages = {36--45},
publisher = {IEEE},
title = {{Goal-Based Modeling of Dynamically Adaptive System Requirements}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4492385},
year = {2008}
}
@inproceedings{gomaa-hashimoto:splc11,
abstract = {This paper describes a dynamic software adaptation approach and environment for service-oriented product lines. The approach uses a dynamic feature model and product line architecture for a family of service-oriented architectures (SOA), in which a member of the SOA can be dynamically adapted to a different member of the family at run-time. The approach integrates software product line and feature modeling concepts with SOA and dynamic software adaptation concepts. The approach is validated using a case study of a dynamic service-oriented product line.},
address = {Munich, Germany},
author = {Gomaa, Hassan and Hashimoto, Koji},
booktitle = {Proc. of the 15th International Software Product Line Conference (SPLC '11)},
doi = {10.1145/2019136.2019176},
file = {:Users/vitor/Mendeley/Gomaa, Hashimoto - 2011 - Dynamic software adaptation for service-oriented product lines.pdf:pdf},
isbn = {9781450307895},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {aug},
pages = {35},
publisher = {ACM},
title = {{Dynamic software adaptation for service-oriented product lines}},
url = {http://dl.acm.org/citation.cfm?doid=2019136.2019176},
year = {2011}
}
@inproceedings{gonzalez-baixauli-et-al:re04,
abstract = {One of the benefits of goal-oriented requirements engineering is the possibility of conducting formal analysis in order to evaluate alternative solutions of goal models. Superficially, goal analysis seems like an optimization technique. In contrast to such techniques, however, goal analysis does not aim at optimal solutions, but rather "good enough" ones (Simon, 1996). Moreover, goal analysis has to blend quantitative with qualitative techniques to account for subject matters that are not readily quantifiable. The analysis of the interplay of nonfunctional softgoals and functional goals at a high level of abstraction is an important element of goal analysis for the requirements engineer, especially so when dealing with requirements variability. This work proposes a visual variability analysis technique and describes an implemented tool that supports it.},
address = {Kyoto, Japan},
author = {Gonzalez-Baixauli, Bruno and {Sampaio do Prado Leite}, J.C. and Mylopoulos, John},
booktitle = {Proc. of the 12th IEEE International Requirements Engineering Conference},
doi = {10.1109/ICRE.2004.1335677},
file = {:Users/vitor/Mendeley/Gonzalez-Baixauli, Sampaio do Prado Leite, Mylopoulos - 2004 - Visual Variability Analysis for Goal Models.pdf:pdf},
isbn = {0-7695-2174-6},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {183--192},
publisher = {IEEE},
title = {{Visual Variability Analysis for Goal Models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1335677},
year = {2004}
}
@techreport{goodloe-pike:report10,
abstract = {Runtime monitors have been proposed as a means to increase the reliability of safety-critical systems. In particular, we explore runtime monitors for distributed hard real-time systems, such as fault-tolerant data buses and control systems for avionics and spacecraft. This class of systems has had little attention from the monitoring community. We motivate the need for monitors by discussing examples of avionic systems failure. We then describe work in the ﬁeld of runtime monitoring. We present potential monitoring architectures for distributed real-time systems, and then we discuss how those architectures might be used to monitor properties of real-time distributed systems.},
annote = {Available at $\backslash$url{\{}http://ntrs.nasa.gov/search.jsp?R=278742{\&}id=3{\&}as=false{\&}or=false{\&}qs=Ns{\%}3DArchiveName{\%}257c0{\%}26N{\%}3D4294643047{\}}},
author = {Goodloe, Alwyn and Pike, Lee},
file = {:Users/vitor/Mendeley/Goodloe, Pike - 2010 - Monitoring Distributed Real-Time Systems A Survey and Future Directions, Technical Report NASACR-2010-216724.pdf:pdf},
institution = {NASA Langley Research Center},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{Monitoring Distributed Real-Time Systems: A Survey and Future Directions, Technical Report NASA/CR-2010-216724}},
url = {https://www.cs.indiana.edu/{~}lepike/pub{\_}pages/monitors.html},
year = {2010}
}
@inproceedings{griss-et-al:icsr98,
abstract = {We have integrated the feature modeling of Feature-Oriented Domain Analysis (FODA) into the processes and work products of the Reuse-Driven Software Engineering Business (RSEB). The RSEB is a use case driven systematic reuse process: architecture and reusable subsystems are first described by use cases and then transformed into object models that are traceable to these use cases. Variability in the RSEB is captured by structuring use case and object models using explicit variation points and variants. Traditional domain engineering steps have been distributed into the steps of the architectural and component system development methods of the RSEB. But the RSEB prescribes no explicit models of the essential features that characterize the different versions. Building on our experience in applying FODA and RSEB to the telecom domain, we have added explicit domain engineering steps and an explicit feature model to the RSEB to support domain engineering and component reuse. These additions provide an effective reuse oriented model as a `catalog' capability to link use cases, variation points, reusable components and configured applications},
address = {Victoria, BC, Canada},
author = {Griss, Martin L. and Favaro, John and D'Alessandro, Massimo},
booktitle = {Proc. of the 5th International Conference on Software Reuse},
doi = {10.1109/ICSR.1998.685732},
file = {:Users/vitor/Mendeley/Griss, Favaro, D'Alessandro - 1998 - Integrating feature modeling with the RSEB.pdf:pdf},
isbn = {0-8186-8377-5},
keywords = {architecture,bibtex,domain engineering,foda,fodacom,not-commented,reuse,telecommunications,uml,use cases},
mendeley-tags = {bibtex,not-commented},
month = {jun},
pages = {76--85},
publisher = {IEEE},
title = {{Integrating feature modeling with the RSEB}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=685732},
year = {1998}
}
@inproceedings{gruninger-fox:wboiks95,
abstract = {This paper describes the methodology used in the Enterprise Integration Laboratory for the design and evaluation of integrated ontologies, including the proposal of new ontologies and the extension of existing ontologies (see Figure 1). We illustrate these ideas with examples from our activity and organisation ontologies.},
author = {Gr{\"{u}}ninger, Michael and Fox, Mark S.},
booktitle = {Workshop on Basic Ontological Issues in Knowledge Sharing},
file = {:Users/vitor/Mendeley/Gr{\"{u}}ninger, Fox - 1995 - Methodology for the Design and Evaluation of Ontologies.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {apr},
title = {{Methodology for the Design and Evaluation of Ontologies}},
url = {http://stl.mie.utoronto.ca/publications/gruninger-ijcai95.pdf},
year = {1995}
}
@inproceedings{guarino:fois98,
abstract = {Research on ontology is becoming increasingly widespread in the computer science community, and its importance is being recognized in a multiplicity of research fields and application areas, including knowledge engineering, database design and integration, information retrieval and extraction. We shall use the generic term “information systems”, in its broadest sense, to collectively refer to these application perspectives. We argue in this paper that so-called ontologies present their own methodological and architectural peculiarities: on the methodological side, their main peculiarity is the adoption of a highly interdisciplinary approach, while on the architectural side the most interesting aspect is the centrality of the role they can play in an information system, leading to the perspective of ontology-driven information systems.},
address = {Trento, Italy},
author = {Guarino, Nicola},
booktitle = {Proc. of the 1st International Conference on Formal Ontology in Information Systems (FOIS 98)},
file = {:Users/vitor/Mendeley/Guarino - 1998 - Formal Ontology in Information Systems.pdf:pdf},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {jun},
pages = {3--15},
publisher = {IOS Press},
title = {{Formal Ontology in Information Systems}},
url = {http://www.iospress.nl/book/formal-ontology-in-information-systems/},
year = {1998}
}
@incollection{guarino-et-al:hobook09,
abstract = {The word “ontology” is used with different senses in different communities. The most radical difference is perhaps between the philosophical sense, which has of course a well-established tradition, and the computational sense, which emerged in the recent years in the knowledge engineering community, starting from an early informal definition of (computational) ontologies as “explicit specifications of conceptualizations”. In this paper we shall revisit the previous attempts to clarify and formalize such original definition, providing a detailed account of the notions of conceptualization and explicit specification, while discussing at the same time the importance of shared explicit specifications.},
author = {Guarino, Nicola and Oberle, Daniel and Staab, Steffen},
booktitle = {Handbook on Ontologies},
edition = {2},
editor = {Staab, Steffen and Studer, Rudi},
file = {:Users/vitor/Mendeley/Guarino, Oberle, Staab - 2009 - What is an Ontology.pdf:pdf},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {1--17},
publisher = {Springer},
series = {International Handbooks on Information Systems},
title = {{What is an Ontology?}},
url = {http://www.springer.com/us/book/9783540709992},
year = {2009}
}
@incollection{guceglioglu-demirors:bpm05,
abstract = {Organizations frequently use product based organizational perf-ormance models to measure the effects of information system (IS) on their organizations. This paper introduces a complementary process based approach that is founded on measuring business process quality attributes. These quality attributes are defined on the basis of ISO/IEC 9126 Software Product Quality Model. The new process quality attributes are applied in an experiment and results are discussed in the paper.},
annote = {10.1007/11538394{\_}26},
author = {Guceglioglu, A. Selcuk and Demirors, Onur},
booktitle = {Business Process Management},
doi = {10.1007/11538394_26},
editor = {van der Aalst, Wil and Benatallah, Boualem and Casati, Fabio and Curbera, Francisco},
file = {:Users/vitor/Mendeley/Guceglioglu, Demirors - 2005 - Using Software Quality Characteristics to Measure Business Process Quality.pdf:pdf},
isbn = {978-3-540-28238-9},
keywords = {bibtex,not-commented,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
pages = {374--379},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Using Software Quality Characteristics to Measure Business Process Quality}},
url = {http://www.springerlink.com/content/3eyxyem9v9a814rp/},
volume = {3649},
year = {2005}
}
@phdthesis{guizzardi:phdthesis05,
author = {Guizzardi, Giancarlo},
file = {:Users/vitor/Mendeley/Guizzardi - 2005 - Ontological Foundations for Structural Conceptual Models.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
school = {University of Twente, The Netherlands},
title = {{Ontological Foundations for Structural Conceptual Models}},
type = {PhD Thesis},
url = {http://doc.utwente.nl/50826/},
year = {2005}
}
@inproceedings{guizzardi:cdis07,
abstract = {In philosophy, the term ontology has been used since the 17th century to refer both to a philosophical discipline (Ontology with a capital “O”), and as a domain-independent system of categories that can be used in the conceptualization of domain-specific scientific theories. In the past decades there has been a growing interest in the subject of ontology in computer and information sciences. In the last few years, this interest has expanded considerably in the context of the Semantic Web and MDA (Model-Driven Architecture) research efforts, and due to the role ontologies are perceived to play in these initiatives. In this paper, we explore the relations between Ontology and ontologies in the philosophical sense with domain ontologies in computer science. Moreover, we elaborate on formal characterizations for the notions of ontology, conceptualization and metamodel, as well as on the relations between these notions. Additionally, we discuss a set of criteria that a modeling language should meet in order to be considered a suitable language to model phenomena in a given domain, and present a systematic framework for language evaluation and design. Furthermore, we argue for the importance of ontology in both philosophical senses aforementioned for designing and evaluating a suitable general ontology representation language, and we address the question whether the so-called Ontology Web languages can be considered as suitable general ontology representation languages. Finally, we motivate the need for two complementary classes of modeling languages in Ontology Engineering addressing two separate sets of concerns.},
author = {Guizzardi, Giancarlo},
booktitle = {Proc. of the 2007 Conference on Databases and Information Systems},
file = {:Users/vitor/Mendeley/Guizzardi - 2007 - On Ontology, ontologies, Conceptualizations, Modeling Languages, and (Meta)Models.pdf:pdf},
keywords = {bibtex,commented,conceptual modeling,formal ontology,language adequacy,metamodeling},
mendeley-tags = {bibtex,commented},
publisher = {IOS Press},
title = {{On Ontology, ontologies, Conceptualizations, Modeling Languages, and (Meta)Models}},
url = {http://dl.acm.org/citation.cfm?id=1565425},
year = {2007}
}
@inproceedings{guizzardi-wagner:emoi04,
abstract = {oundational ontologies provide the basic concepts upon which any domain-specific ontology is built. This paper presents a new foundational ontology, UFO, and shows how it can be used as a guideline in business modeling and for evaluating business modeling methods. UFO is derived from a synthesis of two other foundational ontologies, GFO/GOL and OntoClean/DOLCE. While their main areas of application are natural sciences and linguistics/cognitive engineering, respectively, the main purpose of UFO is to provide a foundation for conceptual modeling, including business modeling.},
address = {Riga, Latvia},
author = {Guizzardi, Giancarlo and Wagner, Gerd},
booktitle = {Proc. of the 2004 Open InterOp Workshop on Enterprise Modelling and Ontologies for Interoperability},
editor = {Missikoff, Michele},
file = {:Users/vitor/Mendeley/Guizzardi, Wagner - 2004 - A Unified Foundational Ontology and some Applications of it in Business Modeling.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {jun},
publisher = {CEUR},
title = {{A Unified Foundational Ontology and some Applications of it in Business Modeling}},
url = {http://ceur-ws.org/Vol-125/},
year = {2004}
}
@inproceedings{guizzardi-et-al:caise04,
abstract = {UML class diagrams can be used as a language for expressing a conceptual model of a domain. In a series of papers [1,2,3] we have been using the General Ontological Language (GOL) and its underlying upper level ontology, proposed in [4,5], to evaluate the ontological correctness of a conceptual UML class model and to develop guidelines for how the constructs of the UML should be used in conceptual modeling. In this paper, we focus on the UML metaconcepts of classes and objects from an ontological point of view. We use a philosophically and psychologically well-founded theory of classifiers to propose a UML profile for Ontology Representation and Conceptual Modeling. Moreover, we propose a design pattern based on this profile to target a recurrent problem in role modeling discussed in the literature. Finally, we demonstrate the relevance of the tools proposed by applying them to solve recurrent problems in the practice of conceptual modeling.},
address = {Riga, Latvia},
author = {Guizzardi, Giancarlo and Wagner, Gerd and Guarino, Nicola and van Sinderen, Marten},
booktitle = {Proc. of the 16th International Conference on Advanced Information Systems Engineering (CAiSE 04)},
doi = {10.1007/978-3-540-25975-6_10},
editor = {Persson, Anne and Stirna, Janis},
file = {:Users/vitor/Mendeley/Guizzardi et al. - 2004 - An Ontologically Well-Founded Profile for UML Conceptual Models.pdf:pdf},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {jun},
pages = {112--126},
publisher = {Springer},
title = {{An Ontologically Well-Founded Profile for UML Conceptual Models}},
url = {http://link.springer.com/10.1007/978-3-540-25975-6{\_}10},
year = {2004}
}
@phdthesis{guizzardi:phdthesis06,
author = {Guizzardi, Renata S. S.},
file = {:Users/vitor/Mendeley/Guizzardi - 2006 - Agent-oriented Constructivist Knowledge Management.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
school = {University of Twente, The Netherlands},
title = {{Agent-oriented Constructivist Knowledge Management}},
type = {PhD Thesis},
url = {http://doc.utwente.nl/56967/},
year = {2006}
}
@inproceedings{franch-et-al:rcis12,
abstract = {The i* community has raised several main dialects and dozens of variations in the definition of the i* language. Differences may be found related not just to the representation of new concepts but to the very core of the i* language. If on the one hand this is caused by large adoption of the framework in the academic setting, on the other hand, it also poses some threats. For example, novices have trouble learning how to use the language, and besides these inconsistencies prevent i* from being largely adopted in business settings. Based on positive results from previous work related to conceptual modeling languages, we believe that foundational ontologies may present a promising solution for this problem. Foundational ontologies may help clarifying the semantics of core i* constructs and provide practical guidelines for their use. Last, they may serve as the basis to propose a normative definition of the framework. In this paper, we develop this idea, first by justifying the use of foundational ontologies and, in particular, the UFO ontology. Then, we raise some problems found in the i* literature. And then, we show the outcomes of adopting an ontological approach for the specific case of the i* framework. We focus here on one of the most characteristic i* construct, namely the means-end link.},
address = {Valencia, Spain},
author = {Guizzardi, Renata S. S. and Franch, Xavier and Guizzardi, Giancarlo},
booktitle = {Proc. of the 6th International Conference on Research Challenges in Information Science},
doi = {10.1109/RCIS.2012.6240425},
file = {:Users/vitor/Mendeley/Guizzardi, Franch, Guizzardi - 2012 - Applying a foundational ontology to analyze means-end links in the i framework.pdf:pdf},
isbn = {978-1-4577-1938-7},
keywords = {UFO,bibtex,foundational ontology,i*,iStar,means-end,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {may},
pages = {1--11},
publisher = {IEEE},
title = {{Applying a foundational ontology to analyze means-end links in the i* framework}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6240425},
year = {2012}
}
@inproceedings{guizzardi-et-al:istar13,
abstract = {In the past few years, the community that develops i* has become aware of the problem of having so many variants, since it makes it difficult for newcomers to learn how to use the language and even to experts to efficiently exchange knowledge and disseminate their proposals. Moreover, this problem also delays the transfer of the i* framework to industrial settings. Our work is one of the current attempts to promote interoperability among the existing variants, and it does that by investigating the semantics behind the i* core concepts. For that, we apply a foundational ontology named UFO, which is used as a semantically coherent reference model to which the language should be isomorphic. In this paper, we report on the steps we have pursued, what we have accomplished so far, also setting the context for the work ahead.},
address = {Valencia, Spain},
author = {Guizzardi, Renata S. S. and Franch, Xavier and Guizzardi, Giancarlo and Wieringa, Roel},
booktitle = {Prof. of the 6th International i* Workshop},
file = {:Users/vitor/Mendeley/Guizzardi et al. - 2013 - Using a Foundational Ontology to Investigate the Semantics Behind the Concepts of the i Language.pdf:pdf},
keywords = {UFO,bibtex,foundational ontology,iStar,language interoperability,semantics},
mendeley-tags = {bibtex},
month = {jun},
pages = {13--18},
publisher = {CEUR},
title = {{Using a Foundational Ontology to Investigate the Semantics Behind the Concepts of the i* Language}},
url = {http://ceur-ws.org/Vol-978/},
year = {2013}
}
@inproceedings{guizzardi-et-al:fois14,
abstract = {Non-functional requirements (NFRs) have been the focus of research in Requirements Engineering (RE) for more than 20 years. Despite this attention, their ontological nature is still an open question, thereby hampering efforts to develop concepts, tools and techniques for eliciting, modeling, and analyzing them, in order to produce a specification for a system-to-be. In this paper, we propose to treat NFRs as qualities, based on definitions of the UFO foundational ontology. Furthermore, based on these ontological definitions, we provide guidelines for distinguishing between non-functional and functional requirements, and sketch a syntax of a specification language that can be used for capturing NFRs.},
address = {Rio de Janeiro, RJ, Brasil},
author = {Guizzardi, Renata S. S. and Li, Feng-Lin and Borgida, Alexander and Guizzardi, Giancarlo and Horkoff, Jennifer and Mylopoulos, John},
booktitle = {Proc. of the 8th International Conference on Formal Ontology in Information Systems},
doi = {10.3233/978-1-61499-438-1-344},
editor = {Garbacz, Pawel and Kutz, Oliver},
file = {:Users/vitor/Mendeley/Guizzardi et al. - 2014 - An Ontological Interpretation of Non-Functional Requirements.pdf:pdf},
isbn = {978-1-61499-437-4},
keywords = {UFO,bibtex,commented,foundational ontology,non-functional requirements,qualities},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {344--357},
publisher = {IOS Press},
title = {{An Ontological Interpretation of Non-Functional Requirements}},
url = {http://ebooks.iospress.nl/volumearticle/37981},
volume = {267},
year = {2014}
}
@inproceedings{guo-et-al:dolap06,
abstract = {In this paper, we present a useful data modeling methodology in data warehousing which integrates three existing approaches normally used in isolation: goal-driven, data-driven and user- driven. It comprises of four stages. Goal-driven stage produces subjects and KPIs(Key Performance Indicators) of main business fields. Data-driven stage produces subject oriented enterprise data schema. User-driven stage yields analytical requirements represented by measures and dimensions of each subject. Combination stage combines the triple-driven results. By triple- driven, we can get a more complete, more structured and more layered data model of a data warehouse. We illustrate each stage step by step using examples in our case study.},
address = {Arlington, VA, USA},
author = {Guo, Yuhong and Tang, Shiwei and Tong, Yunhai and Yang, Dongqing},
booktitle = {Proc. of the 9th ACM International Workshop on Data Warehousing and OLAP},
doi = {10.1145/1183512.1183524},
file = {:Users/vitor/Mendeley/Guo et al. - 2006 - Triple-Driven Data Modeling Methodology in Data Warehousing A Case Study.pdf:pdf},
isbn = {1595935304},
keywords = {bibtex,case study,data warehouse design,not-commented,requirement analysis,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
month = {nov},
pages = {59--66},
publisher = {ACM},
title = {{Triple-Driven Data Modeling Methodology in Data Warehousing: A Case Study}},
url = {http://portal.acm.org/citation.cfm?doid=1183512.1183524},
year = {2006}
}
@article{taieb-et-al:kbsj13,
abstract = {Measuring semantic relatedness is a critical task in many domains such as psychology, biology, linguistics, cognitive science and artificial intelligence. In this paper, we propose a novel system for computing semantic relatedness between words. Recent approaches have exploited Wikipedia as a huge semantic resource that showed good performances. Therefore, we utilized the Wikipedia features (articles, categories, Wikipedia category graph and redirection) in a system combining this Wikipedia semantic information in its different components. The approach is preceded by a pre-processing step to provide for each category pertaining to the Wikipedia category graph a semantic description vector including the weights of stems extracted from articles assigned to the target category. Next, for each candidate word, we collect its categories set using an algorithm for categories extraction from the Wikipedia category graph. Then, we compute the semantic relatedness degree using existing vector similarity metrics (Dice, Overlap and Cosine) and a new proposed metric that performed well as cosine formula. The basic system is followed by a set of modules in order to exploit Wikipedia features to quantify better as possible the semantic relatedness between words. We evaluate our measure based on two tasks: comparison with human judgments using five datasets and a specific application “solving choice problem”. Our result system shows a good performance and outperforms sometimes ESA (Explicit Semantic Analysis) and TSA (Temporal Semantic Analysis) approaches.},
author = {{Hadj Taieb}, Mohamed Ali and {Ben Aouicha}, Mohamed and {Ben Hamadou}, Abdelmajid},
doi = {10.1016/j.knosys.2013.06.015},
editor = {Fujita, Hamido and Lu, Jie},
file = {:Users/vitor/Mendeley/Hadj Taieb, Ben Aouicha, Ben Hamadou - 2013 - Computing semantic relatedness using Wikipedia features.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {bibtex,commented,semantic analysis,semantic relatedness,wikipedia,wikipedia category graph,word relatedness},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {260--278},
publisher = {Elsevier},
title = {{Computing semantic relatedness using Wikipedia features}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950705113001913},
volume = {50},
year = {2013}
}
@inproceedings{hall:isre97,
abstract = {There are many ideas about how to do requirements engineering, and often they conflict with each other. Such conflicts can best be resolved by asking of anything one proposes to do, “What is the use of doing that?” The question demands a thorough understanding of the principles behind different methods, and the answers may surprise those who equate pragmatism with informality. I discuss how applying this rule helps in choosing requirements engineering methods and in dealing with the difficulties that arise in applying these methods.},
address = {Annapolis, MD, USA},
author = {Hall, A.},
booktitle = {Proc. of the 3rd IEEE International Symposium on Requirements Engineering (ISRE 97)},
doi = {10.1109/ISRE.1997.566833},
file = {:Users/vitor/Mendeley/Hall - 1997 - What's the use of requirements engineering.pdf:pdf},
isbn = {0-8186-7740-6},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {jan},
pages = {2--3},
publisher = {IEEE},
title = {{What's the use of requirements engineering?}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=566833},
year = {1997}
}
@article{hallsteinsen:computer08,
abstract = {The Software Engineering Institute (SEI) defines an SPL as a set of software-intensive systems that share a common, managed set of features satisfying the specific needs of a particular market segment or mission. A fundamental principle of SPLs is variability management, which involves separating the product line into three parts - common components, parts common to some but not all products, and individual products with their own specific requirements - and managing these throughout development. Using SPLs seeks to maximize reusable variation and eliminate wasteful generic development of components used only once. Although traditional SPL engineering recognizes that variation points are bound at different stages of development, and possibly also at runtime, it typically binds variation points before delivery of the software. In contrast, DSPL engineers typically aren't concerned with pre-runtime variation points. However, they recognize that in practice mixed approaches might be viable, where some variation points related to the environment's static properties are bound before runtime and others related to the dynamic properties are bound at runtime.},
author = {Hallsteinsen, Svein and Hinchey, Mike and Park, Sooyong and Schmid, Klaus},
doi = {10.1109/MC.2008.123},
file = {:Users/vitor/Mendeley/Hallsteinsen et al. - 2008 - Dynamic Software Product Lines.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {apr},
number = {4},
pages = {93--95},
publisher = {IEEE},
title = {{Dynamic Software Product Lines}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4488260},
volume = {41},
year = {2008}
}
@article{harel-rumpe:computer04,
abstract = {The Unified Modeling Language (UML) is a complex collection of mostly diagrammatic notations for software modeling, and its standardization has prompted an animated discussion about UML's semantics and how to represent it. We have thus set out to clarify some of the notions involved in defining modeling languages, with an eye toward the particular difficulties arising in defining UML. We are primarily interested in distinguishing a language's notation, or syntax, from its meaning, or semantics, as well as recognizing the differences between variants of syntax and semantics in their nature, purpose, style, and use.},
author = {Harel, D. and Rumpe, B.},
doi = {10.1109/MC.2004.172},
file = {:Users/vitor/Mendeley/Harel, Rumpe - 2004 - Meaningful modeling what's the semantics of semantics.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {oct},
number = {10},
pages = {64--72},
publisher = {IEEE},
title = {{Meaningful modeling: what's the semantics of "semantics"?}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1350729},
volume = {37},
year = {2004}
}
@inproceedings{harker-et-al:re93,
abstract = {The difficulty of handling changing requirements within traditional development processes is described. The origins of changing user and organizational requirements are discussed and different types are classified. The author identifies a number of ways in which different approaches to design may help to deal with change as well as mechanisms which should underpin effective communication between users and designers.},
address = {San Diego, CA , USA},
author = {Harker, Susan D.P. and Eason, Ken D. and Dobson, John E.},
booktitle = {Proc. of the 1993 IEEE International Symposium on Requirements Engineering},
doi = {10.1109/ISRE.1993.324847},
file = {:Users/vitor/Mendeley/Harker, Eason, Dobson - 1993 - The Change and Evolution of Requirements as a Challenge to the Practice of Software Engineering.pdf:pdf},
isbn = {0-8186-3120-1},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {jan},
pages = {266--272},
publisher = {IEEE},
title = {{The Change and Evolution of Requirements as a Challenge to the Practice of Software Engineering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=324847},
year = {1993}
}
@article{hartig-langegger:ds10,
abstract = {During recent years an increasing number of data providers adopted the Linked Data principles for publishing and connecting structured data on the Web, thus creating a globally distributed dataspace—the Web of Data. While the execution of structured, SQL-like queries over this dataspace opens possibilities not conceivable before, query execution on the Web of Data poses novel challenges. These challenges provide great opportunities for the database community. In this article we introduce the concept of Linked Data and discuss different approaches to query the Web of Data. Our goal is to provide a general understanding of this new research area and of the challenges and open issues that must be addressed.},
author = {Hartig, Olaf and Langegger, Andreas},
doi = {10.1007/s13222-010-0021-7},
file = {:Users/vitor/Mendeley/Hartig, Langegger - 2010 - A Database Perspective on Consuming Linked Data on the Web.pdf:pdf},
issn = {1618-2162},
journal = {Datenbank-Spektrum},
keywords = {bibtex,commented,linked data,query processing,web of data},
mendeley-tags = {bibtex,commented},
month = {aug},
number = {2},
pages = {57--66},
publisher = {Springer},
title = {{A Database Perspective on Consuming Linked Data on the Web}},
url = {http://link.springer.com/10.1007/s13222-010-0021-7},
volume = {10},
year = {2010}
}
@inproceedings{hawthorne-perry:woss04,
abstract = {We propose a high-level approach to software architecture that bridges the gap between system requirements (in the problem space) and the architectural design (in the solution space). We use abstract constraint- and intent-based architectural prescriptions to enable architectural reflection, reification, and distributed configuration discovery as the basis for designing adaptive, self- configuring software systems. We discuss some key architectural properties and patterns that facilitate the design and implementation of self-configuring systems, and use these as the basis for an example prototype architecture for self-evolving systems called Distributed Configuration Routing (DCR). Finally, we propose the development of architectural prescription languages (APLs) and enhanced system design environments to provide better support for intent-based architectures.},
address = {Newport Beach, CA, USA},
author = {Hawthorne, Matthew J. and Perry, Dewayne E.},
booktitle = {Proc. of the 1st ACM SIGSOFT Workshop on Self-managed Systems},
doi = {10.1145/1075405.1075420},
file = {:Users/vitor/Mendeley/Hawthorne, Perry - 2004 - Exploiting Architectural Prescriptions for Self-Managing, Self-Adaptive Systems A Position Paper.pdf:pdf},
isbn = {1581139896},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {oct},
pages = {75--79},
publisher = {ACM},
title = {{Exploiting Architectural Prescriptions for Self-Managing, Self-Adaptive Systems: A Position Paper}},
url = {http://portal.acm.org/citation.cfm?doid=1075405.1075420},
year = {2004}
}
@book{heath-bizer:book11,
abstract = {This book gives an overview of the principles of Linked Data as well as the Web of Data that has emerged through the application of these principles. The book discusses patterns for publishing Linked Data, describes deployed Linked Data applications and examines their architecture.},
author = {Heath, Tom and Bizer, Christian},
doi = {10.2200/S00334ED1V01Y201102WBE001},
edition = {1},
isbn = {9781608454303},
keywords = {bibtex},
mendeley-tags = {bibtex},
pages = {1--136},
publisher = {Morgan {\&} Claypool Publishers},
series = {Synthesis Lectures on the Semantic Web: Theory and Technology},
title = {{Linked Data: Evolving the Web into a Global Data Space}},
url = {http://linkeddatabook.com/editions/1.0/},
year = {2011}
}
@inproceedings{heaven-letier:re11,
abstract = {Making decisions among a set of alternative system designs is an essential activity of requirements engineering. It involves evaluating how well each alternative satisfies the stakeholders' goals and selecting one alternative that achieves some optimal tradeoffs between possibly conflicting goals. Quantitative goal models support such activities by describing how alternative system designs - expressed as alternative goal refinements and responsibility assignments - impact on the levels of goal satisfaction specified in terms of measurable objective functions. Analyzing large numbers of alternative designs in such models is an expensive activity for which no dedicated tool support is currently available. This paper takes a first step towards providing such support by presenting automated techniques for (i) simulating quantitative goal models so as to estimate the levels of goal satisfaction contributed by alternative system designs and (ii) optimising the system design by applying a multi-objective optimisation algorithm to search through the design space. These techniques are presented and validated using a quantitative goal model for a well-known ambulance service system.},
address = {Trento, Italy},
author = {Heaven, William and Letier, Emmanuel},
booktitle = {Proc. of the 19th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2011.6051653},
file = {:Users/vitor/Mendeley/Heaven, Letier - 2011 - Simulating and Optimising Design Decisions in Quantitative Goal Models.pdf:pdf},
isbn = {978-1-4577-0921-0},
keywords = {bibtex,commented,goal-oriented requirements engineering,quality requirements,quantitative modeling,requirements simulations and optimization,search-based software engineering},
mendeley-tags = {bibtex,commented},
month = {aug},
pages = {79--88},
publisher = {IEEE},
title = {{Simulating and Optimising Design Decisions in Quantitative Goal Models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6051653},
year = {2011}
}
@incollection{heaven-et-al:seams09,
abstract = {To operate reliably in environments where interaction with an operator is infrequent or undesirable, an autonomous system should be capable of both determining how to achieve its objectives and adapting to novel circumstances on its own. We have developed an approach to constructing autonomous systems that synthesise tasks from high-level goals and adapt their software architecture to perform these tasks reliably in a changing environment. This paper presents our approach through a detailed case study, highlighting the challenges involved.},
annote = {10.1007/978-3-642-02161-9{\_}6},
author = {Heaven, William and Sykes, Daniel and Magee, Jeff and Kramer, Jeff},
booktitle = {Software Engineering for Self-Adaptive Systems},
doi = {10.1007/978-3-642-02161-9_6},
editor = {Cheng, Betty H. C. and de Lemos, Rog{\'{e}}rio and Giese, Holger and Inverardi, Paola and Magee, Jeff},
file = {:Users/vitor/Mendeley/Heaven et al. - 2009 - A Case Study in Goal-Driven Architectural Adaptation.pdf:pdf},
isbn = {978-3-642-02160-2},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {109--127},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{A Case Study in Goal-Driven Architectural Adaptation}},
url = {http://www.springerlink.com/content/c5v506gvkl27l854/},
volume = {5525},
year = {2009}
}
@inproceedings{hebig-et-al:soar10,
abstract = {Many self-adaptive systems include control loops between the core system and specific control elements which realize the self-adaptation capabilities. This is also true albeit at a higher level of abstraction for decentralized architectures. However, the available techniques to describe the software architecture of such systems do not support to make the control loops explicit. Therefore, architecting self-adaptive systems and their self-adaptation logic is today not well supported. In this paper, we present a UML profile for control loops that extends UML modeling concepts such that control loops become first class elements of the architecture. This enables that the architecture reflects control loops as crucial elements of the software architecture of these systems. Furthermore, it supports to design control loops as well as the interplay of multiple control loops at the architectural level. In addition, warning signals and related analysis activities are presented that can be used to analyze whether a given architectural UML model using the profile includes potentially problematic occurrences of control loops.},
address = {Washington, DC, USA},
author = {Hebig, Regina and Giese, Holger and Becker, Basil},
booktitle = {Proc. of the 2nd International Workshop on Self-organizing Architectures},
doi = {10.1145/1809036.1809042},
file = {:Users/vitor/Mendeley/Hebig, Giese, Becker - 2010 - Making Control Loops Explicit when Architecting Self-Adaptive Systems.pdf:pdf},
isbn = {9781450300872},
keywords = {bibtex,commented,feedback control,self-adaptive systems,uml profile},
mendeley-tags = {bibtex,commented},
month = {jun},
pages = {21--28},
publisher = {ACM},
title = {{Making Control Loops Explicit when Architecting Self-Adaptive Systems}},
url = {http://portal.acm.org/citation.cfm?doid=1809036.1809042},
year = {2010}
}
@book{hellerstein-et-al:book04,
abstract = {This is the first practical treatment of the design and application of feedback control of computing systems. MATLAB files for the solution of problems and case studies accompany the text throughout. The book discusses information technology examples, such as maximizing the efficiency of Lotus Notes. This book results from the authors' research into the use of control theory to model and control computing systems. This has important implications to the way engineers and researchers approach different resource management problems. This guide is well suited for professionals and researchers in information technology and computer science.},
author = {Hellerstein, Joseph L. and Diao, Yixin and Parekh, Sujay and Tilbury, Dawn M.},
edition = {1st},
file = {:Users/vitor/Mendeley/Hellerstein et al. - 2004 - Feedback Control of Computing Systems.pdf:pdf},
isbn = {978-0-471-26637-2},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Wiley},
title = {{Feedback Control of Computing Systems}},
url = {http://eu.wiley.com/WileyCDA/WileyTitle/productCd-047126637X.html},
year = {2004}
}
@article{hendler-bernerslee:ai10,
abstract = {The advent of social computing on the Web has led to a new generation of Web applications that are powerful and world-changing. However, we argue that we are just at the beginning of this age of “social machines” and that their continued evolution and growth requires the cooperation of Web and AI researchers. In this paper, we show how the growing Semantic Web provides necessary support for these technologies, outline the challenges we see in bringing the technology to the next level, and propose some starting places for the research.},
author = {Hendler, Jim and Berners-Lee, Tim},
doi = {10.1016/j.artint.2009.11.010},
file = {:Users/vitor/Mendeley/Hendler, Berners-Lee - 2010 - From the Semantic Web to social machines A research challenge for AI on the World Wide Web.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {feb},
number = {2},
pages = {156--161},
publisher = {Elsevier},
title = {{From the Semantic Web to social machines: A research challenge for AI on the World Wide Web}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370209001404},
volume = {174},
year = {2010}
}
@book{simon:book96,
abstract = {Continuing his exploration of the organization of complexity and the science of design, this new edition of Herbert Simon's classic work on artificial intelligence adds a chapter that sorts out the current themes and tools—chaos, adaptive systems, genetic algorithms—for analyzing complexity and complex systems. There are updates throughout the book as well. These take into account important advances in cognitive psychology and the science of design while confirming and extending the book's basic thesis: that a physical symbol system has the necessary and sufficient means for intelligent action. The chapter "Economic Reality" has also been revised to reflect a change in emphasis in Simon's thinking about the respective roles of organizations and markets in economic systems.},
author = {{Herbert A. Simon}},
edition = {3},
isbn = {9780262691918},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {MIT Press},
title = {{The Sciences of the Artificial}},
url = {https://mitpress.mit.edu/books/sciences-artificial},
year = {1996}
}
@article{hevner-et-al:misq04,
abstract = {Two paradigms characterize much of the research in the Information Systems discipline: behavioral science and design science. The behavioral-science paradigm seeks to develop and verify theories that explain or predict human or organizational behavior. The design-science paradigm seeks to extend the boundaries of human and organizational capabilities by creating new and innovative artifacts. Both paradigms are foundational to the IS discipline, positioned as it is at the confluence of people, organizations, and technology. Our objective is to describe the performance of design-science research in Information Systems via a concise conceptual framework and clear guidelines for understanding, executing, and evaluating the research. In the design-science paradigm, knowledge and understanding of a problem domain and its solution are achieved in the building and application of the designed artifact. Three recent exemplars in the research literature are used to demonstrate the application of these guidelines. We conclude with an analysis of the challenges of performing high-quality design-science research in the context of the broader IS community.},
author = {Hevner, Alan R. and March, Salvatore T. and Park, Jinsoo and Ram, Sudha},
file = {:Users/vitor/Mendeley/Hevner et al. - 2004 - Design Science in Information Systems Research.pdf:pdf},
journal = {MIS Quarterly},
keywords = {bibtex,business environment,commented,creativity,design artifact,design science,experimental methods,information systems research methodologies,search strategies,technology infrastructure},
mendeley-tags = {bibtex,commented},
number = {1},
pages = {75--105},
publisher = {University of Minnesota},
title = {{Design Science in Information Systems Research}},
url = {http://misq.org/design-science-in-information-systems-research.html},
volume = {28},
year = {2004}
}
@book{hinchey-coyle:book12,
abstract = {Software has long been perceived as complex, at least within Software Engineering circles. We have been living in a recognised state of crisis since the first NATO Software Engineering conference in 1968. Time and again we have been proven unable to engineer reliable software as easily/cheaply as we imagined. Cost overruns and expensive failures are the norm. The problem is fundamentally one of complexity: software is fundamentally complex because it must be precise. Problems that appear to be specified quite easily in plain language become far more complex when written in a more formal notation, such as computer code. Comparisons with other engineering disciplines are deceptive. One cannot easily increase the factor of safety of software in the same way that one could in building a steel structure, for example. Software is typically built assuming perfection, often without adequate safety nets in case the unthinkable happens. In such circumstances it should not be surprising to find out that (seemingly) minor errors have the potential to cause entire software systems to collapse. The goal of this book is to uncover techniques that will aid in overcoming complexity and enable us to produce reliable, dependable computer systems that will operate as intended, and yet are produced on-time, in budget, and are evolvable, both over time and at run time. We hope that the contributions in this book will aid in understanding the nature of software complexity and provide guidance for the control or avoidance of complexity in the engineering of complex software systems.},
author = {Hinchey, Mike and Coyle, Lorcan},
file = {:Users/vitor/Mendeley/Hinchey, Coyle - 2012 - Conquering Complexity.pdf:pdf},
isbn = {978-1-4471-2296-8},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Springer},
title = {{Conquering Complexity}},
url = {http://www.springer.com/computer/book/978-1-4471-2296-8},
year = {2012}
}
@incollection{hirst-stonge:book98,
abstract = {Natural language utterances are, in general, highly ambiguous, and a unique interpretation can usually be determined only by taking into account the constraining influence of the context in which the utterance occurred. Much of the research in natural language understanding in the last twenty years can be thought of as attempts to characterize and represent context and then derive interpretations that fit best with that context. Typically, this research was heavy with AI, taking context to be nothing less than a complete conceptual understanding of the preceding utterances. This was reasonable, as such an understanding of a text was often the main task anyway. However, there are many text-processing tasks that require only a partial understanding of the text, and hence a ‘lighter' representation of context is sufficient. In this paper, we examine the idea of lexical chains as such a representation. We show how they can be constructed by means of WordNet, and how they can be applied in one particular linguistic task: the detection and correction of malapropisms. A malapropism is the confounding of an intended word with another word of similar sound or similar spelling that has a quite different and malapropos meaning, e.g., an ingenuous [for ingenious] machine for peeling oranges. In this example, there is a one-letter difference between the malapropism and the correct word. Ignorance, or a simple typing mistake, might cause such errors. However, since ingenuous is a correctly spelled word, traditional spelling checkers cannot detect this kind of mistake. In section 4, we will propose an algorithm for detecting and correcting malapropisms that is based on the construction of lexical chains.},
author = {Hirst, Graeme and St-Onge, David},
booktitle = {WordNet - An Electronic Lexical Database},
chapter = {13},
editor = {Fellbaum, Christiane},
file = {:Users/vitor/Mendeley/Hirst, St-Onge - 1998 - Lexical chains as representations of context for the detection and correction of malapropisms.pdf:pdf},
isbn = {9780262561167},
keywords = {bibtex,summarized},
mendeley-tags = {bibtex,summarized},
pages = {305--332},
publisher = {MIT Press},
title = {{Lexical chains as representations of context for the detection and correction of malapropisms}},
url = {http://mitpress.mit.edu/books/wordnet},
year = {1998}
}
@book{hitzler-et-al:book09,
author = {Hitzler, Pascal and Kr{\"{o}}tzsch, Markus and Rudolph, Sebastian},
isbn = {9871420090505},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {CRC Press},
title = {{Foundations of Semantic Web Technologies}},
url = {http://www.semantic-web-book.org/page/Foundations{\_}of{\_}Semantic{\_}Web{\_}Technologies},
year = {2009}
}
@article{holanda-et-al:esa13,
abstract = {In the past few years, the use of ontologies for creating more intelligent and effective application has increased considerably. This growth is due to the fact that ontologies attempt to provide semantics to the data consumed by machines so that they can reason about this data. However, developing complex ontology-based applications is still difficult and time-consuming because the existing tools do not provide a simple and unified environment for developers. Most of these tools only provide data manipulation using RDF triples, complicating the development of applications that need to work with the object orientation paradigm. Furthermore, tools that provide instances manipulation via object orientation do not support features such as manipulating ontologies, reasoning over rules or querying data with SPARQL. In this context, this work proposes a framework and a tool for supporting the efficient development of ontology-based applications through the integration of existing technologies. Furthermore, we also define a methodology to use this tool efficiently. In order to evaluate the benefits of our work, a controlled experiment with eight developers (unfamiliar with ontologies) was performed to compare the proposed tool, JOINT, with another one, Jastor/Jena, frequently used by the community. The results suggest that our tool helps novice developers to create ontology-based applications faster and with few errors in the code. In addition, a real educational application with 10 ontologies, more than 200 ontology concepts (classes) and more than a million triples is already using the proposed tool successfully. {\textcopyright} 2013 Elsevier Ltd. All rights reserved.},
author = {Holanda, Olavo and Isotani, Seiji and Bittencourt, Ig Ibert and Elias, Endhe and Ten{\'{o}}rio, Thyago},
doi = {10.1016/j.eswa.2013.05.040},
file = {:Users/vitor/Mendeley/Holanda et al. - 2013 - JOINT Java ontology integrated toolkit.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Integrated development environment,Ontology manipulation tool,Ontology-based software,Ontology-driven software development,bibtex},
mendeley-tags = {bibtex},
number = {16},
pages = {6469--6477},
publisher = {Elsevier},
title = {{JOINT: Java ontology integrated toolkit}},
url = {http://www.sciencedirect.com/science/article/pii/S0957417413003382},
volume = {40},
year = {2013}
}
@inproceedings{hong-et-al:icec05,
abstract = {With the invention of new interaction devices and the requirements for ubiquitous access to application systems, user's interactions have moved beyond the desktop and evolved into a trend of ongoing development. The context in which the application is being used becomes an integral part of the activity carried out with the system. The inclusion of context-awareness provides convenience and efficiency to users for their ubiquitous access. Traditional human-computer interface (HCI) theories are now inadequate for developing these context-aware applications, as we believe that the notion of context should be extended to different categories: computing contexts, user contexts, and physical contexts for ubiquitous computing. This demands a new paradigm for system requirements elicitation and design in order to make good use of such extended context information. In this paper, we introduce a methodology for the elicitation of context-aware requirements and the matching of context-awareness features to the target context by capability matching. Based on this model, we analyze the design issues of some common ubiquitous access situations and show how to fit them systematically into a context-aware application by considering the requirements of a ubiquitous tourist application.},
address = {Xi'an, China},
author = {Hong, Dan and Chiu, Dickson K. W. and Shen, Vincent Y.},
booktitle = {Proc. of the 7th International Conference on Electronic Commerce},
doi = {10.1145/1089551.1089658},
file = {:Users/vitor/Mendeley/Hong, Chiu, Shen - 2005 - Requirements Elicitation for the Design of Context-aware Applications in a Ubiquitous Environment.pdf:pdf},
isbn = {1595931120},
keywords = {HCI,bibtex,commented,context,context-aware application,design issues,summarized,tourist system},
mendeley-tags = {bibtex,commented,summarized},
month = {aug},
pages = {590--596},
publisher = {ACM},
title = {{Requirements Elicitation for the Design of Context-aware Applications in a Ubiquitous Environment}},
url = {http://portal.acm.org/citation.cfm?doid=1089551.1089658},
year = {2005}
}
@inproceedings{horkoff-et-al:rcis14,
abstract = {Creating and reasoning with goal models is useful for capturing, understanding, and communicating about requirements in the early stages of information system (re)development. However, the utility of goal models is greatly enhanced when an awareness of system intentions can feed into other stages in the requirements analysis process (e.g. requirements elaboration, validation, planning), and can be used as part of the entire system life cycle (e.g., architecture, process design, coding, testing, monitoring, adaptation, and evolution). In order to understand the progress that has been made in integrating goal models with downstream system development, we ask: what approaches exist which map/integrate/transform goal-oriented languages to other software artifacts or languages? To answer this question, we conduct a systematic survey, producing a roadmap of work summarizing 174 publications. Results include a categorization of the “why?” and “how?” for each approach. Findings show that there are a wide variety of proposals with many proposed sources and targets, covering multiple paradigms, motivated by a variety of purposes. We conclude that although much work has been done in this area, the work is fragmented and is often still in a proposal stage.},
address = {Marrakesh, Morocco},
author = {Horkoff, Jennifer and Salnitri, Mattia and Cardoso, Evellin and Giorgini, Paolo and Mylopoulos, John and Pimentel, Joao},
booktitle = {Proc. of the 8th IEEE International Conference on Research Challenges in Information Science},
doi = {10.1109/RCIS.2014.6861036},
editor = {Bajec, Marko and Collard, Martine and Deneckere, Rebecca},
file = {:Users/vitor/Mendeley/Horkoff et al. - 2014 - Taking goal models downstream A systematic roadmap.pdf:pdf},
isbn = {978-1-4799-2393-9},
keywords = {bibtex,commented,evidence-based requirements engineering,goal model,model transformation,requirements engineering,systematic literature map,systematic literature survey},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {1--12},
publisher = {IEEE},
title = {{Taking goal models downstream: A systematic roadmap}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6861036},
year = {2014}
}
@misc{horn:website01,
author = {Horn, Paul},
file = {:Users/vitor/Mendeley/Horn - 2001 - Autonomic Computing IBM's Perspective on the State of Information Technology, httpwww.research.ibm.comautonomicmanifesto.pdf:pdf},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
publisher = {IBM Corp.},
title = {{Autonomic Computing: IBM's Perspective on the State of Information Technology, http://www.research.ibm.com/autonomic/manifesto/ (last access: March 20th, 2012)}},
url = {http://www.research.ibm.com/autonomic/manifesto/},
year = {2001}
}
@article{horrocks:cacm08,
abstract = {The goal of semantic web research is to allow the vast range of web-accessible information and services to be more e ec- tively exploited by both humans and automated tools. To facilitate this process, RDF and OWL have been developed as standard formats for the sharing and integration of data and knowledge|the latter in the form of rich conceptual schemas called ontologies. These languages, and the tools developed to support them, have rapidly become de facto standards for ontology development and deployment; they are increasingly used, not only in research labs, but in large scale IT projects. Although many research and development challenges still remain, these $\backslash$semantic web technologies" are already starting to exert a major in uence on the devel- opment of information technology.},
author = {Horrocks, Ian},
doi = {10.1145/1409360.1409377},
file = {:Users/vitor/Mendeley/Horrocks - 2008 - Ontologies and the Semantic Web.pdf:pdf},
isbn = {9783540929130},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {bibtex},
mendeley-tags = {bibtex},
number = {12},
pages = {58--67},
publisher = {ACM},
title = {{Ontologies and the Semantic Web}},
url = {http://dl.acm.org/citation.cfm?id=1409377},
volume = {51},
year = {2008}
}
@article{hosie:emj01,
abstract = {The Egan Report advocates the use of effective partnering in the place of formal contracts in order for the construction industry to re-think its processes and deliver year-on-year improvements in quality, productivity and profits. Formal contracts can, however, help support effective partnering by providing tangible incentives triggered by the achievement of key performance indicators. Here are some ideas.},
annote = {Mentions KPIs only on abstract.},
author = {Hosie, Jonathan},
doi = {10.1049/em:20010106},
file = {:Users/vitor/Mendeley/Hosie - 2001 - Egan's view on contracts.pdf:pdf},
issn = {09607919},
journal = {Engineering Management Journal},
keywords = {bibtex,not-commented,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
month = {feb},
number = {1},
pages = {43--48},
publisher = {IET},
title = {{Egan's view on contracts}},
url = {http://link.aip.org/link/EMAJEP/v11/i1/p43/s1{\&}Agg=doi},
volume = {11},
year = {2001}
}
@article{huebscher-mccann:cs08,
abstract = {Autonomic Computing is a concept that brings together many fields of computing with the purpose of creating computing systems that self-manage. In its early days it was criticised as being a “hype topic” or a rebadging of some Multi Agent Systems work. In this survey, we hope to show that this was not indeed ‘hype' and that, though it draws on much work already carried out by the Computer Science and Control communities, its innovation is strong and lies in its robust application to the specific self-management of computing systems. To this end, we first provide an introduction to the motivation and concepts of autonomic computing and describe some research that has been seen as seminal in influencing a large proportion of early work. Taking the components of an established reference model in turn, we discuss the works that have provided significant contributions to that area. We then look at larger scaled systems that compose autonomic systems illustrating the hierarchical nature of their architectures. Autonomicity is not a well defined subject and as such different systems adhere to different degrees of Autonomicity, therefore we cross-slice the body of work in terms of these degrees. From this we list the key applications of autonomic computing and discuss the research work that is missing and what we believe the community should be considering.},
author = {Huebscher, Markus C. and McCann, Julie A.},
doi = {10.1145/1380584.1380585},
file = {:Users/vitor/Mendeley/Huebscher, McCann - 2008 - A survey of Autonomic Computing—Degrees, Models, and Applications.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
keywords = {autonomic computing,bibtex,design,not-commented,performance,reliability,self-adaptive,self-healing systems},
mendeley-tags = {bibtex,not-commented},
month = {aug},
number = {3},
pages = {1--28},
publisher = {ACM},
title = {{A survey of Autonomic Computing—Degrees, Models, and Applications}},
url = {http://portal.acm.org/citation.cfm?doid=1380584.1380585},
volume = {40},
year = {2008}
}
@inproceedings{huth-et-al:esop01,
abstract = {We present Kripke modal transition systems (Kripke MTSs), a generalization of modal transition systems [27,26], as a foundation for three-valued program analysis. The semantics of Kripke MTSs are presented by means of a mixed power domain of states; soundness and consistency are proved. Two major applications, model checking partial state spaces and three-valued program shape analysis, are presented as evidence of the suitability of Kripke MTSs as a foundation for three-valued analyses.},
address = {Genova, Italy},
author = {Huth, Michael and Jagadeesan, Radha and Schmidt, David},
booktitle = {Proc. of the 10th European Symposium on Programming (ESOP 2001)},
doi = {10.1007/3-540-45309-1_11},
file = {:Users/vitor/Mendeley/Huth, Jagadeesan, Schmidt - 2001 - Modal Transition Systems A Foundation for Three-Valued Program Analysis.pdf:pdf},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {apr},
pages = {155--169},
publisher = {Springer},
title = {{Modal Transition Systems: A Foundation for Three-Valued Program Analysis}},
url = {http://link.springer.com/10.1007/3-540-45309-1{\_}11},
year = {2001}
}
@inproceedings{ingolfo-souza:seams13,
abstract = {The great impact that law has on the design of software systems has been widely recognized in past years. However, little attention has been paid to the challenge of coping with variability characterizing the legal domain (e.g., multiple ways to comply with a given law, frequent updates to regulations, different jurisdictions, etc.) on the design of software systems. This position paper advocates the use of adaptation mechanisms in order to support regulatory compliance for software systems. First we show an example of how Zanshin, a requirements-based adaptation framework, can be used to design a system that adapts to legal requirements to accommodate legal variability. Then we examine how legal texts can be analyzed as sources for parameters and indicators needed to support adaptation. As motivating running example we consider legal situations concerning the Google driverless car and its recent legalization in the highways of Nevada and soon also in California.},
address = {San Francisco, CA, USA},
author = {Ingolfo, Silvia and Souza, V{\'{i}}tor E. S.},
booktitle = {Proc. of the 8th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1109/SEAMS.2013.6595503},
file = {:Users/vitor/Mendeley/Ingolfo, Souza - 2013 - Law and Adaptivity in Requirements Engineering.pdf:pdf},
keywords = {adaptation framework,bibtex,export,legal variability,regulatory compliance,requirements engineering},
mendeley-tags = {bibtex,export},
month = {may},
pages = {163--168},
publisher = {IEEE},
title = {{Law and Adaptivity in Requirements Engineering}},
url = {http://dl.acm.org/citation.cfm?id=2487362},
year = {2013}
}
@book{inmon:book05,
abstract = {The new edition of the classic bestseller that launched the data warehousing industry covers new approaches and technologies, many of which have been pioneered by Inmon himself. In addition to explaining the fundamentals of data warehouse systems, the book covers new topics such as methods for handling unstructured data in a data warehouse and storing data across multiple storage media. Discusses the pros and cons of relational versus multidimensional design and how to measure return on investment in planning data warehouse projects. Covers advanced topics, including data monitoring and testing},
author = {Inmon, William H.},
edition = {4th},
isbn = {978-0-7645-9944-6},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Wiley},
title = {{Building the Data Warehouse}},
url = {http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0764599445,descCd-collegeFeatures.html},
year = {2005}
}
@article{iwasaki:expert97,
abstract = {Qualitative reasoning has attracted much interest from the artificial intelligence research community in the last decade. The emphasis in qualitative reasoning on making inferences about the behavior of physical systems where there is incomplete information makes the technology relevant to many real-world industrial problems. Many applications of qualitative reasoning technology have emerged for such tasks as diagnosis, design, tutoring, real-time monitoring and hazard identification. This article showcases some of these recent applications},
author = {Iwasaki, Yumi},
doi = {10.1109/64.590068},
file = {:Users/vitor/Mendeley/Iwasaki - 1997 - Real-World Applications of Qualitative Reasoning.pdf:pdf},
issn = {0885-9000},
journal = {IEEE Expert},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {may},
number = {3},
pages = {16--21},
publisher = {IEEE},
title = {{Real-World Applications of Qualitative Reasoning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=590068},
volume = {12},
year = {1997}
}
@inproceedings{jain-et-al:aaaiss10,
abstract = {In this position paper, we argue that the Linked Open Data (LoD) Cloud, in its current form, is only of limited value for furthering the Semantic Web vision. Being merely a weakly linked 'triple collection', it will only be of very limited benefit for the AI or Semantic Web communities. We describe the corresponding problems with the LoD Cloud and give directions for research to remedy the situation.},
address = {Palo Alto, CA, USA},
author = {Jain, Prateek and Hitzler, Pascal and Yeh, Peter Z. and Verma, Kunal and Sheth, Amit},
booktitle = {Proc. of the 2010 AAAI Spring Symposium (AAAISS '10)},
editor = {Brickley, Dan and Chaudhri, Vinay K. and Halpin, Harry and McGuiness, Deborah},
file = {:Users/vitor/Mendeley/Jain et al. - 2010 - Linked Data is Merely More Data.pdf:pdf},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {mar},
pages = {82--86},
publisher = {AAAI Press},
title = {{Linked Data is Merely More Data}},
url = {http://www.aaai.org/ocs/index.php/SSS/SSS10/paper/view/1130},
year = {2010}
}
@article{janik-et-al:is11,
abstract = {The World Wide Web has turned hypertext into a success story by enabling world-wide sharing of unstructured information and informal knowledge. The Semantic Web targets the sharing of structured information and formal knowledge pursuing objectives of achieving collective intelligence on the Web. Germane to the structure of the Semantic Web is a layering and standardization of concerns. These concerns are reflected by an architecture of the Semantic Web that we present through a common use case. Semantic Web data for the use case is now found on the Web and is part of a quickly growing set of Semantic Web resources available for formal processing.},
author = {Janik, Maciej and Scherp, Ansgar and Staab, Steffen},
doi = {10.1007/s00287-011-0535-x},
file = {:Users/vitor/Mendeley/Janik, Scherp, Staab - 2011 - The Semantic Web Collective Intelligence on the Web.pdf:pdf},
issn = {0170-6012},
journal = {Informatik-Spektrum},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {sep},
number = {5},
pages = {469--483},
publisher = {Springer},
title = {{The Semantic Web: Collective Intelligence on the Web}},
url = {http://link.springer.com/10.1007/s00287-011-0535-x},
volume = {34},
year = {2011}
}
@article{jarzabek-et-al:jss03,
abstract = {Domain models describe common and variant requirements for a family of similar systems. Although most of the notations, such as UML, are meant for modeling a single system, they can be extended to model variants. We have done that and applied such extended notations in our projects. We soon found that our models with variants were becoming overly complicated, undermining the major role of domain analysis which is understanding. One variant was often reflected in many models and any given model was affected by many variants. The number of possible variant combinations was growing rapidly and mutual dependencies among variants even further complicated the domain model. We realized that our purely descriptive domain model was only useful for small examples but it did not scale up. In this paper, we describe a modeling method and a Flexible Variant Configuration tool (FVC for short) that alleviate the above mentioned problems. In our approach, we start by modeling so-called domain defaults, i.e., requirements that characterize a typical system in a domain. Then, we describe variants as deltas in respect to domain defaults. The FVC interprets variants to produce customized domain model views for a system that meets specific requirements. We implemented the above concepts using commercial tools Netron Fusion™ and Rational Rose™. In the paper, we illustrate our domain modeling method and tool with examples from the Facility Reservation System domain.},
author = {Jarzabek, Stan and Ong, Wai Chun and Zhang, Hongyu},
doi = {10.1016/S0164-1212(03)00060-8},
file = {:Users/vitor/Mendeley/Jarzabek, Ong, Zhang - 2003 - Handling variant requirements in domain modeling.pdf:pdf},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {bibtex,commented,domain analysis and modeling,frame technology,reuse,system families,varian requirements},
mendeley-tags = {bibtex,commented},
month = {dec},
number = {3},
pages = {171--182},
publisher = {Elsevier},
title = {{Handling variant requirements in domain modeling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121203000608},
volume = {68},
year = {2003}
}
@book{aosd10,
abstract = {It is our pleasure to welcome you to the 9th ACM International Conference on Aspect-Oriented Software Development (AOSD.10). This volume comprises the final versions of the research and industry papers presented at the AOSD.10 conference held in Rennes and Saint-Malo, France, March 15-19, 2010. The proceedings also contain the abstracts of the keynote presentations. AOSD.10 is the ninth edition in a series of annual AOSD conferences. The series started in 2002 in Enschede (The Netherlands), followed by Boston, Massachusetts (USA) in 2003, Lancaster (UK) in 2004, Chicago, Illinois (USA) in 2005, Bonn (Germany) in 2006, Vancouver (Canada) in 2007, Brussels (Belgium) in 2008, Charlottesville, Virginia (USA) in 2009 and now Rennes and Saint-Malo, France in 2010. This year's conference continues the tradition of being the premier forum for presentation of research and industry results on leading-edge issues in aspect-oriented software development. The conference reflects the remarkable growth in scale and complexity of the systems now being developed, where modularity and abstraction are essential, not only in code, but across many kinds of software artifacts. Following its predecessors, its focus has been broadening to include other activities of software and systems development, such as software and systems specification, architecture, and adaptation. The mission of this edition is to fulfill the needs of heterogeneous applications and environments, and to identify new directions for future research and development. AOSD.10 gives academia and industry a unique opportunity to share perspectives with others who are interested in the various forms of modularity and abstraction.},
address = {Rennes and Saint Malo, France},
editor = {Jezequel, Jean-Marc and Sudholt, Mario},
isbn = {978-1-60558-958-9},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {ACM},
title = {{Proceedings of the 9th International Conference on Aspect-Oriented Software Development}},
url = {http://dl.acm.org/citation.cfm?id=1739230},
year = {2010}
}
@article{jhala-majumdar:acmcs09,
abstract = {We survey recent progress in software model checking.},
author = {Jhala, Ranjit and Majumdar, Rupak},
doi = {10.1145/1592434.1592438},
file = {:Users/vitor/Mendeley/Jhala, Majumdar - 2009 - Software model checking.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
keywords = {bibtex},
mendeley-tags = {bibtex},
number = {4},
pages = {1--54},
publisher = {ACM},
title = {{Software model checking}},
url = {http://portal.acm.org/citation.cfm?doid=1592434.1592438},
volume = {41},
year = {2009}
}
@inproceedings{jovan-zorzut:cis06,
abstract = {Improving production performance requires the definition of global production objectives with a proper implementation strategy and suitable closed-loop control for their achievement. Closed-loop control structures for simple systems like temperature or velocity control are well defined, but a synthesis of plant-wide control structures is still recognised as the most crucial production management design problem in process industries. One vital issue to be resolved is how to translate implicit operating objectives, such as the minimisation of production costs into a set of measurable variables that can be then used in a feedback-control. A promising solution is the use of the Key Performance Indicator (KPI) approach. To verify the idea of production feedback control using production KPIs as referenced controlled variables, a procedural model of a production process for a polymerisation plant has been developed. The model has been used during a number of simulation runs performed with the aim of developing and verifying the idea of KPI-based production control.},
address = {Bangkok, Thailand},
author = {Jovan, Vladimir and Zorzut, Sebastjan},
booktitle = {Proc. of the 2006 IEEE Conference on Cybernetics and Intelligent Systems},
doi = {10.1109/ICCIS.2006.252343},
file = {:Users/vitor/Mendeley/Jovan, Zorzut - 2006 - Use of Key Performance Indicators in Production Management.pdf:pdf},
isbn = {1-4244-0022-8},
keywords = {bibtex,closed-loop control,decision support systems,key performance indicators,not-commented,production management,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
month = {jun},
pages = {1--6},
publisher = {IEEE},
title = {{Use of Key Performance Indicators in Production Management}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4017902},
year = {2006}
}
@inproceedings{jureta-et-al:re10,
abstract = {Techne is an abstract requirements modeling language that lays formal foundations for new modeling languages applicable during early phases of the requirements engineering process. During these phases, the requirements problem for the system-to-be is being structured, its candidate solutions described and compared in terms of how desirable they are to stakeholders. We motivate the need for Techne, introduce it through examples, and sketch its formalization.},
address = {Sydney, Australia},
author = {Jureta, Ivan J. and Borgida, Alex and Ernst, Neil A. and Mylopoulos, John},
booktitle = {Proc. of the 18th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2010.24},
file = {:Users/vitor/Mendeley/Jureta et al. - 2010 - Techne Towards a New Generation of Requirements Modeling Languages with Goals, Preferences, and Inconsistency Han.pdf:pdf},
isbn = {978-1-4244-8022-7},
keywords = {bibtex,goal-oriented requirements engineering,requirements modeling languages,requirements models},
mendeley-tags = {bibtex},
month = {sep},
pages = {115--124},
publisher = {IEEE},
title = {{Techne: Towards a New Generation of Requirements Modeling Languages with Goals, Preferences, and Inconsistency Handling}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5636885},
year = {2010}
}
@inproceedings{jureta-et-al:re08,
abstract = {In their seminal paper in the ACM Transactions on Software Engineering and Methodology, Zave and Jackson established a core ontology for requirements engineering (RE) and used it to formulate the "requirements problem", thereby defining what it means to successfully complete RE. Given that stakeholders of the system-to-be communicate the information needed to perform RE, we show that Zave and Jackson's ontology is incomplete. It does not cover all types of basic concerns that the stakeholders communicate. These include beliefs, desires, intentions, and attitudes. In response, we propose a core ontology that covers these concerns and is grounded in sound conceptual foundations resting on a foundational ontology. The new core ontology for RE leads to a new formulation of the requirements problem that extends Zave and Jackson's formulation. We thereby establish new standards for what minimum information should be represented in RE languages and new criteria for determining whether RE has been successfully completed.},
address = {Barcelona, Spain},
author = {Jureta, Ivan J. and Mylopoulos, John and Faulkner, Stephane},
booktitle = {Proc. of the 16th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2008.13},
file = {:Users/vitor/Mendeley/Jureta, Mylopoulos, Faulkner - 2008 - Revisiting the Core Ontology and Problem in Requirements Engineering.pdf:pdf},
isbn = {978-0-7695-3309-4},
issn = {1090-705X},
keywords = {bibtex,core ontology,formal specification,ontologies,requirements engineering,requirements problem,x-commented},
mendeley-tags = {bibtex,x-commented},
month = {sep},
pages = {71--80},
publisher = {IEEE},
title = {{Revisiting the Core Ontology and Problem in Requirements Engineering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4685655},
year = {2008}
}
@inproceedings{kaddoum-et-al:seams10,
abstract = {In the last years, the growing complexity of the current applications has led to the design of self-adapting systems presenting self- properties. These systems are composed of several autonomous interactive entities. They behave autonomously and present enhanced characteristics allowing them to handle dynamics coming from exogenous and endogenous changes. In this paper, we propose a set of criteria for the description and evaluation of the adaptive properties of such systems. They aim to provide a concrete mechanism to analyze the quality of the design of adaptive systems, to evaluate the effect of self- properties on the performances and to compare the adaptive features of different systems. The criteria are grouped into different categories: methodological, architectural, intrinsic, and runtime evaluation. They have been identified and specified by analyzing several case studies, which address self-adaptivity issues through different approaches with different objectives in various application contexts.},
address = {Cape Town, South Africa},
author = {Kaddoum, Elsy and Raibulet, Claudia and Georg{\'{e}}, Jean-Pierre and Picard, Gauthier and Gleizes, Marie-Pierre},
booktitle = {Proc. of the 2010 ICSE Workshop on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1145/1808984.1808988},
file = {:Users/vitor/Mendeley/Kaddoum et al. - 2010 - Criteria for the Evaluation of Self- Systems.pdf:pdf},
isbn = {9781605589718},
keywords = {bibtex,characterization,commented,comparison,evaluation,self-* systems},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {29--38},
publisher = {ACM},
title = {{Criteria for the Evaluation of Self-* Systems}},
url = {http://portal.acm.org/citation.cfm?doid=1808984.1808988},
year = {2010}
}
@article{kaindl:ase97,
abstract = {According to our experience in real‐world projects, we still observe deficiencies of current methods for object‐oriented analysis (OOA), especially in respect to the early elicitation and definition of requirements. Therefore, we used object‐oriented technology and hypertext to develop a practical approach – with tool support – that tightly combines OOA with requirements definition. This novel approach is compatible with virtually any OOA method. While more work needs to be done especially for supporting the process of requirements definition, the observed deficiencies and current limitations of existing OOA methods are addressed and partly removed through this combination. We have applied our approach in real‐world projects, and our experience suggests the usefulness of this approach. Essentially, its use leads to a more complete and structured definition of the requirements, and consequently we derive some recommendations for practitioners.},
annote = {10.1023/A:1018954425162},
author = {Kaindl, Hermann},
doi = {10.1023/A:1018954425162},
file = {:Users/vitor/Mendeley/Kaindl - 1997 - A practical approach to combining requirements definition and object-oriented analysis.pdf:pdf},
issn = {1022-7091},
journal = {Annals of Software Engineering},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
number = {1},
pages = {319--343},
publisher = {Springer Netherlands},
title = {{A practical approach to combining requirements definition and object-oriented analysis}},
url = {http://www.springerlink.com/content/u841237202862011/},
volume = {3},
year = {1997}
}
@inproceedings{kang-han:iccit08,
abstract = {Recently, strong interests in the real-time performance management are increasing to gain competitive advantages in the rapidly changing business environment. For better business performance or continuous process improvement of an enterprise, real-time measurement and analysis of the performance of managerial activities is essential. Business Activity Monitoring (BAM) which provides real-time access to key performance indicators is one of core elements for the real-time performance management. A BAM system prototype is designed and implemented for a global automotive company in this paper. This paper presents the design procedure and implementation result of BAM system. This paper is expected to be a practical help to the practitioners who are planning and executing the BAM system implementation for the real-time performance management.},
address = {Daejeon, Korea},
author = {Kang, Jin Gu and Han, Kwan Hee},
booktitle = {Proc. of the 3rd International Conference on Convergence and Hybrid Information Technology},
doi = {10.1109/ICCIT.2008.224},
file = {:Users/vitor/Mendeley/Kang, Han - 2008 - A Business Activity Monitoring System Supporting Real-Time Business Performance Management.pdf:pdf},
isbn = {978-0-7695-3407-7},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {aug},
pages = {473--478},
publisher = {IEEE},
title = {{A Business Activity Monitoring System Supporting Real-Time Business Performance Management}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4682072},
year = {2008}
}
@article{kang-et-al:software02,
abstract = {The feature-oriented reuse method analyzes and models a product line's commonalities and differences in terms of product features and uses the analysis results to develop architectures and components. The article illustrates, with a home integration system example, how FORM brings efficiency into product line development.},
author = {Kang, Kyo C. and Lee, Jaejoon and Donohoe, Patrick},
doi = {10.1109/MS.2002.1020288},
file = {:Users/vitor/Mendeley/Kang, Lee, Donohoe - 2002 - Feature-oriented product line engineering.pdf:pdf},
issn = {0740-7459},
journal = {IEEE Software},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {jul},
number = {4},
pages = {58--65},
publisher = {IEEE},
title = {{Feature-oriented product line engineering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1020288},
volume = {19},
year = {2002}
}
@article{kephart-chess:computer03,
abstract = {Systems manage themselves according to an administrator's goals. New components integrate as effortlessly as a new cell establishes itself in the human body. These ideas are not science ﬁction, but elements of the grand challenge to create self-managing computing systems.},
author = {Kephart, Jeffrey O. and Chess, David M.},
doi = {10.1109/MC.2003.1160055},
file = {:Users/vitor/Mendeley/Kephart, Chess - 2003 - The vision of autonomic computing.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {jan},
number = {1},
pages = {41--50},
publisher = {IEEE},
title = {{The vision of autonomic computing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1160055},
volume = {36},
year = {2003}
}
@inproceedings{khan-et-al:icas08,
abstract = {Autonomic computing is an emerging philosophy which promises to enable self-management capabilities in software systems. These self-management properties include self-configuration, self-healing, self-protection, self-optimization, self-awareness and self-governance. Enabling any of these properties in software systems is an open challenge. Exhibiting such self-management behavior is a continuous process in the software life cycle. Case-based reasoning is a problem solving methodology which exploits past experience. Past experience is maintained in the form of problem-solution pairs, also called cases. On the arrival of new problem, solution of past similar problems is used after appropriate adaptation. This problem solving technique can be used to achieve some of the properties of autonomic systems based on experience. To find this solution, entire experience space is searched which reduces efficiency. To overcome this efficiency problem, we restrict the fast growth of case repository, so that every time we have to search a very limited number of cases. We applied the proposed approach on a simulation of Autonomic Forest Fire application for self-configuration capability. Our results show that the proposed approach is quite promising in terms of accuracy as well as efficiency.},
address = {Gosier, Guadeloupe},
author = {Khan, Malik J. and Awais, Mian M. and Shamail, Shafay},
booktitle = {Proc. of the 4th International Conference on Autonomic and Autonomous Systems},
doi = {10.1109/ICAS.2008.44},
file = {:Users/vitor/Mendeley/Khan, Awais, Shamail - 2008 - Enabling Self-Configuration in Autonomic Systems using Case-Based Reasoning with Improved Efficiency.pdf:pdf},
isbn = {978-0-7695-3093-2},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {mar},
pages = {112--117},
publisher = {IEEE},
title = {{Enabling Self-Configuration in Autonomic Systems using Case-Based Reasoning with Improved Efficiency}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4488331},
year = {2008}
}
@article{khoroshevskii:stip11,
abstract = {A new line of investigation that integrates studies on artificial intelligence and Internet technologies, which is known as the Semantic Web, is presented. A review of the present state of research is given; problems on the establishment of knowledge spaces on the Internet, the means and methods for the extraction of knowledge from texts in natural languages, as well as questions on the use of knowledge spaces in the creation of applied intelligent systems operating on the Internet, are considered.},
author = {Khoroshevskii, V. F.},
doi = {10.3103/S0147688210060079},
file = {:Users/vitor/Mendeley/Khoroshevskii - 2011 - Knowledge spaces on the internet and Semantic Web (part 1).pdf:pdf},
issn = {0147-6882},
journal = {Scientific and Technical Information Processing},
keywords = {bibtex,commented,extraction of knowledge,intelligen systems,the semantic web},
mendeley-tags = {bibtex,commented},
month = {feb},
number = {6},
pages = {418--431},
publisher = {Allerton Press},
title = {{Knowledge spaces on the internet and Semantic Web (part 1)}},
url = {http://www.springerlink.com/index/10.3103/S0147688210060079},
volume = {37},
year = {2011}
}
@incollection{kiczales-et-al:ecoop97,
abstract = {We have found many programming problems for which neither procedural nor object-oriented programming techniques are sufficient to clearly capture some of the important design decisions the program must implement. This forces the implementation of those design decisions to be scattered throughout the code, resulting in “tangled” code that is excessively difficult to develop and maintain. We present an analysis of why certain design decisions have been so difficult to clearly capture in actual code. We call the properties these decisions address aspects, and show that the reason they have been hard to capture is that they cross-cut the system's basic functionality. We present the basis for a new programming technique, called aspect-oriented programming, that makes it possible to clearly express programs involving such aspects, including appropriate isolation, composition and reuse of the aspect code. The discussion is rooted in systems we have built using aspect-oriented programming.},
author = {Kiczales, Gregor and Lamping, John and Mendhekar, Anurag and Maeda, Chris and Lopes, Cristina and Loingtier, Jean-Marc and Irwin, John},
booktitle = {ECOOP'97 --- Object-Oriented Programming},
doi = {10.1007/BFb0053381},
editor = {Akşit, Mehmet and Matsuoka, Satoshi},
isbn = {978-3-540-63089-0},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
pages = {220--242},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Aspect-oriented programming}},
url = {http://dx.doi.org/10.1007/BFb0053381},
volume = {1241},
year = {1997}
}
@book{kimball-roos:book02,
abstract = {The latest edition of the single most authoritative guide on dimensional modeling for data warehousing! Dimensional modeling has become the most widely accepted approach for data warehouse design. Here is a complete library of dimensional modeling techniques-- the most comprehensive collection ever written. Greatly expanded to cover both basic and advanced techniques for optimizing data warehouse design, this second edition to Ralph Kimball's classic guide is more than sixty percent updated. The authors begin with fundamental design recommendations and gradually progress step-by-step through increasingly complex scenarios. Clear-cut guidelines for designing dimensional models are illustrated using real-world data warehouse case studies drawn from a variety of business application areas and industries, including: * Retail sales and e-commerce * Inventory management * Procurement * Order management * Customer relationship management (CRM) * Human resources management * Accounting * Financial services * Telecommunications and utilities * Education * Transportation * Health care and insurance By the end of the book, you will have mastered the full range of powerful techniques for designing dimensional databases that are easy to understand and provide fast query response. You will also learn how to create an architected framework that integrates the distributed data warehouse using standardized dimensions and facts.},
author = {Kimball, Ralph and Ross, Margy},
edition = {2nd},
isbn = {978-0-471-20024-6},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Wiley},
title = {{The Data Warehouse Toolkit: The Complete Guide to Dimensional Modeling}},
url = {http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0471200247.html},
year = {2002}
}
@inproceedings{kitchenham-et-al:icease12,
abstract = {Context: We have been undertaking a series of case studies to investigate the value of mapping (scoping) studies in software engineering. Our previous studies have assessed these using the subjective opinions of researchers. Objective: In order to provide a more objective assessment of value, for this study, we used the results of a systematic mapping study to investigate how well mapping studies identify clusters of related studies and to what extent such clusters are complete. Method: In this participant-observer case study, we undertook a mapping study of unit testing and regression testing empirical studies, which we compared with a previous expert literature review and with six other mapping studies and systematic literature reviews (SLRs) that addressed overlapping topics. Results: Our mapping study found more clusters than the expert literature review although it benefited from the set of studies identified by the expert review when refining our search process. The set of studies found by our searches were less complete than those found by SLRs addressing more specific topics, although we found some studies missed by those SLRs. Conclusions: Researchers undertaking systematic reviews and mapping studies should make use of related systematic reviews and mapping studies to identify known studies in order to refine search strings and validate search results. For completeness and traceability, mapping studies should keep a record of all multiple reports of a single study. Meta-analyses and other systematic literature reviews undertaking detailed aggregation should report on candidate primary studies that were rejected in the final screening process, as well as candidate studies that were included. This helps ensure the repeatability of aggregation results.},
address = {Ciudad Real, Spain},
author = {Kitchenham, B. and Brereton, P. and Budgen, D.},
booktitle = {Proc. of the 16th International Conference on Evaluation {\&} Assessment in Software Engineering},
doi = {10.1049/ic.2012.0016},
file = {:Users/vitor/Mendeley/Kitchenham, Brereton, Budgen - 2012 - Mapping study completeness and reliability - a case study.pdf:pdf},
isbn = {978-1-84919-541-6},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {may},
pages = {126--135},
publisher = {IET},
title = {{Mapping study completeness and reliability - a case study}},
url = {http://digital-library.theiet.org/content/conferences/10.1049/ic.2012.0016},
year = {2012}
}
@article{kitchenham-et-al:jist11,
abstract = {Context: We are strong advocates of evidence-based software engineering (EBSE) in general and systematic literature reviews (SLRs) in particular. We believe it is essential that the SLR methodology is used constructively to support software engineering research. Objective: This study aims to assess the value of mapping studies which are a form of SLR that aims to identify and categorise the available research on a broad software engineering topic. Method: We used a multi-case, participant-observer case study using five examples of studies that were based on preceding mapping studies. We also validated our results by contacting two other researchers who had undertaken studies based on preceding mapping studies and by assessing review comments related to our follow-on studies. Results: Our original case study identified 11 unique benefits that can accrue from basing research on a preceding mapping study of which only two were case specific. We also identified nine problems associated with using preceding mapping studies of which two were case specific. These results were consistent with the information obtained from the validation activities. We did not find an example of an independent research group making use of a mapping study produced by other researchers. Conclusion: Mapping studies can save time and effort for researchers and provide baselines to assist new research efforts. However, they must be of high quality in terms of completeness and rigour if they are to be a reliable basis for follow-on research.},
author = {Kitchenham, Barbara A. and Budgen, David and {Pearl Brereton}, O.},
doi = {10.1016/j.infsof.2010.12.011},
file = {:Users/vitor/Mendeley/Kitchenham, Budgen, Pearl Brereton - 2011 - Using mapping studies as the basis for further research – A participant-observer case stud.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {bibtex},
mendeley-tags = {bibtex},
number = {6},
pages = {638--651},
publisher = {Elsevier},
title = {{Using mapping studies as the basis for further research – A participant-observer case study}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584910002272},
volume = {53},
year = {2011}
}
@techreport{kitchenham-charters:techrep07,
abstract = {The objective of this report is to propose comprehensive guidelines for systematic literature reviews appropriate for software engineering researchers, including PhD students. A systematic literature review is a means of evaluating and interpreting all available research relevant to a particular research question, topic area, or phenomenon of interest. Systematic reviews aim to present a fair evaluation of a research topic by using a trustworthy, rigorous, and auditable methodology. The guidelines presented in this report were derived from three existing guidelines used by medical researchers, two books produced by researchers with social science backgrounds and discussions with researchers from other disciplines who are involved in evidence-based practice. The guidelines have been adapted to reflect the specific problems of software engineering research. The guidelines cover three phases of a systematic literature review: planning the review, conducting the review and reporting the review. They provide a relatively high level description. They do not consider the impact of the research questions on the review procedures, nor do they specify in detail the mechanisms needed to perform meta-analysis.},
author = {Kitchenham, Barbara A. and Charters, Stuart},
file = {:Users/vitor/Mendeley/Kitchenham, Charters - 2007 - Guidelines for performing Systematic Literature Reviews in Software Engineering.pdf:pdf},
institution = {Keele University, UK},
keywords = {bibtex,summarized},
mendeley-tags = {bibtex,summarized},
title = {{Guidelines for performing Systematic Literature Reviews in Software Engineering}},
url = {https://www.cs.auckland.ac.nz/{~}mria007/Sulayman/Systematic{\_}reviews{\_}5{\_}8.pdf},
year = {2007}
}
@article{kitchenham-et-al:tse02,
abstract = {Empirical software engineering research needs research guidelines to improve the research and reporting processes. We propose a preliminary set of research guidelines aimed at stimulating discussion among software researchers. They are based on a review of research guidelines developed for medical researchers and on our own experience in doing and reviewing software engineering research. The guidelines are intended to assist researchers, reviewers, and meta-analysts in designing, conducting, and evaluating empirical studies. Editorial boards of software engineering journals may wish to use our recommendations as a basis for developing guidelines for reviewers and for framing policies for dealing with the design, data collection, and analysis and reporting of empirical studies.},
author = {Kitchenham, Barbara A. and Pfleeger, Shari L. and Pickard, Lesley M. and Jones, Peter W. and Hoaglin, David C. and {El Emam}, Khaled and Rosenberg, Jarrett},
doi = {10.1109/TSE.2002.1027796},
file = {:Users/vitor/Mendeley/Kitchenham et al. - 2002 - Preliminary guidelines for empirical research in software engineering.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {bibtex,empirical software research,research guidelines,statistical mistakes,summarized},
mendeley-tags = {bibtex,summarized},
month = {aug},
number = {8},
pages = {721--734},
publisher = {IEEE},
title = {{Preliminary guidelines for empirical research in software engineering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1027796},
volume = {28},
year = {2002}
}
@article{kitchenham-et-al:ist10,
abstract = {Context In a previous study, we reported on a systematic literature review (SLR), based on a manual search of 13 journals and conferences undertaken in the period 1st January 2004 to 30th June 2007. Objective The aim of this on-going research is to provide an annotated catalogue of SLRs available to software engineering researchers and practitioners. This study updates our previous study using a broad automated search. Method We performed a broad automated search to find SLRs published in the time period 1st January 2004 to 30th June 2008. We contrast the number, quality and source of these SLRs with SLRs found in the original study. Results Our broad search found an additional 35 SLRs corresponding to 33 unique studies. Of these papers, 17 appeared relevant to the undergraduate educational curriculum and 12 appeared of possible interest to practitioners. The number of SLRs being published is increasing. The quality of papers in conferences and workshops has improved as more researchers use SLR guidelines. Conclusion SLRs appear to have gone past the stage of being used solely by innovators but cannot yet be considered a main stream software engineering research methodology. They are addressing a wide range of topics but still have limitations, such as often failing to assess primary study quality.},
author = {Kitchenham, Barbara A. and Pretorius, Rialette and Budgen, David and {Pearl Brereton}, O. and Turner, Mark and Niazi, Mahmood and Linkman, Stephen},
doi = {10.1016/j.infsof.2010.03.006},
editor = {Wohlin, Claes},
file = {:Users/vitor/Mendeley/Kitchenham et al. - 2010 - Systematic literature reviews in software engineering – A tertiary study.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {bibtex,mapping study,software engineering,summarized,systematic literature review,tertiary study},
mendeley-tags = {bibtex,summarized},
month = {aug},
number = {8},
pages = {792--805},
publisher = {Elsevier},
title = {{Systematic literature reviews in software engineering – A tertiary study}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584910000467},
volume = {52},
year = {2010}
}
@inproceedings{kitchenham-et-al:icse10,
abstract = {We identify three challenges related to the provenance of the material we use in teaching software engineering. We suggest that these challenges can be addressed by using evidence-based software engineering (EBSE) and its primary tool of systematic literature reviews (SLRs). This paper aims to assess the educational and scientific value of undergraduate and postgraduate students undertaking a specific form of SLR called a mapping study. Using a case study methodology, we asked three postgraduate students and three undergraduates and their supervisor to complete a questionnaire concerning the educational value of mapping studies and any problems they experienced. Students found undertaking a mapping study to be a valuable experience providing both reusable research skills and a good overview of a research topic. Postgraduates found it useful as a starting point for their studies. Undergraduates reported problems undertaking the study in the required timescales. Searching and classifying the literature was difficult.},
address = {Cape Town, South Africa},
author = {Kitchenham, Barbara and Brereton, Pearl and Budgen, David},
booktitle = {Proc. of the 32nd ACM/IEEE International Conference on Software Engineering},
doi = {10.1145/1806799.1806887},
file = {:Users/vitor/Mendeley/Kitchenham, Brereton, Budgen - 2010 - The educational value of mapping studies of software engineering literature.pdf:pdf},
isbn = {9781605587196},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {may},
pages = {589--598},
publisher = {ACM},
title = {{The educational value of mapping studies of software engineering literature}},
url = {http://portal.acm.org/citation.cfm?doid=1806799.1806887},
volume = {1},
year = {2010}
}
@inproceedings{knauss:re12,
abstract = {Today's systems are faced with the need of constant evolution to remain competitive, especially when looking at IT Ecosystems and their growing number of subsystems. As a prerequisite for these to stay competitive, system providers need a clear understanding of their stakeholder's needs. As systems tend to be increasingly complex nowadays, support an increasingly number of stakeholders, have a shorter release cycles to evolve and need to adapt to the environment and the users, some of the standard requirements elicitation techniques tend not to be suitable any more. Especially when adaptivity is necessary, system providers need to understand the context, in which the systems are used, but also the context of users for the adaptation. In this paper I concentrate on the largest stakeholder group, namely the end-users for requirements elicitation. Evaluation criteria include (i) support of context, (ii) scalability to large numbers of end-users, and (iii) scalability to large numbers of end-user's needs and problems that lead to new requirements. My literature review suggests that this important field is currently underrepresented in Requirements Engineering research. This research proposes to develop a framework that explains the different context types and their role for requirements elicitation. The framework is then used to investigate existing requirements elicitation techniques and their potential for considering context. It is also used to show how emerging techniques can further support requirements elicitation with context.},
address = {Chicago, IL, USA},
author = {Knauss, Alessia},
booktitle = {Proc. of the 20th IEEE International Requirements Engineering Conference (RE '12)},
doi = {10.1109/RE.2012.6345835},
file = {:Users/vitor/Mendeley/Knauss - 2012 - On the usage of context for requirements elicitation End-user involvement in IT ecosystems.pdf:pdf},
isbn = {978-1-4673-2785-5},
keywords = {bibtex,commented,end-user involvement,observation,requirements elicitation,social media},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {345--348},
publisher = {IEEE},
title = {{On the usage of context for requirements elicitation: End-user involvement in IT ecosystems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6345835},
year = {2012}
}
@inproceedings{knauss-et-al:empire10,
abstract = {IT ecosystems are large software systems that consist of various, constantly interacting and partly autonomous subsystems as well as stakeholders of the overall system. Because of these specific properties, such systems are a highly relevant research area in the field of requirements engineering. In this paper we describe our approach to investigate and to model the flow of requirements in IT ecosystems. We are currently applying this approach in a case study in the IBM Collaborative Lifecycle Management project. This project is of particular relevance to the requirements engineering community because of its open commercial approach. This paper contributes by highlighting challenges of requirements engineering in IT ecosystems, i.e. contextualizing requirements, mapping them to subsystems, and communicating them to stakeholders. We define research questions and describe a mixed method approach to answer them.},
address = {Chicago, IL, USA},
author = {Knauss, Alessia and Borici, Arber and Knauss, Eric and Damian, Daniela},
booktitle = {Proc. of the 2nd IEEE International Workshop on Empirical Requirements Engineering (EmpiRE '10)},
doi = {10.1109/EmpiRE.2012.6347679},
file = {:Users/vitor/Mendeley/Knauss et al. - 2012 - Towards understanding requirements engineering in IT ecosystems.pdf:pdf},
isbn = {978-1-4673-4365-7},
keywords = {bibtex,commented,ecosystem,mixed method research,requirement flow,stakeholder analysis},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {33--36},
publisher = {IEEE},
title = {{Towards understanding requirements engineering in IT ecosystems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6347679},
year = {2012}
}
@inproceedings{knauss-et-al:creare12,
abstract = {When improving existing software systems, requirements engineers have to capture stakeholder needs. These needs have to be transformed into improvements of the system. Creative processes accompany this task. Especially when improving large systems with many heterogeneous stakeholders, it is difficult to consider all stakeholders. End-users of the system can be a valuable source of creativity in discovering requirements, currently not sufficiently supported in conventional requirements engineering methods. Today, these end-users are adept in using new techniques (e.g. multimedia, and social media). This allows using these techniques to establish a community of practice, facilitate creativity among end-users, and leverage this source of creativity in requirements engineering. In this paper we describe our vision on how to support end-users by leveraging novel modes of interaction such as social media and multimedia. We propose a number of research questions grounded in related work in the areas of creativity, social media and multimedia.},
address = {Essen, Germany},
author = {Knauss, Alessia and Knauss, Eric and Damian, Daniela},
booktitle = {Workshop Proceedings of the 18th International Working Conference on Requirements Engineering: Foundation for Software Quality (REFSQ '12) - ICB-Research Report},
file = {:Users/vitor/Mendeley/Knauss, Knauss, Damian - 2012 - Towards Supporting End-User Creativity with Social Media and Multimedia.pdf:pdf},
keywords = {bibtex,commented,end-user participation,multimedia,seeding,social media,user-centered requirements engineering},
mendeley-tags = {bibtex,commented},
month = {mar},
number = {52},
pages = {87--92},
publisher = {ICB-Research},
title = {{Towards Supporting End-User Creativity with Social Media and Multimedia}},
url = {http://www.icb.uni-due.de/fileadmin/ICB/research/research{\_}reports/ICB-Report{\_}No52.pdf},
year = {2012}
}
@article{knuth:spe89,
abstract = {This paper is a case study of program evolution. The author kept track of all changes made to TEX during a period of ten years, including the changes made when the original program was first debugged in 1978. The log book of these errors, numbering more than 850 items, appears as an appendix to this paper. The errors have been classified into fifteen categories for purposes of analysis, and some of the noteworthy bugs are discussed in detail. The history of the TEX project can teach valuable lessons about the preparation of highly portable software and the maintenance of programs that aspire to high standards of reliability.},
author = {Knuth, Donald E.},
doi = {10.1002/spe.4380190702},
file = {:Users/vitor/Mendeley/Knuth - 1989 - The errors of tex.pdf:pdf},
issn = {00380644},
journal = {Software: Practice and Experience},
keywords = {bibtex,commented,debugging,errors,language design,program evolution,tex,true confessions},
mendeley-tags = {bibtex,commented},
month = {jul},
number = {7},
pages = {607--685},
publisher = {Wiley},
title = {{The errors of tex}},
url = {http://doi.wiley.com/10.1002/spe.4380190702},
volume = {19},
year = {1989}
}
@article{kramer-magee:ieeeps98,
abstract = {The software architecture of a system is the overall structure of the system in terms of its constituent components and their interconnections. Dynamic changes to the instantiated system architecture (to the components and/or interconnections) may take place while it is running. In order that these changes do not violate the integrity of the system, we adopt a general model of dynamic configuration which only permits change to occur when the affected portions of the system are quiescent. This paper investigates the feasibility of performing behaviour analysis on systems which conform to the change model. The analysis approach associates behavioural specifications with the components of a software architecture and analyses the behaviour of systems composed from these components. The changes that can occur are modelled as constraints on the architecture, thereby permitting incremental and even concurrent changes. Analysis is used to check that the architecture satisfies the properties required of it: before, during and after the changes. The paper uses an example to illustrate the approach},
author = {Kramer, Jeff and Magee, Jeff},
doi = {10.1049/ip-sen:19982297},
file = {:Users/vitor/Mendeley/Kramer, Magee - 1998 - Analysing dynamic change in distributed software architectures.pdf:pdf},
issn = {14625970},
journal = {IEE Proceedings - Software},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
number = {5},
pages = {146},
publisher = {IEEE},
title = {{Analysing dynamic change in distributed software architectures}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=741284},
volume = {145},
year = {1998}
}
@incollection{kramer-magee:fose07,
abstract = {Self-management is put forward as one of the means by which we could provide systems that are scalable, support dynamic composition and rigorous analysis, and are flexible and robust in the presence of change. In this paper, we focus on architectural approaches to self-management, not because the language-level or network-level approaches are uninteresting or less promising, but because we believe that the architectural level seems to provide the required level of abstraction and generality to deal with the challenges posed. A self-managed software architecture is one in which components automatically configure their interaction in a way that is compatible with an overall architectural specification and achieves the goals of the system. The objective is to minimise the degree of explicit management necessary for construction and subsequent evolution whilst preserving the architectural properties implied by its specification. This paper discusses some of the current promising work and presents an outline three-layer reference model as a context in which to articulate some of the main outstanding research challenges.},
address = {Minneapolis, MN, USA},
author = {Kramer, Jeff and Magee, Jeff},
booktitle = {Future of Software Engineering (FOSE '07)},
doi = {10.1109/FOSE.2007.19},
file = {:Users/vitor/Mendeley/Kramer, Magee - 2007 - Self-Managed Systems an Architectural Challenge.pdf:pdf},
isbn = {0-7695-2829-5},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {may},
pages = {259--268},
publisher = {IEEE},
title = {{Self-Managed Systems: an Architectural Challenge}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4221625},
year = {2007}
}
@article{kramer-magee:tse90,
abstract = {A model for dynamic change management which separates structural concerns from component application concerns is presented. This separation of concerns permits the formulation of general structural rules for change at the configuration level without the need to consider application state, and the specification of application component actions without prior knowledge of the actual structural changes which may be introduced. In addition, the changes can be applied in such a way so as to leave the modified system in a consistent state, and cause no disturbance to the unaffected part of the operational system. The model is applied to an example problem, `evolving philosophers'. The principles of this model have been implemented and tested in the Conic environment for distributed systems},
author = {Kramer, Jeff and Magee, Jeff},
doi = {10.1109/32.60317},
file = {:Users/vitor/Mendeley/Kramer, Magee - 1990 - The evolving philosophers problem dynamic change management.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {bibtex,change management,commented,distributed systems,dynamic configuration,system evoluion},
mendeley-tags = {bibtex,commented},
number = {11},
pages = {1293--1306},
publisher = {IEEE},
title = {{The evolving philosophers problem: dynamic change management}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=60317},
volume = {16},
year = {1990}
}
@article{kramer-magee:jcst09,
abstract = {The engineering of distributed adaptive software is a complex task which requires a rigorous approach. Software architectural (structural) concepts and principles are highly beneficial in specifying, designing, analysing, constructing and evolving distributed software. A rigorous architectural approach dictates formalisms and techniques that are compositional, components that are context independent and systems that can be constructed and evolved incrementally. This paper overviews some of the underlying reasons for adopting an architectural approach, including a brief “rational history” of our research work, and indicates how an architectural model can potentially facilitate the provision of self-managed adaptive software system.},
annote = {10.1007/s11390-009-9216-5},
author = {Kramer, Jeff and Magee, Jeff},
doi = {10.1007/s11390-009-9216-5},
file = {:Users/vitor/Mendeley/Kramer, Magee - 2009 - A Rigorous Architectural Approach to Adaptive Software Engineering.pdf:pdf},
issn = {1000-9000},
journal = {Journal of Computer Science and Technology},
keywords = {adaptive systems,autonomic systems,bibtex,commented,self-managed systems,software architecture,summarized},
mendeley-tags = {bibtex,commented,summarized},
number = {2},
pages = {183--188},
publisher = {Springer},
title = {{A Rigorous Architectural Approach to Adaptive Software Engineering}},
url = {http://www.springerlink.com/content/c45045k272085145/},
volume = {24},
year = {2009}
}
@article{kramer-magee:pi08,
annote = {This publication has no abstract.},
author = {Kramer, Jeff and Magee, Jeff},
doi = {10.2201/NiiPi.2008.5.1},
file = {:Users/vitor/Mendeley/Kramer, Magee - 2008 - Towards robust self-managed systems.pdf:pdf},
journal = {Progress in Informatics},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
number = {5},
pages = {1--4},
publisher = {National Institute of Informatics, Japan},
title = {{Towards robust self-managed systems}},
url = {http://www.nii.ac.jp/pi/n5/5{\_}1.html},
year = {2008}
}
@article{kramer-wolf:acmsen96,
abstract = {The 8th International Workshop on Software Specification and Design (IWSSD-8) was held at Schloss Velen, Germany, in March 1996. In order to foster informed and fruitful discussions, the workshop was an invitation-only event of limited size. Based on formal submissions, approximately 60 people were selected and invited. Like its predecessors, IWSSD-8 maintained the principle that the accepted papers should serve as background material for the workshop. Therefore, the workshop did not include formal paper presentations, but rather provided an opportunity to engage in real work, with intensive discussions focussed around major themes. Each theme was discussed in a separate working group directed by a Working Group Chair who organized their group members so as to discuss the research issues of that particular theme. This year the themes selected were Requirements Engineering, Design Engineering, Software Architecture, and Concurrency/Distribution.IWSSD has established a tradition of using "case studies" as a focus for individual working groups. These case studies, supplied in advance to participants, have proved to be a fruitful way of working. Evidence of this can be seen most clearly in the "succeedings" or workshop reports which have followed previous workshops. It was decided that for IWSSD-8, in order to provide common ground between the themes, a single common case study should be used. The "Report on the Inquiry into the London Ambulance Service" was selected, with each theme drawing on it in a manner appropriate to their own interests and concerns.The London Ambulance Service (LAS) is briefly summarized below and discussed in the first paper appearing in the proceedings. The case study was presented in a plenary session at the beginning of the workshop and the findings of the different working groups presented and discussed at the end of the workshop, again in a plenary session. In order to make best use of the time available, working group members were asked to prepare for the workshop by familiarizing themselves with the case study and the major issues in their area relevant to that case study. We believe that this format made it both attractive and rewarding for people to attend, and was a major reason for the success of this workshop.},
author = {Kramer, Jeff and Wolf, Alexander L.},
doi = {10.1145/235969.235976},
file = {:Users/vitor/Mendeley/Kramer, Wolf - 1996 - Succeedings of the 8th International Workshop on Software Specification and Design.pdf:pdf},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {bibtex,x-commented},
mendeley-tags = {bibtex,x-commented},
month = {sep},
number = {5},
pages = {21--35},
publisher = {ACM},
title = {{Succeedings of the 8th International Workshop on Software Specification and Design}},
url = {http://portal.acm.org/citation.cfm?doid=235969.235976},
volume = {21},
year = {1996}
}
@inproceedings{krause-et-al:iswc03,
abstract = {Context-aware computing describes the situation where a wearable / mobile computer is aware of its user's state and surroundings and modifies its behavior based on this information. We designed, implemented and evaluated a wearable system which can determine typical user context and context transition probabilities online and without external supervision. The system relies on techniques from machine learning, statistical analysis and graph algorithms. It can be used for online classification and prediction. Our results indicate the power of our method to determine a meaningful user context model while only requiring data from a comfortable physiological sensor device},
address = {White Plains, NY, USA},
author = {Krause, A. and Siewiorek, D.P. and Smailagic, A. and Farringdon, J.},
booktitle = {Proc. of the 7th IEEE International Symposium on Wearable Computers},
doi = {10.1109/ISWC.2003.1241398},
file = {:Users/vitor/Mendeley/Krause et al. - 2003 - Unsupervised, dynamic identification of physiological and activity context in wearable computing.pdf:pdf},
isbn = {0-7695-2034-0},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {oct},
pages = {88--97},
publisher = {IEEE},
title = {{Unsupervised, dynamic identification of physiological and activity context in wearable computing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1241398},
year = {2003}
}
@article{kuipers:automatica89,
abstract = {Recently developed methods for qualitative reasoning may fill an important gap in the modeling and control toolkit. Qualitative reasoning methods provide greater expressive power for states of incomplete knowledge than differential or difference equations, and thus make it possible to build models without incorporating assumptions of linearity or specific values for incompletely known constants. Even with incomplete knowledge, there is enough information in a qualitative description to support qualitative simulation, predicting the possible behaviors of an incompletely described system. We survey results from several approaches to qualitative reasoning, and provide a detailed example of the application of these methods to a simple problem. The mathematical validity of qualitative simulation is also assessed. Initial results have been encouraging, and steps are now being taken to develop additional mathematical power, hierarchical decomposition methods, and incremental quantitative constraints, to make qualitative reasoning into a formal reasoning method useful on realistic problems.},
author = {Kuipers, Benjamin},
doi = {10.1016/0005-1098(89)90099-X},
file = {:Users/vitor/Mendeley/Kuipers - 1989 - Qualitative Reasoning Modeling and Simulation with Incomplete Knowledge.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {artificial intelligence,bibtex,commented,modeling,qualitative reasoning,qualitative simulation,simulation},
mendeley-tags = {bibtex,commented},
month = {jul},
number = {4},
pages = {571--585},
publisher = {Elsevier},
title = {{Qualitative Reasoning: Modeling and Simulation with Incomplete Knowledge}},
url = {http://linkinghub.elsevier.com/retrieve/pii/000510988990099X},
volume = {25},
year = {1989}
}
@inproceedings{laddaga-robertson:selfstar04,
abstract = {In this paper, we define Self Adaptive Software (SAS), discuss paradigms for implementing SAS, the core problem of self evaluation, discuss some applications, and indicate some area of future work.},
address = {Bertinoro, FC, Italy},
author = {Laddaga, Robert and Robertson, Paul},
booktitle = {Proc. of the 2004 International Workshop on Self-* Properties in Complex Information Systems},
file = {:Users/vitor/Mendeley/Laddaga, Robertson - 2004 - Self Adaptive Software A Position Paper.pdf:pdf},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {may},
title = {{Self Adaptive Software: A Position Paper}},
url = {http://www.cs.unibo.it/self-star/papers/laddaga.pdf},
year = {2004}
}
@inproceedings{lam-loomes:csmr98,
abstract = {Requirements evolve, not only during system development but also after a system has been installed. The aim of the work on the EVE (Evolution Engineering) project is to develop practical methods for dealing with requirements evolution. The paper presents the early output from our work-the EVE framework for requirements evolution. The EVE framework is comprised of two components: a meta model and an associated process model. The EVA meta model captures a set of modelling concepts in requirements evolution, including change, impact, risk and viewpoint. The EVA process model provides technologists with a framework for handling the emergence of new or changing requirements during the lifetime of a system. The paper illustrates the EVA framework on a simple example, and highlights the importance of social and environmental responsibility in requirements evolution},
address = {Florence , Italy},
author = {Lam, Wai and Loomes, Martin},
booktitle = {Proc. of the 2nd Euromicro Conference on Software Maintenance and Reengineering},
doi = {10.1109/CSMR.1998.665774},
file = {:Users/vitor/Mendeley/Lam, Loomes - 1998 - Requirements Evolution in the Midst of Environmental Change a Managed Approach.pdf:pdf},
isbn = {0-8186-8421-6},
keywords = {bibtex,change management,not-commented,process model,requirements,requirements evolution,software project management},
mendeley-tags = {bibtex,not-commented},
month = {mar},
pages = {121--127},
publisher = {IEEE},
title = {{Requirements Evolution in the Midst of Environmental Change: a Managed Approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=665774},
year = {1998}
}
@phdthesis{lapouchnian:phdthesis10,
abstract = {The complexity of software systems is exploding, along with their use and application in new domains. Managing this complexity has become a focal point for research in Software Engineering. One direction for research in this area is developing techniques for designing adaptive software systems that self-optimize, self-repair, self-configure and self-protect, thereby reducing maintenance costs, while improving quality of service. This thesis presents a requirements-driven approach for developing adaptive and customizable systems. Requirements goal models are used as a basis for capturing problem variability, leading to software designs that support a space of possible behaviours – all delivering the same functionality. This space can be exploited at system deployment time to customize the system on the basis of user preferences. It can also be used at runtime to support system adaptation if the current behaviour of the running system is deemed to be unsatisfactory. The contributions of the thesis include a framework for systematically generating designs from high-variability goal models. Three complementary design views are generated: configurational view (feature model), behavioural view (statecharts) and an architectural view (parameterized architecture). The framework is also applied to the field of business process management for intuitive high-level process customization. In addition, the thesis proposes a modeling framework for capturing domain variability through contexts and applies it to goal models. A single goal model is used to capture requirements variations in different contexts. Models for particular contexts can then be automatically generated from this global requirements model. As well, the thesis proposes a new class of requirements-about-requirements called awareness requirements. Awareness requirements are naturally operationalized through feedback controllers – the core mechanisms of every adaptive system. The thesis presents an approach for systematically designing monitoring, analysis/diagnosis, and compensation components of a feedback controller, given a set of awareness requirements. Situations requiring adaptation are explicitly captured using contexts.},
author = {Lapouchnian, Alexei},
file = {:Users/vitor/Mendeley/Lapouchnian - 2010 - Exploiting Requirements Variability for Software Customization and Adaptation.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
school = {University of Toronto, Canada},
title = {{Exploiting Requirements Variability for Software Customization and Adaptation}},
type = {PhD Thesis},
url = {http://www.cs.toronto.edu/{~}alexei/},
year = {2010}
}
@techreport{lapouchnian:report05,
annote = {This publication has no abstract.},
author = {Lapouchnian, Alexei},
file = {:Users/vitor/Mendeley/Lapouchnian - 2005 - Goal-Oriented Requirements Engineering An Overview of the Current Research.pdf:pdf},
institution = {University of Toronto, Canada (available online: http://www.cs.toronto.edu/{\~{}}alexei/pub/Lapouchnian-Depth.pdf)},
keywords = {bibtex,x-commented},
mendeley-tags = {bibtex,x-commented},
publisher = {University of Toronto},
title = {{Goal-Oriented Requirements Engineering: An Overview of the Current Research}},
url = {http://www.cs.toronto.edu/{~}alexei/pub/Lapouchnian-Depth.pdf},
year = {2005}
}
@inproceedings{lapouchnian-et-al:deas05,
abstract = {Autonomic computing systems reduce software maintenance costs and management complexity by taking on the responsibility for their configuration, optimization, healing, and protection. These tasks are accomplished by switching at runtime to a different system behaviour - the one that is more efficient, more secure, more stable, etc. - while still fulfilling the main purpose of the system. Thus, identifying and analyzing alternative ways of how the main objectives of the system can be achieved and designing a system that supports all of these alternative behaviours is a promising way to develop autonomic systems. This paper proposes the use of requirements goal models as a foundation for such software development process and sketches a possible architecture for autonomic systems that can be built using the this approach.},
address = {St. Louis, MO, USA},
author = {Lapouchnian, Alexei and Liaskos, Sotirios and Mylopoulos, John and Yu, Yijun},
booktitle = {Proceedings of the 2005 Workshop on Design and Evolution of Autonomic Application Software},
doi = {10.1145/1083063.1083075},
file = {:Users/vitor/Mendeley/Lapouchnian et al. - 2005 - Towards Requirements-Driven Autonomic systems design.pdf:pdf},
isbn = {1595930396},
keywords = {autonomic computing software customization,bibtex,goal-oriented requirements engineering,not-commented,self-management,software variability},
mendeley-tags = {bibtex,not-commented},
month = {may},
pages = {1--7},
publisher = {ACM},
title = {{Towards Requirements-Driven Autonomic systems design}},
url = {http://portal.acm.org/citation.cfm?doid=1083063.1083075},
year = {2005}
}
@incollection{lapouchnian-mylopoulos:er09,
abstract = {Various characteristics of the problem domain define the context in which the system is to operate and thus impact heavily on its requirements. However, most requirements specifications do not consider contextual properties and few modeling notations explicitly specify how domain variability affects the requirements. In this paper, we propose an approach for using contexts to model domain variability in goal models. We discuss the modeling of contexts, the specification of their effects on system goals, and the analysis of goal models with contextual variability. The approach is illustrated with a case study.},
address = {Gramado, RS, Brazil},
annote = {10.1007/978-3-642-04840-1{\_}11},
author = {Lapouchnian, Alexei and Mylopoulos, John},
booktitle = {Conceptual Modeling - ER 2009},
doi = {10.1007/978-3-642-04840-1_11},
editor = {Laender, Alberto and Castano, Silvana and Dayal, Umeshwar and Casati, Fabio and de Oliveira, Jos{\'{e}}},
file = {:Users/vitor/Mendeley/Lapouchnian, Mylopoulos - 2009 - Modeling Domain Variability in Requirements Engineering with Contexts.pdf:pdf},
isbn = {978-3-642-04839-5},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
pages = {115--130},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Modeling Domain Variability in Requirements Engineering with Contexts}},
url = {http://www.springerlink.com/content/3781muw828jpq7n2/},
volume = {5829},
year = {2009}
}
@incollection{lapouchnian-et-al:bpm07,
abstract = {The success of a business process (BP) depends on whether it meets its business goal as well as non-functional requirements associated with it. BP specifications frequently need to accommodate changing business priorities, varying client preferences, etc. However, since business process goals and preferences are rarely captured explicitly in the dominant BP modeling approaches, adapting business processes proves difficult. We propose a systematic requirements-driven approach for BP design and configuration management that uses requirements goal models to capture alternative process configurations and provides the ability to tailor deployed processes to changing business priorities or customer preferences (i.e., non-functional constraints) by configuring their corresponding goal models at the goal level. A set of design time and runtime tools for configuring business processes implemented using WS-BPEL is provided, allowing to easily change the behaviour of deployed BP instances at a high level, based on business priorities and stakeholder preferences.},
address = {Brisbane, Australia},
annote = {10.1007/978-3-540-75183-0{\_}18},
author = {Lapouchnian, Alexei and Yu, Yijun and Mylopoulos, John},
booktitle = {Business Process Management},
doi = {10.1007/978-3-540-75183-0_18},
editor = {Alonso, Gustavo and Dadam, Peter and Rosemann, Michael},
file = {:Users/vitor/Mendeley/Lapouchnian, Yu, Mylopoulos - 2007 - Requirements-Driven Design and Configuration Management of Business Processes.pdf:pdf},
isbn = {978-3-540-75182-3},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
pages = {246--261},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Requirements-Driven Design and Configuration Management of Business Processes}},
url = {http://www.springerlink.com/content/5h41288071534010/},
volume = {4714},
year = {2007}
}
@article{leal:csis13,
abstract = {Extracting the semantic relatedness of terms is an important topic in several areas, including data mining, information retrieval and web recommendation. This paper presents an approach for computing the semantic relatedness of terns in RDF graphs based on the notion of proximity. It proposes a formal definition of proximity in terms of the set paths connecting two concept nodes, and an algorithm for finding this set and computing proximity with a given error margin. This algorithm was implemented on a tool called Shakti that extracts relevant ontological data for a given domain from DBpedia – a community effort to extract structured data from the Wikipedia. To validate the proposed approach Shakti was used to recommend web pages on a Portuguese social site related to alternative music and the results of that experiment are also reported.},
author = {Leal, Jos{\'{e}}},
doi = {10.2298/CSIS121130060L},
editor = {Ivanovic, Mirjana},
file = {:Users/vitor/Mendeley/Leal - 2013 - Using proximity to compute semantic relatedness in RDF graphs.pdf:pdf},
issn = {1820-0214},
journal = {Computer Science and Information Systems},
keywords = {bibtex,commented,ontology generation,processing Wikipedia data,semantic relatedness,semantic similarity,web recommendation},
mendeley-tags = {bibtex,commented},
number = {4},
pages = {1727--1746},
publisher = {ComSIS Consortium},
title = {{Using proximity to compute semantic relatedness in RDF graphs}},
url = {http://www.doiserbia.nb.rs/Article.aspx?ID=1820-02141300060L},
volume = {10},
year = {2013}
}
@inproceedings{lee-et-al:act11,
abstract = {An autonomic system provides self-adaptive ability that enables system to dynamically adjust its behavior on environmental changes or system failure. Fundamental process of adaptive behavior in an autonomic system is consist of monitoring system or/and environment information, analyzing monitored information, planning adaptation policy and executing selected policy. Evaluating system utility is one of a significant part among them. We propose a novel approach on evaluating autonomic system at runtime. Our proposed method takes advantage of a goal model that has been widely used at requirement elicitation phase to capture system requirements. We suggest the state-based goal model that is dynamically activated as the system state changes. In addition, we defined type of constraints that can be used to evaluate goal satisfaction level. We implemented a prototype of autonomic computing software engine to verity our proposed method. We simulated the behavior of the autonomic computing engine with the home surveillance robot scenario and observed the validity of our proposed method.},
address = {Jakarta, Indonesia},
author = {Lee, Chonghyun and Youn, Hyunsang and Chun, Ingeol and Lee, Eunseok},
booktitle = {Proc. of the 3rd International Conference on Advances in Computing, Control, and Telecommunication Technologies},
file = {:Users/vitor/Mendeley/Lee et al. - 2011 - A Runtime evaluation methodology and framework for autonomic systems.pdf:pdf},
keywords = {adaptive systems,autonomic computing,bibtex,commented,embedded system,goal model},
mendeley-tags = {bibtex,commented},
month = {dec},
pages = {57--61},
publisher = {IDES},
title = {{A Runtime evaluation methodology and framework for autonomic systems}},
url = {http://www.engineeringvillage.com/search/submit.url?CID=searchSubmit{\&}searchtype=Quick{\&}resetDataBase=1{\&}database=1{\&}searchWord1="A Runtime evaluation methodology and framework for autonomic systems"{\&}section1=TI{\&}boolean1=AND{\&}searchWord2={\&}section2=NO-LIMIT{\&}boo},
year = {2011}
}
@article{lehman:ieee80,
abstract = {By classifying programs according to their relationship to the environment in which they are executed, the paper identifies the sources of evolutionary pressure on computer applications and programs and shows why this results in a process of never ending maintenance activity. The resultant life cycle processes are then briefly discussed. The paper then introduces laws of Program Evolution that have been formulated following quantitative studies of the evolution of a number of different systems. Finally an example is provided of the application of Evolution Dynamics models to program release planning.},
author = {Lehman, Meir M.},
doi = {10.1109/PROC.1980.11805},
file = {:Users/vitor/Mendeley/Lehman - 1980 - Programs, life cycles, and laws of software evolution.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
number = {9},
pages = {1060--1076},
title = {{Programs, life cycles, and laws of software evolution}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1456074},
volume = {68},
year = {1980}
}
@article{lehman:jss79,
abstract = {The paper presents interpretations of some recently discovered laws of evolution and conservation in the largeprogram life cycle. Program development and maintenance processes are managed and implemented by people; thus in the long term they could be expected to be unpredictable, dependant on the judgments, whims, and actions of programming process participants (e.g., managers, programmers, and product users). Yet, observed, measured, and modeled regularities suggest laws that are closer to biological laws or those of modern physics than to those currently formulated in other areas subject to human influence (e.g., economics and sociology). After a brief discussion of the first four laws, to highlight underlying phenomena and natural attributes of the program evolution process, the paper concentrates on a fifth law and shows how, and why, this law represents a conservation phenomenon: the Conservation of Familiarity.},
author = {Lehman, Meir M.},
doi = {10.1016/0164-1212(79)90022-0},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {jan},
pages = {213--221},
publisher = {Elsevier},
title = {{On understanding laws, evolution, and conservation in the large-program life cycle}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0164121279900220},
volume = {1},
year = {1979}
}
@incollection{lehman-ramil:sw02,
abstract = {This paper presents reasoning implying that the outcome of the execution of an E-type program or E-type software system (software for short) of whatever class are not absolutely predictable. It is intrinsically uncertain. Some of the sources of that uncertainty are identified and it is argued that the phenomenon qualifies as a Principle of Software Uncertainty. The latter represents an example of an assertion in a Theory of Software Evolution which is ripe for development based on empirical generalisations identified in previous research, most recently in the FEAST projects. The paper briefly discusses some practical implications of uncertainty, and the other concepts presented, on evolution technology and software processes. Though much of what is presented here has previously been discussed, its presentation as a cohesive whole provides a new perspective.},
annote = {10.1007/3-540-46019-5{\_}14},
author = {Lehman, Meir M. and Ramil, Juan F.},
booktitle = {Soft-Ware 2002: Computing in an Imperfect World},
doi = {10.1007/3-540-46019-5_14},
editor = {Bustard, David and Liu, Weiru and Sterritt, Roy},
file = {:Users/vitor/Mendeley/Lehman, Ramil - 2002 - Software Uncertainty.pdf:pdf},
isbn = {978-3-540-43481-8},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {477--514},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Software Uncertainty}},
url = {http://www.springerlink.com/content/e2x3tjkbq8gvundm/},
volume = {2311},
year = {2002}
}
@incollection{lehmann-et-al:mse11,
abstract = {Runtime models enable the implementation of highly adaptive applications but also require a rethinking in the way we approach models. Metamodels of runtime models have to be supplemented with additional runtime concepts that have an impact on the way how runtime models are built and reflected in the underlying runtime architectures. The goal of this work is the generalization of concepts found in different approaches utilizing runtime models and the provision of a basis for their meta-modeling. After analyzing recent work dealing with runtime models, we present a meta-modeling process for runtime models. Based on a meta-metamodel it guides the creation of metamodels combining design time and runtime concepts.},
author = {Lehmann, Grzegorz and Blumendorf, Marco and Trollmann, Frank and Albayrak, Sahin},
booktitle = {Models in Software Engineering},
doi = {10.1007/978-3-642-21210-9_21},
keywords = {bibtex,meta-metamodel,meta-modeling,models@runtime,runtime models},
mendeley-tags = {bibtex},
pages = {209--223},
publisher = {Springer},
title = {{Meta-modeling Runtime Models}},
url = {http://link.springer.com/10.1007/978-3-642-21210-9{\_}21},
year = {2011}
}
@phdthesis{letier:phdthesis01,
abstract = {The thesis proposes a number of techniques for elaborating requirements constructively from high-level goals. The techniques are based on the KAOS goal-oriented method for requirements engineering. This method consists in identifying goals and refining them into subgoals until the latter can be assigned as responsibilities of single agents such as humans, devices and software. Domain properties and assumptions about the software environment are also used during the goal refinement process. The method supports the exploration of alternative goal refinements and alternative responsibility assignments of goals to agents. It also supports the identification and resolution of conflicts between goals, and the identification and resolution of exceptional agent behaviors, called obsta- cles, that violate goals and assumptions produced during the goal refinement process. The thesis enriches the KAOS framework through three kinds of techniques: (a) techniques for identifying agents, goal refinements, and alternative responsibility assignments, and for deriving agent interfaces from such responsibility assignments; (b) techniques for deriving operational requirements from goal specifications; (c) techniques for generating obstacles to the satisfaction of idealized goals and assump- tions, and for generating alternative obstacle resolutions. The result is a coherent body of systematic techniques for requirements elaboration that are both theoretically well-founded (a formal model of agent is defined) and effective in practice (the techniques are validated on two real case studies of significant size: the London ambulance despatching system, and the Bay Area Rapid Transit train system).},
address = {Louvain-la-Neuve, Belgium},
author = {Letier, Emmanuel},
file = {:Users/vitor/Mendeley/Letier - 2001 - Reasoning about Agents in Goal-Oriented Requirements Engineering.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
school = {Universit{\'{e}} Catholique de Louvain, Belgium},
title = {{Reasoning about Agents in Goal-Oriented Requirements Engineering}},
type = {PhD Thesis},
url = {http://www.info.ucl.ac.be/Research/Publication/Theses.php},
year = {2001}
}
@article{letier-et-al:ase08,
abstract = {Goal-oriented methods are increasingly popular for elaborating software requirements. They offer systematic support for incrementally building intentional, structural, and operational models of the software and its environment. Event-based transition systems on the other hand are convenient formalisms for reasoning about software behaviour at the architectural level. The paper relates these two worlds by presenting a technique for translating formal specification of software operations built according to the KAOS goal-oriented method into event-based transition systems analysable by the LTSA toolset. The translation involves moving from a declarative, state-based, timed, synchronous formalism typical of requirements modelling languages to an operational, event-based, untimed, asynchronous one typical of architecture description languages. The derived model can be used for the formal analysis and animation of KAOS operation models in LTSA. The paper also provides insights into the two complementary formalisms, and shows that the use of synchronous temporal logic for requirements specification hinders a smooth transition from requirements to software architecture models.},
annote = {10.1007/s10515-008-0027-7},
author = {Letier, Emmanuel and Kramer, Jeff and Magee, Jeff and Uchitel, Sebastian},
doi = {10.1007/s10515-008-0027-7},
file = {:Users/vitor/Mendeley/Letier et al. - 2008 - Deriving event-based transition systems from goal-oriented requirements models.pdf:pdf},
issn = {0928-8910},
journal = {Automated Software Engineering},
keywords = {bibtex,commented,goal-oriented requirements engineering,labelled transition systems,method integration,requirement analysis,requirements animation,summarized},
mendeley-tags = {bibtex,commented,summarized},
number = {2},
pages = {175--206},
publisher = {Springer},
title = {{Deriving event-based transition systems from goal-oriented requirements models}},
url = {http://www.springerlink.com/content/v3h614348n775772/},
volume = {15},
year = {2008}
}
@inproceedings{letier-vanlamsweerde:fos04,
abstract = {Exploring alternative options is at the heart of the requirements and design processes. Different alternatives contribute to different degrees of achievement of non-functional goals about system safety, security, performance, usability, and so forth. Such goals in general cannot be satisfied in an absolute, clear-cut sense. Various qualitative and quantitative frameworks have been proposed to support the assessment of alternatives for design decision making. In general they lead to limited conclusions due to the lack of accuracy and measurability of goal formulations and the lack of impact propagation rules along goal contribution links. The paper presents techniques for specifying partial degrees of goal satisfaction and for quantifying the impact of alternative system designs on the degree of goal satisfaction. The approach consists in enriching goal refinement models with a probabilistic layer for reasoning about partial satisfaction. Within such models, non-functional goals are specified in a precise, probabilistic way; their specification is interpreted in terms of application-specific measures; impact of alternative goal refinements is evaluated in terms of refinement equations over random variables involved in the system's functional goals. A systematic method is presented for guiding the elaboration of such models. The latter can then be used to assess the impact of alternative decisions on the degree of goal satisfaction or to derive quantitative, fine-grained requirements on the software to achieve the higher-level goals.},
address = {Newport Beach (CA), USA},
author = {Letier, Emmanuel and van Lamsweerde, Axel},
booktitle = {Proc. of the 12th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
doi = {10.1145/1041685.1029905},
file = {:Users/vitor/Mendeley/Letier, van Lamsweerde - 2004 - Reasoning about Partial Goal Satisfaction for Requirements and Design Engineering.pdf:pdf},
isbn = {1-58113-855-5},
issn = {01635948},
keywords = {bibtex,commented,goal-oriented requirements engineering,non-functional requirements,partial satisfaction of requirements,probabilistic requirements modeling,reasoning about design alternatives},
mendeley-tags = {bibtex,commented},
month = {nov},
pages = {53--62},
publisher = {ACM},
title = {{Reasoning about Partial Goal Satisfaction for Requirements and Design Engineering}},
url = {http://portal.acm.org/citation.cfm?doid=1041685.1029905},
volume = {29},
year = {2004}
}
@article{leucker-schallhart:jlap09,
abstract = {In this paper, a brief account of the field of runtime verification is given. Starting with a definition of runtime verification, a comparison to well-known verification techniques like model checking and testing is provided, and applications in which runtime verification brings out its distinguishing features are pointed out. Moreover, extensions of runtime verification such as monitor-oriented programming, and monitor-based runtime reflection are sketched and their similarities and differences are discussed. Finally, the use of runtime verification for contract enforcement is briefly pointed out.},
author = {Leucker, Martin and Schallhart, Christian},
doi = {10.1016/j.jlap.2008.08.004},
file = {:Users/vitor/Mendeley/Leucker, Schallhart - 2009 - A brief account of runtime verification.pdf:pdf},
issn = {15678326},
journal = {The Journal of Logic and Algebraic Programming},
keywords = {bibtex},
mendeley-tags = {bibtex},
number = {5},
pages = {293--303},
publisher = {Elsevier},
title = {{A brief account of runtime verification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1567832608000775},
volume = {78},
year = {2009}
}
@inproceedings{li-et-al:re14,
abstract = {We propose a modeling language for non-functional requirements (NFRs) that views NFRs as requirements over qualities, mapping a software-related domain to a quality space. The language is compositional in that it allows (recursively) complex NFRs to be constructed in several ways. Importantly, the language allows the definition of requirements about the quality of fulfillment of other requirements, thus capturing, among others, the essence of probabilistic and fuzzy goals as proposed in the literature. We also offer a methodology for systematically refining informal NFRs elicited from stakeholders, resulting in unambiguous, de-idealized, and measurable requirements. The proposal is evaluated with a requirements dataset that includes 370 NFRs crossing 15 projects. The results suggest that our framework can adequately handle and clarify NFRs generated in practice.},
address = {Karlskrona, Sweden},
author = {Li, Feng-Lin and Horkoff, Jennifer and Mylopoulos, John and Guizzardi, Renata S. S. and Guizzardi, Giancarlo and Borgida, Alexander and Liu, Lin},
booktitle = {Proc. of the 22nd International Requirements Engineering Conference},
doi = {10.1109/RE.2014.6912271},
file = {:Users/vitor/Mendeley/Li et al. - 2014 - Non-functional requirements as qualities, with a spice of ontology.pdf:pdf},
isbn = {978-1-4799-3033-3},
keywords = {bibtex,goal models,non-functional requirements,ontologies,software qualities,summarized},
mendeley-tags = {bibtex,summarized},
month = {aug},
pages = {293--302},
publisher = {IEEE},
title = {{Non-functional requirements as qualities, with a spice of ontology}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6912271},
year = {2014}
}
@inproceedings{li-et-al:istar13,
abstract = {Goal-Oriented Requirements Engineering (GORE) is founded on the premise that functional and non-functional requirements (NFRs) are stakeholder goals to be fulfilled by the system-to-be. Moreover, functional requirements are “hard” goals with clear-cut criteria for fulfillment, while traditionally NFRs are usually “soft” goals (aka softgoals) lacking a clear-cut criterion for success. We argue against this distinction and in favor of a different one: traditional NFRs (e.g., security, reliability, performance, usability etc.) are requirements for qualities that existentially depend on the subject they qualify. We give examples in support of our argument, and sketch an abstract syntax and semantics for goal models that follow our proposal.},
address = {Valencia, Spain},
author = {Li, Feng-Lin and Horkoff, Jennifer and Mylopoulos, John and Liu, Lin and Borgida, Alexander},
booktitle = {Proc. of the 6th International i* Workshop},
file = {:Users/vitor/Mendeley/Li et al. - 2013 - Non-Functional Requirements Revisited.pdf:pdf},
keywords = {bibtex,goal model,ontology,quality,quality constraint,softgoal,summarized},
mendeley-tags = {bibtex,summarized},
month = {jun},
pages = {109--114},
publisher = {CEUR},
title = {{Non-Functional Requirements Revisited}},
url = {http://ceur-ws.org/Vol-978/},
volume = {978},
year = {2013}
}
@inproceedings{liaskos-et-al:re06,
abstract = {We introduce a variability-intensive approach to goal decomposition that is tailored to support requirements identification for highly customizable software. The approach is based on the semantic characterization of OR-decompositions of goals. We first show that each high-level goal can be associated with a set of concerns, in response to which, alternative refinements of the goal can be introduced. A text corpus relevant to the domain of discourse can be used to derive such variability concerns that are specific to the problem. In parallel, contextual facts that can vary while a goal is being fulfilled are modeled. Then, a high-variability goal model is constructed aiming at responding to the predefined variability concerns completely, while contextual factors are used to test whether it addresses all realistic background circumstances. We apply our approach in a study from the geriatric health care domain},
address = {Minneapolis, MN, USA},
author = {Liaskos, Sotirios and Lapouchnian, Alexei and Yu, Yijun and Yu, Eric S. K. and Mylopoulos, John},
booktitle = {Proc. of the 14th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2006.45},
file = {:Users/vitor/Mendeley/Liaskos et al. - 2006 - On Goal-based Variability Acquisition and Analysis.pdf:pdf},
isbn = {0-7695-2555-5},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {79--88},
publisher = {IEEE},
title = {{On Goal-based Variability Acquisition and Analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1704051},
year = {2006}
}
@article{liaskos-et-al:rej11,
abstract = {The priorities that stakeholders associate with requirements may vary from stakeholder to stakeholder and from one situation to the next. Differing priorities, in turn, imply different design decisions for the system to be. While elicitation of requirement priorities is a well-studied activity, modeling and reasoning with prioritization has not enjoyed equal attention. In this paper, we address this problem by extending a state-of-the-art goal modeling notation to support the representation of preference (“nice-to-have”) requirements. In our extension, preference goals are distinguished from mandatory ones. Then, quantitative prioritizations of the former are constructed and used as criteria for evaluating alternative ways to achieve the latter. To generate solutions, an existing preference-based planner is utilized to efficiently search for alternatives that best satisfy a given set of mandatory and preferred requirements. With such a planning tool, analysts can acquire a better understanding of the impact of high-level stakeholder preferences on low-level design decisions.},
annote = {10.1007/s00766-011-0129-9},
author = {Liaskos, Sotirios and McIlraith, Sheila and Sohrabi, Shirin and Mylopoulos, John},
doi = {10.1007/s00766-011-0129-9},
file = {:Users/vitor/Mendeley/Liaskos et al. - 2011 - Representing and reasoning about preferences in requirements engineering.pdf:pdf},
issn = {0947-3602},
journal = {Requirements Engineering},
keywords = {bibtex,commented,goal modeling,preference specification,requirements engineering},
mendeley-tags = {bibtex,commented},
number = {3},
pages = {227--249},
publisher = {Springer},
title = {{Representing and reasoning about preferences in requirements engineering}},
url = {http://www.springerlink.com/content/t27624345512v390/},
volume = {16},
year = {2011}
}
@techreport{lima-pg15,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Lima, Luiz V{\'{i}}tor Fran{\c{c}}a},
file = {:Users/vitor/Mendeley/Lima - 2015 - SAP – Sistema de Apoio ao Professor.pdf:pdf},
institution = {Projeto de Gradua{\c{c}}{\~{a}}o, Departamento de Inform{\'{a}}tica, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{SAP – Sistema de Apoio ao Professor}},
year = {2015}
}
@article{lohman-et-al:ejor04,
abstract = {Performance measurement (PM) by means of local performance indicators (PIs) is developing into performance management at a company-wide scale. But how should PIs at various levels in the organization be incorporated into one system that can help managers, working at levels that range from operational to strategic? How do we convince potential users and obtain their support when starting to develop such a system? How can we aggregate PIs? How do we present results? This paper addresses these and related questions. It is based on a case study carried out at the European Operations department of Nike, a company producing and selling sportswear worldwide. The study resulted in a prototype system that basically is a balanced scorecard tailored to the needs of the company. The empirical findings differ in some ways from the literature on developing performance measurement systems (PMSs) in Operations. Discussing these differences provides new theoretical and practical insights. They relate to the role of parallel initiatives for PM, the role of standardized metrics, the continuous improvement of PMSs, and the normalization and aggregation of measures. Our findings suggest that developing PMSs should to a large extent be understood as a co-ordination effort rather than a design effort. The lessons learned cannot have universal validity, but may be helpful in similar kinds of initiatives.},
author = {Lohman, Clemens},
doi = {10.1016/S0377-2217(02)00918-9},
file = {:Users/vitor/Mendeley/Lohman - 2004 - Designing a performance measurement system A case study.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {balanced scorecard,bibtex,not-commented,performance measurement,summarized,supply chain management},
mendeley-tags = {bibtex,not-commented,summarized},
month = {jul},
number = {2},
pages = {267--286},
publisher = {Elsevier},
title = {{Designing a performance measurement system: A case study}},
url = {http://www.sciencedirect.com/science/article/pii/S0377221702009189},
volume = {156},
year = {2004}
}
@techreport{lourenco-pg07,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Louren{\c{c}}o, Thiago W.},
file = {:Users/vitor/Mendeley/Louren{\c{c}}o - 2007 - Uma extens{\~{a}}o para o framework Struts2 para a implementa{\c{c}}{\~{a}}o de aplica{\c{c}}{\~{o}}es para a Web Sem{\^{a}}ntica com S-FrameWeb.pdf:pdf},
institution = {Projeto de Gradua{\c{c}}{\~{a}}o, Departamento de Inform{\'{a}}tica, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{Uma extens{\~{a}}o para o framework Struts2 para a implementa{\c{c}}{\~{a}}o de aplica{\c{c}}{\~{o}}es para a Web Sem{\^{a}}ntica com S-FrameWeb}},
year = {2007}
}
@inproceedings{luckey-et-al:seams11,
abstract = {Adaptivity is prevalent in today's software. Mobile devices self-adapt to available network connections, washing machines adapt to the amount of laundry, etc. Current approaches for engineering such systems facilitate the specification of adaptivity in the analysis and the technical design. However, the modeling of platform independent models for adaptivity in the logical design phase remains rather neglected causing a gap between the analysis and the technical design phase. To overcome this situation, we propose an approach called Adapt Cases. Adapt Cases allow the explicit modeling of adaptivity with domain-specific means, enabling adaptivity to gather attention early in the software engineering process. Since our approach is based on the concept of use cases it is easy adoptable in new and even running projects that use the UML as a specification language, and additionally, can be easily incorporated into model-based development environments.},
address = {Honolulu, HI, USA},
author = {Luckey, Markus and Nagel, Benjamin and Gerth, Christian and Engels, Gregor},
booktitle = {Proc of the 6th International Symposium on Software Engineering for Adaptive and Self-managing Systems (SEAMS '11)},
doi = {10.1145/1988008.1988014},
file = {:Users/vitor/Mendeley/Luckey et al. - 2011 - Adapt cases.pdf:pdf},
isbn = {9781450305754},
keywords = {adapt case,adaptive systems,bibtex,commented,model-based,requirements,use case},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {30--39},
publisher = {ACM},
title = {{Adapt cases}},
url = {http://portal.acm.org/citation.cfm?doid=1988008.1988014},
year = {2011}
}
@inproceedings{lujan-mora:dolap04,
abstract = {During the few last years, several approaches have been proposed to model different aspects of a Data Warehouse (DW), such as the conceptual model of the DW, the design of the ETL (Extraction, Transformation, Loading) processes, the derivation of the DW models from the enterprise data models, etc. At the end, a DW has to be deployed to a database environment and that takes many decisions of a physical nature. However, few efforts have been dedicated to the modeling of the physical design (i.e. the physical structures that will host data together with their corresponding implementations) of a DW from the early stages of a DW project. From our previously presented DW engineering process, in this paper we present our proposal for the modeling of the physical design of DWs by using the component diagrams and deployment diagrams of the Unified Modeling Language (UML). Our approach allows the designer to anticipate important physical design decisions that may reduce the overall development time of a DW such as replicating dimension tables, vertical and horizontal partitioning of a fact table, the use of particular servers for certain ETL processes and so on. Moreover, our approach allows the designer to cover all main design phases of DWs, from the conceptual modeling phase until the final implementation, as we show with an example in this paper.},
address = {Washington, DC, USA},
author = {Luj{\'{a}}n-Mora, Sergio and Trujillo, Juan},
booktitle = {Proc. of the 7th ACM International Workshop on Data Warehousing and OLAP},
doi = {10.1145/1031763.1031772},
file = {:Users/vitor/Mendeley/Luj{\'{a}}n-Mora, Trujillo - 2004 - Physical modeling of data warehouses using UML.pdf:pdf},
isbn = {1581139772},
keywords = {bibtex,component,configuration,data warehouse,deployment,not-commented,physical design,uml},
mendeley-tags = {bibtex,not-commented},
month = {nov},
pages = {48--57},
publisher = {ACM},
title = {{Physical modeling of data warehouses using UML}},
url = {http://portal.acm.org/citation.cfm?doid=1031763.1031772},
year = {2004}
}
@article{lujan-mora-et-al:dke03,
abstract = {The multidimensional (MD) modeling, which is the foundation of data warehouses (DWs), MD databases, and On-Line Analytical Processing (OLAP) applications, is based on several properties different from those in traditional database modeling. In the past few years, there have been some proposals, providing their own formal and graphical notations, for representing the main MD properties at the conceptual level. However, unfortunately none of them has been accepted as a standard for conceptual MD modeling. In this paper, we present an extension of the Unified Modeling Language (UML) using a UML profile. This profile is defined by a set of stereotypes, constraints and tagged values to elegantly represent main MD properties at the conceptual level. We make use of the Object Constraint Language (OCL) to specify the constraints attached to the defined stereotypes, thereby avoiding an arbitrary use of these stereotypes. We have based our proposal in UML for two main reasons: (i) UML is a well known standard modeling language known by most database designers, thereby designers can avoid learning a new notation, and (ii) UML can be easily extended so that it can be tailored for a specific domain with concrete peculiarities such as the multidimensional modeling for data warehouses. Moreover, our proposal is Model Driven Architecture (MDA) compliant and we use the Query View Transformation (QVT) approach for an automatic generation of the implementation in a target platform. Throughout the paper, we will describe how to easily accomplish the MD modeling of DWs at the conceptual level. Finally, we show how to use our extension in Rational Rose for MD modeling.},
author = {Luj{\'{a}}n-Mora, Sergio and Trujillo, Juan and Song, Il-Yeol},
doi = {10.1016/j.datak.2005.11.004},
issn = {0169023X},
journal = {Data and Knowledge Engineering},
keywords = {bibtex,data warehouses,multidimensional modeling,not-commented,uml,uml extension,uml profile},
mendeley-tags = {bibtex,not-commented},
month = {dec},
number = {3},
pages = {725--769},
publisher = {Elsevier},
title = {{A UML profile for multidimensional modeling in data warehouses}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169023X0500176X},
volume = {59},
year = {2006}
}
@incollection{ma-et-al:caise09,
abstract = {Service, as a computing and business paradigm, is gaining daily growing attention, which is being recognized and adopted by more and more people. For all involved players, it is inevitable to face service selection situations where multiple qualities of services criteria needs to be taken into account, and complex interrelationships between different impact factors and actors need to be understood and traded off. In this paper, we propose using goal and agent-based preference models, represented with annotated NFR/i* framework to drive these decision making activities. Particularly, we present how we enhance the modeling language with quantitative preference information based on input from domain experts and end users, how softgoals interrelationships graph can be used to group impact factors with common focus, and how actor dependency models can be used to represent and evaluate alternative services decisions. We illustrate the proposed approach with an example scenario of provider selection for logistics.},
annote = {10.1007/978-3-642-02144-2{\_}20},
author = {Ma, Wenting and Liu, Lin and Xie, Haihua and Zhang, Hongyu and Yin, Jinglei},
booktitle = {Advanced Information Systems Engineering},
doi = {10.1007/978-3-642-02144-2_20},
editor = {van Eck, Pascal and Gordijn, Jaap and Wieringa, Roel},
file = {:Users/vitor/Mendeley//Ma et al. - 2009 - Preference Model Driven Services Selection.pdf:pdf},
isbn = {978-3-642-02143-5},
keywords = {actor dependency network,bibtex,decision making,goal modeling,not-commented,services selection},
mendeley-tags = {bibtex,not-commented},
pages = {216--230},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Preference Model Driven Services Selection}},
url = {http://www.springerlink.com/content/x623553660034237/},
volume = {5565},
year = {2009}
}
@incollection{magee-et-al:esec95,
abstract = {There is a real need for clear and sound design specifications of distributed systems at the architectural level. This is the level of the design which deals with the high-level organisation of computational elements and the interactions between those elements. The paper presents the Darwin notation for specifying this high-level organisation. Darwin is in essence a declarative binding language which can be used to define hierarchic compositions of interconnected components. Distribution is dealt with orthogonally to system structuring. The language supports the specification of both static structures and dynamic structures which may evolve during execution. The central abstractions managed by Darwin are components and services. Services are the means by which components interact. In addition to its use in specifying the architecture of a distributed system, Darwin has an operational semantics for the elaboration of specifications such that they may be used at runtime to direct the construction of the desired system. The paper describes the operational semantics of Darwin in terms of the $\pi$-calculus, Milner's calculus of mobile processes. The correspondence between the treatment of names in the $\pi$-calculus and the management of services in Darwin leads to an elegant and concise $\pi$-calculus model of Darwin's operational semantics. The model is used to argue the correctness of the Darwin elaboration process. The overall objective is to provide a soundly based notation for specifying and constructing distributed software architectures.},
author = {Magee, Jeff and Dulay, Naranker and Eisenbach, Susan and Kramer, Jeff},
booktitle = {Software Engineering — ESEC '95},
doi = {10.1007/3-540-60406-5_12},
editor = {Sch{\"{a}}fer, Wilhelm and Botella, Pere},
file = {:Users/vitor/Mendeley/Magee et al. - 1995 - Specifying distributed software architectures.pdf:pdf},
isbn = {978-3-540-60406-8},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {137--153},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Specifying distributed software architectures}},
url = {http://link.springer.com/chapter/10.1007{\%}2F3-540-60406-5{\_}12},
volume = {989},
year = {1995}
}
@inproceedings{magee-kramer:sigsoft96,
abstract = {Much of the recent work on Architecture Description Languages (ADL) has concentrated on specifying organisations of components and connectors which are static. When the ADL specification is used to drive system construction, then the structure of the resulting system in terms of its component instances and their interconnection is fixed. This paper examines ADL features which permit the description of dynamic software architectures in which the organisation of components and connectors may change during system execution.The paper outlines examples of language features which support dynamic structure. These examples are taken from Darwin, a language used to describe distributed system structure. An operational semantics for these features is presented in the {\&}pi;-calculus, together with a discussion of their advantages and limitations. The paper discusses some general approaches to dynamic architecture description suggested by these examples.},
address = {San Francisco, CA, USA},
author = {Magee, Jeff and Kramer, Jeff},
booktitle = {Proc. of the 4th ACM SIGSOFT Symposium on Foundations of Software Engineering (SIGSOFT '96)},
doi = {10.1145/239098.239104},
file = {:Users/vitor/Mendeley/Magee, Kramer - 1996 - Dynamic structure in software architectures.pdf:pdf},
isbn = {0897917979},
issn = {01635948},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {nov},
number = {6},
pages = {3--14},
publisher = {ACM},
title = {{Dynamic structure in software architectures}},
url = {http://portal.acm.org/citation.cfm?doid=250707.239104},
volume = {21},
year = {1996}
}
@inproceedings{manola-et-al:webmedia08,
abstract = {This paper presents Biblioref, a system that is meant to manage content from academic professionals. The main benefits of this system can be described as: a) promoting collaboration among users through mutual access to each other's documents; b) granting user autonomy in knowledge organization, since documents are classified according to individual points of view instead of a centralized model; and c) providing mechanisms to relate the different user's classification schemes, allowing to find potential collaborators, inferred from these relations. Moreover, Biblioref is Semantic Web compliant, opening possibilities for interoperating with other systems.},
address = {Vila Velha, ES, Brasil},
author = {Manola, Renan and Guizzardi, Renata S. S. and Gomes, Roberta L.},
booktitle = {Companion Proc. of the 14th Brazilian Symposium on Multimedia and the Web},
doi = {10.1145/1809980.1810022},
file = {:Users/vitor/Mendeley/Manola, Guizzardi, Gomes - 2008 - Biblioref a semantic bibliographic reference management system.pdf:pdf},
isbn = {9788576691990},
keywords = {bibtex,content management system,cscw,not-commented,rdf,semantic web,taxonomy},
mendeley-tags = {bibtex,not-commented},
pages = {149--151},
publisher = {ACM},
title = {{Biblioref: a semantic bibliographic reference management system}},
url = {http://portal.acm.org/citation.cfm?doid=1809980.1810022},
year = {2008}
}
@inproceedings{maretto-barcellos:eselaw13,
abstract = {During the execution of software projects, it is necessary to collect, store and analyze data to support project and organizational decisions. Software measurement is a fundamental practice for project management and process improvement. It is present in the main models and standards that address software process improvement, such as ISO/IEC 12207, CMMI and MR MPS.BR. In order to effectively perform software measurement, it is necessary an infrastructure to support data collection, storage and analysis. This article presents a study that investigated measurement architectures described in the literature. As a result, eight architectures were found. Their main characteristics were analyzed and are presented in this paper.},
address = {Montevideo, Uruguay},
author = {Maretto, Ciro Xavier and Barcellos, Monalessa Perini},
booktitle = {Proc. of the 10th Experimental Software Engineering Latin American Workshop},
file = {:Users/vitor/Mendeley/Maretto, Barcellos - 2013 - Software Measurement Architectures A Mapping Study.pdf:pdf},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {apr},
pages = {403--416},
publisher = {Curran Associates},
title = {{Software Measurement Architectures: A Mapping Study}},
url = {http://toc.proceedings.com/21425webtoc.pdf},
year = {2013}
}
@phdthesis{martins-msc16,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Martins, Beatriz Franco},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
school = {Disserta{\c{c}}{\~{a}}o de Mestrado, Universidade Federal do Esp{\'{i}}rito Santo},
title = {{Uma abordagem dirigida a modelos para o projeto de Sistemas de Informa{\c{c}}{\~{a}}o Web com base no m{\'{e}}todo FrameWeb}},
year = {2016}
}
@inproceedings{martins-souza:webmedia15,
abstract = {In the field of Web Engineering, many methods have been proposed. FrameWeb is a method that targets the development of systems that use certain kinds of frameworks in their architecture, proposing the use of models that incorporate concepts from these frameworks during design. However, in its original proposal, FrameWeb's models do not fit well different framework instances, its language is not formally defined and no tool support is offered to aid software architects in creating the models. In this paper, we propose to address these issues using model-driven techniques.},
address = {Manaus, AM, Brazil},
annote = {Qualis 2012: B3},
author = {Martins, Beatriz Franco and Souza, V{\'{i}}tor E. S.},
booktitle = {Proc. of the 21st Brazilian Symposium on Multimedia and the Web},
doi = {10.1145/2820426.2820439},
file = {:Users/vitor/Mendeley/Martins, Souza - 2015 - A Model-Driven Approach for the Design of Web Information Systems based on Frameworks.pdf:pdf},
isbn = {9781450339599},
keywords = {bibtex,export,frameweb,frameworks,meta-model,model-driven,web engineering},
mendeley-tags = {bibtex,export},
month = {oct},
pages = {41--48},
publisher = {ACM},
title = {{A Model-Driven Approach for the Design of Web Information Systems based on Frameworks}},
url = {http://dl.acm.org/citation.cfm?doid=2820426.2820439},
year = {2015}
}
@techreport{masolo-et-al:report2003,
abstract = {This document forms part of a research project funded by the IST Programme of the Commission of the European Communities as project number IST-2001-33052.},
author = {Masolo, Claudio and Borgo, Stefano and Gangemi, Aldo and Guarino, Nicola and Oltramari, Alessandro},
file = {:Users/vitor/Mendeley/Masolo et al. - 2003 - Wonderweb deliverable d18 - ontology library (final). Technical Report D18 httpwonderweb.man.ac.ukdeliverablesdoc.pdf:pdf},
institution = {Laboratory For Applied Ontology - ISTC-CNR, Italy},
keywords = {bibtex},
mendeley-tags = {bibtex},
pages = {343},
title = {{Wonderweb deliverable d18 - ontology library (final). Technical Report D18: http://wonderweb.man.ac.uk/deliverables/documents/D18.pdf}},
url = {http://wonderweb.man.ac.uk/deliverables/documents/D18.pdf},
year = {2003}
}
@inproceedings{mate-et-al:er2012,
abstract = {Key Performance Indicators (KPI) measure the performance of an organization relative to its objectives. To monitor organizational performance relative to KPIs, such KPIs need to be manually implemented in the form of data warehouse queries, to be used in dashboards or scorecards. Moreover, dashboards include little if any information about business strategy and offer a scattered view of KPIs and what do they mean relative to business concerns. In this paper, we propose an integrated view of strategic business models and conceptual data warehouse models. The main benefit of our proposal is that it links strategic business models to the data through which objectives can be monitored and assessed. In our proposal, KPIs are defined in Structured English and are implemented in a semi-automatic way, allowing for quick modifications. This enables real-time monitoring and what-if analysis, thereby helping analysts compare expectations with reported results.},
address = {Florence, Italy},
author = {Mat{\'{e}}, Alejandro and Trujillo, Juan and Mylopoulos, John},
booktitle = {Proc. of the 31st International Conference on Conceptual Modeling (ER 2012)},
doi = {10.1007/978-3-642-34002-4_22},
file = {:Users/vitor/Mendeley/Mat{\'{e}}, Trujillo, Mylopoulos - 2012 - Conceptualizing and Specifying Key Performance Indicators in Business Strategy Models.pdf:pdf},
keywords = {KPI,OLAP,SBVR,bibtex,business intelligence,commented,conceptual data warehouse models},
mendeley-tags = {bibtex,commented},
month = {oct},
pages = {282--291},
publisher = {Springer},
title = {{Conceptualizing and Specifying Key Performance Indicators in Business Strategy Models}},
url = {http://link.springer.com/10.1007/978-3-642-34002-4{\_}22},
year = {2012}
}
@inproceedings{mazon-et-al:rigim07,
address = {Auckland, New Zealand},
author = {Maz{\'{o}}n, Jose-Norberto and Pardillo, Jes{\'{u}}s and Trujillo, Juan},
booktitle = {Proc. of the 1st International Workshop on Requirements, Intentions and Goals in Conceptual Modeling},
file = {:Users/vitor/Mendeley/Maz{\'{o}}n, Pardillo, Trujillo - 2007 - A Model-Driven Goal-Oriented Requirement Engineering Approach for Data Warehouses.pdf:pdf},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {nov},
title = {{A Model-Driven Goal-Oriented Requirement Engineering Approach for Data Warehouses}},
year = {2007}
}
@article{mazon-trujillo:dss08,
abstract = {Different modeling approaches have been proposed to overcome every design pitfall of different data warehouse (DW) components. However, most of them offer partial solutions that deal only with isolated aspects of the DW and do not provide developers with an integrated and standard framework for designing all DW relevant components, such as ETL processes, data sources, DW repository and so on. To overcome this problem, this paper describes how to align the whole DW development process with a Model Driven Architecture (MDA) framework. We then focus on describing one part of it: an MDA approach for the development of the DW repository, because it is the cornerstone of any DW system. Therefore, we describe how to build the different MDA models for the DW repository by using an extension of the Unified Modeling Language (UML) and the Common Warehouse Metamodel (CWM). Transformations between models are also clearly and formally established by using the Query/View/Transformation (QVT) language. Finally, a case study is provided to exemplify the benefits of our MDA framework.},
author = {Maz{\'{o}}n, Jose-Norberto and Trujillo, Juan},
doi = {10.1016/j.dss.2006.12.003},
file = {:Users/vitor/Mendeley/Maz{\'{o}}n, Trujillo - 2008 - An MDA approach for the development of data warehouses.pdf:pdf},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {apr},
number = {1},
pages = {41--58},
publisher = {Elsevier},
title = {{An MDA approach for the development of data warehouses}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167923606002077},
volume = {45},
year = {2008}
}
@inproceedings{mazon-et-al:rebnita05,
address = {Paris, France},
author = {Maz{\'{o}}n, Jose-Norberto and Trujillo, Juan and Serrano, Manuel and Piattini, Mario},
booktitle = {Proc. of the 1st International Workshop on Requirements Engineering for Business Need and IT Alignment},
file = {:Users/vitor/Mendeley/Maz{\'{o}}n et al. - 2005 - Designing Data Warehouses From Business Requirement Analysis to Multidimensional Modeling.pdf:pdf},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
pages = {44--53},
title = {{Designing Data Warehouses: From Business Requirement Analysis to Multidimensional Modeling}},
year = {2005}
}
@article{mckinley-et-al:computer08,
abstract = {In digital evolution, self replicating computer programs — digital organisms — experience mutations and selective pressures, potentially producing computational systems that, like natural organisms, adapt to their environment and protect themselves from threats. Such organisms can help guide the design of computer software.},
author = {McKinley, Philip K. and Cheng, Betty H. C. and Ofria, Charles A. and Knoester, David B. and Beckmann, Benjamin and Goldsby, Heather J.},
doi = {10.1109/MC.2008.17},
file = {:Users/vitor/Mendeley/McKinley et al. - 2008 - Harnessing Digital Evolution.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {jan},
number = {1},
pages = {54--63},
publisher = {IEEE},
title = {{Harnessing Digital Evolution}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4445603},
volume = {41},
year = {2008}
}
@inproceedings{mealy:fjcc67,
address = {Anaheim, CA, USA},
author = {Mealy, George H.},
booktitle = {International Workshop on Managing Requirements Knowledge, Proc. of the 1967 Fall Joint Computer Conference (AFIPS)},
doi = {10.1109/AFIPS.1967.112},
file = {:Users/vitor/Mendeley/Mealy - 1967 - Another Look at Data.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {nov},
pages = {525--534},
publisher = {IEEE},
title = {{Another Look at Data}},
url = {http://www.computer.org/csdl/proceedings/afips/1967/5070/00/50700525-abs.html},
year = {1967}
}
@article{menasce-et-al:software11,
abstract = {Making architectural decisions manually in the presence of quality-of-service trade-offs can be complicated. The SASSY (Self-architecting Software Systems) framework automatically generates candidate software architectures and selects the one that best serves stakeholder-defined, scenario-based quality-of-service (QoS) goals. This lets domain experts concentrate on functional and QoS requirements. SASSY reduces the effort of composing service-oriented systems by automatically generating the QoS-optimized architecture and rapidly reconfiguring it at runtime. Self-architecting occurs during initial system deployment and at runtime, thus making systems self-adaptive, self-healing, self-managing, and self-optimizing.},
author = {Menasce, Daniel A. and Gomaa, Hassan and Malek, Sam and Sousa, Jo{\~{a}}o P.},
doi = {10.1109/MS.2011.22},
file = {:Users/vitor/Mendeley/Menasce et al. - 2011 - SASSY A Framework for Self-Architecting Service-Oriented Systems.pdf:pdf},
issn = {0740-7459},
journal = {IEEE Software},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {nov},
number = {6},
pages = {78--85},
publisher = {IEEE},
title = {{SASSY: A Framework for Self-Architecting Service-Oriented Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5696721},
volume = {28},
year = {2011}
}
@inproceedings{menzies-richardson:sew06,
abstract = {Acquisition of "quantitative" models of sufficient accuracy to enable effective analysis of requirements tradeoffs is hampered by the slowness and difficulty of obtaining sufficient data. "Qualitative" models, based on expert opinion, can be built quickly and therefore used earlier. Such qualitative models are nondeterminate which makes them hard to use for making categorical policy decisions over the model. The nondeterminacy of qualitative models can be tamed using "stochastic sampling" and "treatment learning". These tools can quickly find and set the "master variables" that restrain qualitative simulations. Once tamed, qualitative modeling can be used in requirements engineering to assess more options, earlier in the life cycle.},
address = {Columbia, MD, USA},
author = {Menzies, Tim and Richardson, Julian},
booktitle = {Proc. of the 30th Annual IEEE/NASA Software Engineering Workshop},
doi = {10.1109/SEW.2006.27},
file = {:Users/vitor/Mendeley/Menzies, Richardson - 2006 - Qualitative Modeling for Requirements Engineering.pdf:pdf},
isbn = {0-7695-2624-1},
issn = {1550-6215},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {apr},
pages = {11--20},
publisher = {IEEE},
title = {{Qualitative Modeling for Requirements Engineering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4090240},
year = {2006}
}
@article{millen:me02,
abstract = {Phil Millen suggests that the measures many companies choose to record are not always those that indicate key performance},
author = {Millen, Phil},
doi = {10.1049/me:20020305},
file = {:Users/vitor/Mendeley/Millen - 2002 - Communicating performance.pdf:pdf},
issn = {09569944},
journal = {Manufacturing Engineer},
keywords = {bibtex,not-commented,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
month = {jun},
number = {3},
pages = {119--122},
publisher = {IET},
title = {{Communicating performance}},
url = {http://link.aip.org/link/MFENES/v81/i3/p119/s1{\&}Agg=doi},
volume = {81},
year = {2002}
}
@incollection{moody:adis04,
abstract = {According to Cognitive Load Theory (CLT), presenting information in a way that cognitive load falls within the limitations of working memory can improve speed and accuracy of understanding, and facilitate deep understanding of information content. This paper describes a laboratory experiment which investigates the effects of reducing cognitive load on end user understanding of conceptual models. Participants were all na{\"{i}}ve users, and were given a data model consisting of almost a hundred entities, which corresponds to the average-sized data model encountered in practice. One group was given the model in standard Entity Relationship (ER) form and the other was given the same model organised into cognitively manageable “chunks”. The reduced cognitive load representation was found to improve comprehension and verification accuracy by more than 50{\%}, though conflicting results were found for time taken. The practical significance of this research is that it shows that managing cognitive load can improve end user understanding of conceptual models, which will help reduce requirements errors. The theoretical significance is that it provides a theoretical insight into the effects of complexity on understanding of conceptual models, which have previously been unexplored. The research findings have important design implications for all conceptual modelling notations.},
annote = {10.1007/978-3-540-30204-9{\_}9},
author = {Moody, Daniel},
booktitle = {Advances in Databases and Information Systems},
doi = {10.1007/978-3-540-30204-9_9},
editor = {Bencz{\'{u}}r, Andr{\'{a}}s and Demetrovics, J{\'{a}}nos and Gottlob, Georg},
file = {:Users/vitor/Mendeley/Moody - 2004 - Cognitive Load Effects on End User Understanding of Conceptual Models An Experimental Analysis.pdf:pdf},
isbn = {978-3-540-23243-8},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
pages = {129--143},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Cognitive Load Effects on End User Understanding of Conceptual Models: An Experimental Analysis}},
url = {http://www.springerlink.com/content/ytmw9ncqhl7r0td7/},
volume = {3255},
year = {2004}
}
@article{moody:tse09,
abstract = {Visual notations form an integral part of the language of software engineering (SE). Yet historically, SE researchers and notation designers have ignored or undervalued issues of visual representation. In evaluating and comparing notations, details of visual syntax are rarely discussed. In designing notations, the majority of effort is spent on semantics, with graphical conventions largely an afterthought. Typically, no design rationale, scientific or otherwise, is provided for visual representation choices. While SE has developed mature methods for evaluating and designing semantics, it lacks equivalent methods for visual syntax. This paper defines a set of principles for designing cognitively effective visual notations: ones that are optimized for human communication and problem solving. Together these form a design theory, called the Physics of Notations as it focuses on the physical (perceptual) properties of notations rather than their logical (semantic) properties. The principles were synthesized from theory and empirical evidence from a wide range of fields and rest on an explicit theory of how visual notations communicate. They can be used to evaluate, compare, and improve existing visual notations as well as to construct new ones. The paper identifies serious design flaws in some of the leading SE notations, together with practical suggestions for improving them. It also showcases some examples of visual notation design excellence from SE and other fields.},
author = {Moody, Daniel},
doi = {10.1109/TSE.2009.67},
file = {:Users/vitor/Mendeley/Moody - 2009 - The “Physics” of Notations Toward a Scientific Basis for Constructing Visual Notations in Software Engineering.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {analysis,bibtex,communication,concrete syntax,diagrams,modeling,not-commented,visual syntax,visualization},
mendeley-tags = {bibtex,not-commented},
month = {nov},
number = {6},
pages = {756--779},
publisher = {IEEE},
title = {{The “Physics” of Notations: Toward a Scientific Basis for Constructing Visual Notations in Software Engineering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5353439},
volume = {35},
year = {2009}
}
@phdthesis{morandini:thesis11,
abstract = {Today's software is expected to be able to work autonomously in an unpredictable en- vironment, avoiding failure and achieving satisfactory performance. Self-adaptive sys- tems try to cope with these challenging issues, autonomously adapting their behaviour to a dynamic environment to fulfil the objectives of their stakeholders. This implies that the software needs multiple ways to accomplish its purpose, enough knowledge of its con- struction, decision criteria for the selection of specific behaviours and the capability to make effective changes at runtime. The engineering of such systems is still challenging research in software engineering methods and techniques, as recently pointed out by the research community. The objective of this thesis is twofold: First, to capture and detail at design time the specific knowledge and decision criteria needed for a system to guide adaptation at run-time. Second, to create systems which are aware of their high-level requirements, by explicitly representing them as run-time objects, thus enabling it to act according to them and to monitor their satisfaction. To deliver on this aim, we provide conceptual models and process guidelines to model at design time the knowledge necessary to enable self-adaptation in a dynamic environ- ment, extending the agent-oriented software engineering methodology Tropos. The re- sulting framework, called Tropos4AS, offers a detailed specification of goal achievement, of the relationships with the environment, of possible failures and recovery activities. A claim underlying the approach is that the concepts of agent, goal, and goal model, used to capture the system's requirements, should be preserved explicitly along the whole development process, from requirements analysis to the design and run-time, thus re- ducing the conceptual gaps between the software development phases, and providing a representation of the high-level requirements at run-time. A direct, tool-supported mapping from goal models to an implementation in a Belief-Desire-Intention agent ar- chitecture, and an operational semantics for goal model satisfaction at run-time, com- plement this work. The framework is evaluated through application to research case studies and through an empirical study with subjects, assessing the usability and the comprehensibility of the modelling concepts.},
author = {Morandini, Mirko},
file = {:Users/vitor/Mendeley/Morandini - 2011 - Goal-Oriented Development of Self-Adaptive Systems.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
school = {University of Trento},
title = {{Goal-Oriented Development of Self-Adaptive Systems}},
type = {PhD Thesis},
url = {http://eprints-phd.biblio.unitn.it/511/},
year = {2011}
}
@inproceedings{morandini-et-al:aamas09,
abstract = {Several agent-oriented software engineering methodologies address the emerging challenges posed by the increasing need of adaptive software. A common denominator of such methodologies is the paramount importance of the concept of goal model in order to understand the requirements of a software system. Goal models consist of goal graphs representing AND/OR-decomposition of abstract goals down to operationalisable leaf-level goals. Goal models are used primarily in the earlier phases of software engineering, for social modelling, requirements elicitation and analysis, to concretise abstract objectives, to detail them and to capture alternatives for their satisfaction. Although various agent programming languages incorporate the notion of (leaf-level) goal as a language construct, none of them natively support the definition of goal models. However, the semantic gap between goal models used at design-time and the concept of goal used at implementation and execution time represent a limitation especially in the development of self-adaptive and fault-tolerant systems. In such systems, design-time knowledge on goals and variability becomes relevant at run-time, to take autonomous decisions for achieving high level objectives correctly. Recently, unifying operational semantics for (leaf) goals have been proposed [15]. We extend this work to define an operational semantics for the behaviour of goals in goal models, maintaining the flexibility of using different goal types and conditions. We use a simple example to illustrate how the proposed approach effectively deals with the semantic gap between design-time goal models and run-time agent implementations.},
address = {Budapest, Hungary},
author = {Morandini, Mirko and Penserini, Loris and Perini, Anna},
booktitle = {Proc. of the 8th International Conference on Autonomous Agents and Multiagent Systems},
file = {:Users/vitor/Mendeley/Morandini, Penserini, Perini - 2009 - Operational Semantics of Goal Models in Adaptive Agents.pdf:pdf},
isbn = {978-0-9817381-6-1},
keywords = {agent programming,bibtex,commented,formal semantics,goal models,goals},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {129--136},
publisher = {ACM},
title = {{Operational Semantics of Goal Models in Adaptive Agents}},
url = {http://dl.acm.org/citation.cfm?id=1558030},
year = {2009}
}
@inproceedings{morandini-et-al:seams08,
abstract = {Self-adaptive software aims at anticipating changes which occur in a complex environment and to automatically deal with them at run-time. The increasing demand for complex networked software, which makes computing resources available to anyone, anywhere and at any time, is drawing attention to the engineering of self- adaptive software. The objective of our work is to define a process and a tool-supported design framework to develop self-adaptive systems, which consider Belief-Desire-Intention agent models as reference architectures. We adopt an agent-oriented approach,which allows to explicitly model system goals in requirements specifica- tion and in the system architecture design. Moreover, goal achieve- ment conditions are specified along with their relationships with the environment and with possible failures, and corresponding recov- ery actions. This paper aims at motivating and giving an overview of our approach with the help of an example.},
address = {Leipzig, Germany},
author = {Morandini, Mirko and Penserini, Loris and Perini, Anna},
booktitle = {Proc. of the 2008 International Workshop on Software Engineering for Adaptive and Self-managing Systems},
doi = {10.1145/1370018.1370021},
file = {:Users/vitor/Mendeley/Morandini, Penserini, Perini - 2008 - Towards Goal-Oriented Development of Self-Adaptive Systems.pdf:pdf},
isbn = {9781605580371},
keywords = {BDI agents,adaptive systems,agent-oriented,bibtex,commented,software development process,software engineering,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {may},
pages = {9--16},
publisher = {ACM},
title = {{Towards Goal-Oriented Development of Self-Adaptive Systems}},
url = {http://portal.acm.org/citation.cfm?doid=1370018.1370021},
year = {2008}
}
@inproceedings{mori-et-al:sefm11,
abstract = {Applications in ubiquitous environments need to adapt to a range of fluid factors, like user preferences, context, and various system configurations. In this paper, we address the problem of system adaptation in order to continuously achieve high user benefit while keeping reconfiguration costs low. To this end, the presented approach leverages not only the immediate context but also future transitions. In contrast to existing approaches that either maximize benefit or minimize reconfiguration costs, our proposed decision support mechanism achieves a trade-off between those factors. Considering user preferences, deployment constraints, and probabilistic context state transitions, we propose a multi-objective utility function to determine the best reconfiguration choices. Experimental results show that the proposed approach achieves high user benefit while keeping reconfigurations costs low.},
address = {Montevideo, Uruguay},
author = {Mori, Marco and Li, Fei and Dorn, Christoph and Inverardi, Paola and Dustdar, Schahram},
booktitle = {Proc. of the 9th International Conference on Software Engineering and Formal Methods},
doi = {10.1007/978-3-642-24690-6_20},
file = {:Users/vitor/Mendeley/Mori et al. - 2011 - Leveraging State-Based User Preferences in Context-Aware Reconfigurations for Self-Adaptive Systems.pdf:pdf},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {nov},
pages = {286--301},
publisher = {Springer},
title = {{Leveraging State-Based User Preferences in Context-Aware Reconfigurations for Self-Adaptive Systems}},
url = {http://link.springer.com/10.1007/978-3-642-24690-6{\_}20},
year = {2011}
}
@inproceedings{Morin2008,
abstract = {Constructing and executing distributed systems that can adapt to their operating context in order to sustain provided services and the service qualities are complex tasks. Managing adaptation of multiple, interacting services is particularly difficult since these services tend to be distributed across the system, interdependent and sometimes tangled with other services. Furthermore, the exponential growth of the number of potential system configurations derived from the variabilities of each service need to be handled. Current practices of writing low-level reconfiguration scripts as part of the system code to handle run time adaptation are both error prone and time consuming and make adaptive systems difficult to validate and evolve. In this paper, we propose to combine model driven and aspect oriented techniques to better cope with the complexities of adaptive systems construction and execution, and to handle the problem of exponential growth of the number of possible configurations. Combining these techniques allows us to use high level domain abstractions, simplify the representation of variants and limit the problem pertaining to the combinatorial explosion of possible configurations. In our approach we also use models at runtime to generate the adaptation logic by comparing the current configuration of the system to a composed model representing the configuration we want to reach.},
address = {Tolouse, France},
author = {Morin, Brice and Fleurey, Franck and Bencomo, Nelly and J{\'{e}}z{\'{e}}quel, Jean-Marc and Solberg, Arnor and Dehlen, Vegard and Blair, Gordon},
booktitle = {Proc. of the 11th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems},
doi = {10.1007/978-3-540-87875-9},
editor = {Czarnecki, Krzysztof and Ober, Ileana and Bruel, Jean-Michel and Uhl, Axel and V{\"{o}}lter, Markus},
file = {:Users/vitor/Mendeley/Morin et al. - 2008 - Model Driven Engineering Languages and Systems.pdf:pdf},
isbn = {978-3-540-87874-2},
issn = {0302-9743},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {782--796},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Model Driven Engineering Languages and Systems}},
url = {http://www.springerlink.com/index/10.1007/978-3-540-87875-9},
year = {2008}
}
@inproceedings{mosincat:edoc10,
abstract = {Dynamically adaptive systems propose adaptation by means of variants that are specified in the system model at design time and allow for a fixed set of different runtime configurations. However, in a dynamic environment, unanticipated changes may result in the inability of the system to meet its quality requirements. To allow the system to react to these changes we propose a solution for automatically evolving the system model by integrating new variants and periodically validating existing ones based on updated quality parameters. To illustrate our approach we present a BPEL based framework using a service composition model to represent the system functional requirements. Our framework estimates Quality of Service (QoS) values based on information provided by our monitoring mechanism, ensuring that changes in QoS are reflected in the system model. We show how the evolved model can be used at runtime to increase the system's autonomic capabilities and delivered QoS.},
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Mosincat, Adina and Binder, Walter and Jazayeri, Mehdi},
booktitle = {Proc. of the 14th IEEE International Enterprise Distributed Object Computing Workshop},
doi = {10.1109/EDOC.2010.22},
file = {:Users/vitor/Mendeley/Mosincat, Binder, Jazayeri - 2010 - Runtime adaptability through automated model evolution.pdf:pdf},
isbn = {9780769541631},
issn = {15417719},
keywords = {Dynamic adaptability,Model at runtime,Model evolution,Quality requirements,bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {oct},
pages = {217--226},
publisher = {IEEE},
title = {{Runtime adaptability through automated model evolution}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp={\&}arnumber=5632143},
year = {2010}
}
@misc{mukerji-miller:website03,
author = {Mukerji, Jishnu and Miller, Joaquin},
file = {:Users/vitor/Mendeley/Mukerji, Miller - 2003 - MDA Guide Version 1.0.1, httpwww.omg.orgcgi-bindocomg03-06-01 (last access May 8th, 2015).pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{MDA Guide Version 1.0.1, http://www.omg.org/cgi-bin/doc?omg/03-06-01 (last access: May 8th, 2015)}},
url = {http://www.omg.org/cgi-bin/doc?omg/03-06-01},
year = {2003}
}
@inproceedings{muller-et-al:ulssis08,
abstract = {Adaptive systems respond to changes in their internal state or external environment with guidance from an underlying control system. ULS systems are particularly likely to re- quire dynamic adaptation because of their decentralized con- trol and the large number of independent stakeholders whose actions are integral to the system's behavior. Adaptation may take various forms, but the system structure will al- most inevitably include one or more closed feedback loops. We argue that adaptability is a characteristic of a solution, not of a problem, and that the feedback loop governing con- trol of adaptability should be explicit in design and analysis and either explicit or clearly traceable in implementation.},
address = {Leipzig, Germany},
author = {M{\"{u}}ller, Hausi A. and Pezz{\`{e}}, Mauro and Shaw, Mary},
booktitle = {Proc. of the 2nd International Workshop on Ultra-Large-Scale Software-Intensive Systems},
doi = {10.1145/1370700.1370707},
file = {:Users/vitor/Mendeley/M{\"{u}}ller, Pezz{\`{e}}, Shaw - 2008 - Visibility of Control in Adaptive Systems.pdf:pdf},
isbn = {9781605580265},
keywords = {autonomic systems,bibtex,commented,continuous evolution,self-adaptive systems,software ecosystems,ultra-large scale systems},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {23--26},
publisher = {ACM},
title = {{Visibility of Control in Adaptive Systems}},
url = {http://portal.acm.org/citation.cfm?doid=1370700.1370707},
year = {2008}
}
@incollection{munn:aoi09,
author = {Munn, Katherine},
booktitle = {Applied Ontology: An Introduction},
chapter = {1},
editor = {Munn, Katherine and Smith, Barry},
file = {:Users/vitor/Mendeley/Munn - 2009 - Introduction What is Ontology for.pdf:pdf},
isbn = {978-3938793985},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {7--19},
publisher = {Ontos},
series = {Metaphysical Research},
title = {{Introduction: What is Ontology for?}},
url = {http://ontology.buffalo.edu/AppliedOntology.pdf},
year = {2009}
}
@incollection{murugesan-et-al:we01,
abstract = {This section addresses some of the most fundamental themes of Web Engineering. In the context of identification and promotion of Web Engineering as a new discipline for the development of Web-based systems and applications, several questions naturally arise: What is Web Engineering? What is its place among all the other disciplines? Why is it being put forward as a new discipline? When is it needed? Is there an illustrative case study that would highlight the arguments? The three papers in this section answer these questions. The first two papers originate from the early exposure of the authors to Web developmental activities, which helped to define the field of Web Engineering and to bring a focus on areas that are not regarded as part of the traditional domains of computer science, information systems and software engineering. The third paper reports on the development of Web sites and Web-based applications that were undertaken consciously after most of the arguments for Web Engineering had been articulated earlier by the first two papers.},
author = {Murugesan, San and Deshpande, Yogesh and Hansen, Steve and Ginige, Athula},
booktitle = {Web Engineering - Managing Diversity and Complexity of Web Application Development},
chapter = {1},
doi = {10.1007/3-540-45144-7_2},
editor = {Murugesan, San and Deshpande, Yogesh},
isbn = {978-3-540-42130-6},
issn = {0937-6429},
keywords = {bibtex},
mendeley-tags = {bibtex},
pages = {3--13},
publisher = {Springer},
title = {{Web Engineering: a New Discipline for Development of Web-Based Systems}},
url = {http://www.springerlink.com/content/c54dq3p3drgad8wg/},
year = {2001}
}
@article{mylopoulos-et-al:tse92,
abstract = {A comprehensive framework for representing and using nonfunctional requirements during the development process is proposed. The framework consists of five basic components which provide the representation of nonfunctional requirements in terms of interrelated goals. Such goals can be refined through refinement methods and can be evaluated in order to determine the degree to which a set of nonfunctional requirements is supported by a particular design. Evidence for the power of the framework is provided through the study of accuracy and performance requirements for information systems},
author = {Mylopoulos, John and Chung, Lawrence and Nixon, Brian},
doi = {10.1109/32.142871},
file = {:Users/vitor/Mendeley/Mylopoulos, Chung, Nixon - 1992 - Representing and using nonfunctional requirements a process-oriented approach.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {jun},
number = {6},
pages = {483--497},
title = {{Representing and using nonfunctional requirements: a process-oriented approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=142871},
volume = {18},
year = {1992}
}
@article{mylopoulos-et-al:cacm99,
abstract = {The growing influence of object-oriented programming on programming practice has led to the rise of a new paradigm for system and software requirements analysis, popularly known as object-oriented analysis (OOA). This paradigm adopts ideas from object-oriented programming and blends them with ideas from semantic data modeling and knowledge representation (notably semantic networks) into a modeling framework that is more powerful than traditional techniques such as data flow diagrams, structured analysis, and the like.},
author = {Mylopoulos, John and Chung, Lawrence and Yu, Eric S. K.},
doi = {10.1145/291469.293165},
file = {:Users/vitor/Mendeley/Mylopoulos, Chung, Yu - 1999 - From Object-Oriented to Goal-Oriented Requirements Analysis.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {jan},
number = {1},
pages = {31--37},
publisher = {ACM},
title = {{From Object-Oriented to Goal-Oriented Requirements Analysis}},
url = {http://portal.acm.org/citation.cfm?doid=291469.293165},
volume = {42},
year = {1999}
}
@inproceedings{nakagawa-et-al:seams11,
abstract = {Self-adaptive systems have recently attracted attention because of their ability to cope with changing environments, including system intrusions or faults. Such software must modify itself to better fit its environment, and one of the approaches by which we expect this capability to be achieved is the introduction of multiple control loops to assess the situation and to determine whether a change in behaviors or configurations is necessary and how to implement the change. Development of such systems with multiple control loops complicates the task of identifying components, and could be greatly aided by appropriate tool support. In this paper, we propose an architectural compiler for self-adaptive systems, which generates architectural configurations from the goal-oriented requirements descriptions. We also present a framework for generating such configurations with this compiler and a pattern in the requirements description. We evaluate the framework experimentally and show that it helps to generate suitable configurations that have high performance, and that the compiler scales well to large input models.},
address = {Honolulu, HI, USA},
author = {Nakagawa, Hiroyuki and Ohsuga, Akihiko and Honiden, Shinichi},
booktitle = {Proc. of the 6th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1145/1988008.1988015},
file = {:Users/vitor/Mendeley/Nakagawa, Ohsuga, Honiden - 2011 - gocc A Configuration Compiler for Self-adaptive Systems Using Goal-oriented Requirements Description.pdf:pdf},
isbn = {9781450305754},
keywords = {bibtex,development framework,goal-oriented requirements analysis,not-commented,self-adaptive systems,software architecture},
mendeley-tags = {bibtex,not-commented},
month = {may},
pages = {40--49},
publisher = {ACM},
title = {{gocc: A Configuration Compiler for Self-adaptive Systems Using Goal-oriented Requirements Description}},
url = {http://portal.acm.org/citation.cfm?doid=1988008.1988015},
year = {2011}
}
@inproceedings{nardi-falbo:clei08,
abstract = {Requirements Engineering (RE) is a complex process. Establishing a common conceptualization about its domain is important for several reasons, such as communication and interoperability between RE tools. Truthfulness to reality and conceptual clarity are fundamental quality attributes of domain ontologies, and are directly responsible for the effectiveness of these models as reference frameworks. A way to achieve these quality attributes is by grounding domain ontologies in a foundational ontology. This paper presents an evolution of a Software Requirements Ontology that was reengineered by mapping the concepts of its previous version to the Unified Foundational Ontology (UFO).},
address = {Santa Fe, Argentina},
author = {Nardi, Julio C. and Falbo, Ricardo A.},
booktitle = {Proc. of the 34th Conferencia Latinoamericana de Informatica (CLEI 08)},
file = {:Users/vitor/Mendeley/Nardi, Falbo - 2008 - Evolving a Software Requirements Ontology.pdf:pdf},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {sep},
title = {{Evolving a Software Requirements Ontology}},
url = {http://www.clei.org/nuevaweb/cleiversion/2008/xxxivclei/index0387.html?aceptados=1},
year = {2008}
}
@incollection{nardi-et-al:i3e13,
abstract = {Despite (i) the recognized benefits of using ontologies in semantic EAI initiatives, (ii) the benefits of using foundational ontologies for promoting meaning negotiation and common understanding, and (iii) the importance of the semantic integration issue in EAI area, foundational ontologies have not yet become widely adopted in EAI initiatives for dealing with semantic conflicts. This has led us to investigate, through a systematic review of the literature, the adoption of foundational ontologies in EAI initiatives, with the purpose of understanding the current role of these ontologies in EAI and identifying gaps for future research, in which the potential benefits of such ontologies could be explored. We consider: (i) the role of foundational ontologies as part of the integration approach; (ii) the use of ontologies at development time and/or at run time; and (iii) the adoption of systematic approaches for semantic EAI.},
address = {Athens, Greece},
author = {Nardi, Julio Cesar and Falbo, Ricardo A. and Almeida, Jo{\~{a}}o Paulo A.},
booktitle = {Collaborative, Trusted and Privacy-Aware e/m-Services - 12th IFIP WG 6.11 Conference on e-Business, e-Services, and e-Society},
doi = {10.1007/978-3-642-37437-1_20},
editor = {Douligeris, Christos and Polemi, Nineta and Karantjias, Athanasios and Lamersdorf, Winfried},
file = {:Users/vitor/Mendeley/Nardi, Falbo, Almeida - 2013 - Foundational Ontologies for Semantic Integration in EAI A Systematic Literature Review.pdf:pdf},
isbn = {978-3-642-37436-4},
keywords = {bibtex,commented,enterprise application integration,foundational ontologies,semantic integration,semantic interoperability,systematic literature review},
mendeley-tags = {bibtex,commented},
pages = {238--249},
publisher = {Springer},
series = {IFIP Advances in Information and Communication Technology},
title = {{Foundational Ontologies for Semantic Integration in EAI: A Systematic Literature Review}},
url = {http://link.springer.com/chapter/10.1007{\%}2F978-3-642-37437-1{\_}20},
volume = {399},
year = {2013}
}
@techreport{negri-pg14,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Negri, Pedro P.},
file = {:Users/vitor/Mendeley/Negri - 2014 - Uma Transforma{\c{c}}{\~{a}}o Autom{\'{a}}tica Entre Modelos de Representa{\c{c}}{\~{a}}o de Situa{\c{c}}{\~{o}}es e Modelos de Especifica{\c{c}}{\~{a}}o de Simula{\c{c}}.pdf:pdf},
institution = {Projeto de Gradua{\c{c}}{\~{a}}o (orientador principal: Giancarlo Guizzardi), Departamento de Inform{\'{a}}tica, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{Uma Transforma{\c{c}}{\~{a}}o Autom{\'{a}}tica Entre Modelos de Representa{\c{c}}{\~{a}}o de Situa{\c{c}}{\~{o}}es e Modelos de Especifica{\c{c}}{\~{a}}o de Simula{\c{c}}{\~{a}}o em Ambiente Baseado em Relacionamento Agente-Objeto}},
year = {2014}
}
@techreport{nezhad-et-al:report07,
abstract = {The problem of understanding the behavior of business processes and of services is rapidly becoming a priority in medium and large companies. To this end, recently, analysis tools as well as variations of data mining techniques have been applied to process and service execution logs to perform OLAP-style analysis and to discover behavioral (process and protocol) models out of execution data. All these approaches are based on one key assumption: events describing executions and stored in process and service logs include identifiers that allow associating each event to the process or service execution they belong to (e.g., can correlate all events related to the processing of a certain purchase order or to the hiring of a given employee). In reality, however, such information rarely exists. In this paper, we present a framework for discovering correlations among messages in service logs. We characterize the problem of message correlation and propose novel algorithms and techniques based on heuristics on the characteristics of conversations and of message attributes that can act as identifier for such conversations. As we will show, there is no right or wrong way to correlate messages, and such correlation is necessarily subjective. To account for this subjectiveness, we propose an approach where algorithms suggest candidate correlators, provide measures that help users understand the implications of choosing a given correlators, and organize candidate correlators in such a way to facilitate visual exploration. The approach has been implemented and experimental results show its viability and scalability on large synthetic and real-world datasets. We believe that message correlation is a very important and challenging area of research that will witness many contributions in the near future due to the pressing industry needs for process and service execution analysis.},
author = {Nezhad, Hamid R. M. and Saint-Paul, Regis and Benatallah, Boualem and Casati, Fabio and Andritsos, Periklis},
file = {:Users/vitor/Mendeley/Nezhad et al. - 2007 - Message Correlation for Conversation Reconstruction in Service Interaction Logs.pdf:pdf},
institution = {DIT-07-010, University of Trento, Italy},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
title = {{Message Correlation for Conversation Reconstruction in Service Interaction Logs}},
url = {http://eprints.biblio.unitn.it/archive/00001175/},
year = {2007}
}
@inproceedings{nissen-et-al:re09,
abstract = {When developing software-based control systems, knowledge and experiences in the relevant domain are of great importance. Small- and medium-sized enterprises (SMEs) that are most active here need to capture requirements under severe time and costs pressures. In previous work we have shown that a domain model based on the requirements formalism i* accelerates the requirements capture. Furthermore, the domain model-based similarity search supports the detection of reusable components from earlier projects. But due to the innovativeness, flexibility, and customer-orientation of control systems development, this domain model is subject to continuous change. Within this paper, we investigate the effects of model evolution on our domain model-based requirements engineering approach. Building on examples from industrial practice, we develop a classification of possible domain model modifications. For each such class, we analyze its impact on the similarity search and derive appropriate counter measures to limit these harmful impacts.},
address = {Atlanta, USA},
author = {Nissen, Hans W. and Schmitz, Dominik and Jarke, Matthias and Rose, Thomas and Drews, Peter and Hesseler, Frank J. and Reke, Michael},
booktitle = {Proc. of the 17th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2009.38},
file = {:Users/vitor/Mendeley/Nissen et al. - 2009 - Evolution in Domain Model-Based Requirements Engineering for Control Systems Development.pdf:pdf},
isbn = {978-0-7695-3761-0},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {aug},
pages = {323--328},
publisher = {IEEE},
title = {{Evolution in Domain Model-Based Requirements Engineering for Control Systems Development}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5328510},
year = {2009}
}
@book{northrop-et-al:book06,
abstract = {Ultra-Large-Scale Systems: The Software Challenge of the Future is the product of a 12-month study of ultra-large-scale (ULS) systems software. The study brought together experts in software and other fields to answer a question: "Given the issues with today's software engineering, how can we build the systems of the future that are likely to have billions of lines of code?” The report details a broad, multi-disciplinary research agenda for developing the ultra-large-scale systems of the future.},
author = {Northrop, Linda and Feiler, Peter and Gabriel, Richard P. and Goodenough, John and Linger, Rick and Longstaff, Tom and Kazman, Rick and Klein, Mark and Schmidt, Douglas and Sullivan, Kevin and Wallnau, Kurt},
editor = {Pollak, Bill},
file = {:Users/vitor/Mendeley/Northrop et al. - 2006 - Ultra-Large-Scale Systems The Software Challenge of the Future.pdf:pdf},
isbn = {0-9786956-0-7},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Software Engineering Institute, Carnegie Mellon},
title = {{Ultra-Large-Scale Systems: The Software Challenge of the Future}},
url = {http://www.sei.cmu.edu/library/abstracts/books/0978695607.cfm},
year = {2006}
}
@inproceedings{omitola-et-al:ldfi10,
abstract = {The world is moving from a state where there is paucity of data to one of surfeit. These data, and datasets, are normally in different datastores and of different formats. Connecting these datasets together will increase their value and help discover interesting relationships amongst them. This paper describes our experience of using Linked Data to inter-operate these different datasets, the challenges we faced, and the solutions we devised. The paper concludes with apposite design principles for using linked data to inter-operate disparate datasets.},
address = {Ghent, Belgium},
author = {Omitola, Tope and Koumenides, Christos L. and Popov, Igor O. and Yang, Yang and Salvadores, Manuel and Correndo, Gianluca and Hall, Wendy and Shadbolt, Nigel},
booktitle = {Proc. of the 2010 Workshop on Linked Data in the Future Internet at the Future Internet Assembly (LDFI '10)},
editor = {Auer, S{\"{o}}ren and Decker, Stefan and Hauswirth, Manfred},
file = {:Users/vitor/Mendeley/Omitola et al. - 2010 - Integrating Public Datasets Using Linked Data Challenges and Design Principles.pdf:pdf},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {dec},
pages = {{\#}8},
publisher = {CEUR},
title = {{Integrating Public Datasets Using Linked Data: Challenges and Design Principles}},
url = {http://ceur-ws.org/Vol-700/},
year = {2010}
}
@article{oreizy-et-al:is99,
abstract = {Self-adaptive software requires high dependability, robustness, adaptability, and availability. This paper describes an infrastructure supporting two simultaneous processes in self-adaptive software: (1) system evolution, the consistent application of change over time, and (2) system adaptation, the cycle of detecting changing circumstances and planning and deploying responsive modifications.},
author = {Oreizy, Peyman and Gorlick, Michael. M. and Taylor, Richard N. and Heimhigner, Dennis and Johnson, Gregory and Medvidovic, Nenad and Quilici, Alex and Rosenblum, David S. and Wolf, Alexander L.},
doi = {10.1109/5254.769885},
file = {:Users/vitor/Mendeley/Oreizy et al. - 1999 - An Architecture-Based Approach to Self-Adaptive Software.pdf:pdf},
issn = {1094-7167},
journal = {IEEE Intelligent Systems},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {may},
number = {3},
pages = {54--62},
publisher = {IEEE},
title = {{An Architecture-Based Approach to Self-Adaptive Software}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=769885},
volume = {14},
year = {1999}
}
@article{orr:nature05,
abstract = {Theoretical studies of adaptation have exploded over the past decade. This work has been inspired by recent, surprising findings in the experimental study of adaptation. For example, morphological evolution sometimes involves a modest number of genetic changes, with some individual changes having a large effect on the phenotype or fitness. Here I survey the history of adaptation theory, focusing on the rise and fall of various views over the past century and the reasons for the slow development of a mature theory of adaptation. I also discuss the challenges that face contemporary theories of adaptation.},
author = {Orr, H. Allen},
doi = {10.1038/nrg1523},
issn = {1471-0056},
journal = {Nature reviews. Genetics},
keywords = {20th Century,21st Century,Adaptation,Animals,Biological,Biological: genetics,Biology,Biology: history,Evolution,Genetic,History,Humans,Models,Molecular,bibtex},
mendeley-tags = {bibtex},
month = {feb},
number = {2},
pages = {119--27},
pmid = {15716908},
title = {{The genetic theory of adaptation: a brief history.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15716908},
volume = {6},
year = {2005}
}
@inproceedings{paim-castro:re03,
abstract = {In the novel domain of data warehouse systems, software engineers are required to define a solution that integrates with a number of heterogeneous sources to extract, transform and aggregate data, as well as to offer flexibility to run adhoc queries that retrieve analytic information. Moreover, these activities should be performed based on a concise dimensional schema. This intricate process with its particular multidimensionality claims for a requirements engineering approach to aid the precise definition of data warehouse applications. We adapt the traditional requirements engineering process and propose DWARF, a data warehouse requirements definition method. A case study demonstrates how the method has been successfully applied in the company wise development of a large-scale data warehouse system that stores hundreds of gigabytes of strategic data for the Brazilian Federal Revenue Service.},
address = {Monterey, CA, USA},
author = {Paim, F{\'{a}}bio R.S. and Castro, Jaelson F. B.},
booktitle = {Journal of Lightwave Technology},
doi = {10.1109/ICRE.2003.1232739},
file = {:Users/vitor/Mendeley/Paim, Castro - 2003 - DWARF An Approach for Requirements Definition and Management of Data Warehouse Systems.pdf:pdf},
isbn = {0-7695-1980-6},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {sep},
pages = {75--84},
publisher = {IEEE},
title = {{DWARF: An Approach for Requirements Definition and Management of Data Warehouse Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1232739},
year = {2003}
}
@book{icac10,
abstract = {It is our great pleasure to welcome you to the 7th IEEE/ACM International Conference on Autonomic Computing and Communications -- ICAC-2010. Since its inception, ICAC has established a track record of meetings that attract quality technical papers addressing the multiple facets of self-management in computing systems and applications, and that promote synergistic interactions among academia and industry. This year's ICAC continues this tradition -- we are pleased with the organization of a strong, diverse program and the opportunity to host an event that brings together experts in this exciting field. So, first and foremost, we would like to thank the authors and conference attendees for making this year's conference a reality. This year, the program chairs have updated the call for papers to attract a broader set of topics to the conference. The call for papers attracted 66 submissions from Asia, Canada, Europe, and the United States. We opted for a smaller TPC than in past years to foster as much as possible group discussions during the face-to-face meeting -- we would like to thank all members of the program committee for their participation in a rigorous review process, in a fruitful TPC meeting, and in the shepherding of papers. Following on the tradition of past ICAC conferences, the TPC has strived to select a set of excellent and timely papers that represent the state of the art in autonomic computing and cover a range of topics in this cross-disciplinary field. This year, these topics include cloud infrastructures, performance and power management, software architectures, troubleshooting, and quality of service. The technical program features 18 papers in the conference main track, five Industry Session papers, and five posters. The chairs would also like to thank Brent Miller, Michael Nunez, and Thierry Coupaye for the organization of the Industry Session, continuing the ICAC tradition of fostering collaborations between industry and academia. We are privileged to have distinguished keynote speakers who will share their experience and vision also from both academia and industry perspectives. Complementing the main conference program are workshops that cover bio-inspired algorithms (BADS), Grid computing (GMAC), and self-organizing architectures (SOAR), and a Hot Topics in Autonomic Computing session associated with the conference, thanks to the leadership of Omer Rana and Julie McCann.},
address = {Reston, VA, USA},
editor = {Parashar, Manish and Figueiredo, Renato and Kıcıman, Emre Emre},
isbn = {978-1-4503-0074-2},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {ACM},
title = {{Proceedings of the 7th International Conference on Autonomic Computing}},
url = {http://dl.acm.org/citation.cfm?id=1809049},
year = {2010}
}
@article{pardillo-et-al:is10,
abstract = {The development of data warehouses begins with the definition of multidimensional models at the conceptual level in order to structure data, which will facilitate decision makers with an easier data analysis. Current proposals for conceptual multidimensional modelling focus on the design of static data warehouse structures, but few approaches model the queries which the data warehouse should support by means of OLAP (on-line analytical processing) tools. OLAP queries are, therefore, only defined once the rest of the data warehouse has been implemented, which prevents designers from verifying from the very beginning of the development whether the decision maker will be able to obtain the required information from the data warehouse. This article presents a solution to this drawback consisting of an extension to the object constraint language (OCL), which has been developed to include a set of predefined OLAP operators. These operators can be used to define platform-independent OLAP queries as a part of the specification of the data warehouse conceptual multidimensional model. Furthermore, OLAP tools require the implementation of queries to assure performance optimisations based on pre-aggregation. It is interesting to note that the OLAP queries defined by our approach can be automatically implemented in the rest of the data warehouse, in a coherent and integrated manner. This implementation is supported by a code-generation architecture aligned with model-driven technologies, in particular the MDA (model-driven architecture) proposal. Finally, our proposal has been validated by means of a set of sample data sets from a well-known case study.},
author = {Pardillo, Jes{\'{u}}s and Maz{\'{o}}n, Jose-Norberto and Trujillo, Juan},
doi = {10.1016/j.ins.2009.11.006},
file = {:Users/vitor/Mendeley/Pardillo, Maz{\'{o}}n, Trujillo - 2010 - Extending OCL for OLAP Querying on Conceptual Multidimensional Models of Data Warehouses.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {bibtex,conceptual modeling,data warehouse,multidimensional modeling,not-commented,olap,query language},
mendeley-tags = {bibtex,not-commented},
month = {mar},
number = {5},
pages = {584--601},
publisher = {Elsevier},
title = {{Extending OCL for OLAP Querying on Conceptual Multidimensional Models of Data Warehouses}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S002002550900468X},
volume = {180},
year = {2010}
}
@phdthesis{pasquale:thesis10,
abstract = {SOAs (Service Oriented Architectures) have been widely used for the provisioning and maintenance of business processes. SOA foster the pro- visioning of complex functionality through service compositions that as- semble third party, oftentimes distrubuted, services. In this context this thesis aims at providing service compositions able to enact business processes in a coherent and effective way (i.e., ac- cording to their requirements), and support their evolution. This is an ambitious objective that requires to address several open problems. First, requirements models must incorporate the variability of processes, due to their business dimension. Furthermore, the distributed and loose coupled nature of service composition may cause unexpected failures at runtime. For this reason, requirements must also express the adaptation strategies used to cope with the intrinsic unreliability of service compo- sitions. Second, service compositions must reflect their functional and non-functional requirements and avoid their violations by applying suit- able adaptation strategies. To this aim, methods and tools to precisely relate requirements to service compositions must be provided. Finally, requirements must be constantly assessed at runtime and adaptation strategies be activated when necessary to keep the execution on track and offer a reliable and trustable solutions. This thesis addresses these challenges by proposing a goal-oriented methodology. It introduces a new goal model to represent the require- ments of the system together with its self-adaptation capabilities. It traces requirements onto a service composition, able to satisfy stated requirements, and a set of strategies that define how to assess the re- quirements of interest and keep the application on track. Finally, the proposed methodology is complemented by a flexible runtime infrastruc- ture that supports the controlled execution of service compositions. VI},
author = {Pasquale, Liliana},
file = {:Users/vitor/Mendeley/Pasquale - 2010 - A Goal-oriented Methodology for Self-supervised Service Compositions.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
school = {Politecnico di Milano},
title = {{A Goal-oriented Methodology for Self-supervised Service Compositions}},
type = {PhD Thesis},
url = {http://www.dei.polimi.it/ricerca/alumni/details.php?idlang=ita{\&}id{\_}elemento=257},
year = {2010}
}
@article{pastor-et-al:is08,
abstract = {Abstract The model-driven architecture (MDA) paradigm is well-known and widely used in the field of model-based software development.$\backslash$nHowever, there are still some issues that are problematic and that need to be dealt with carefully. In this paper we present$\backslash$na metaphor that explains how MDA grows in complexity as problems faced become more difficult or “wicked”, and how a method$\backslash$ndesigned to be powerful, flexible and MDA-compliant can eventually become, in effect, a “jigsaw puzzle”. This jigsaw puzzle$\backslash$nis not merely the result of having a collection of methodological “pieces” with routes across them, but also arises as a result$\backslash$nof the criteria underlying the MDA abstraction layers. We compare MDA to other research fields such as human-computer interaction,$\backslash$nmodel management and method engineering, and we use as an example the OO-Method, a software development method based on MDA-compliant$\backslash$nmodel transformations. We focus on a methodological piece that is conceived to allow the specification of interaction requirements$\backslash$nby means of interface sketches. These sketches are supported by a task model that serves as a sound basis for formalisation$\backslash$nand allows the application of model transformation in order to obtain subsequent models. A case study illustrates the requirements$\backslash$ncapture method together with the software development process defined by the OO-Method. The whole process presented in the$\backslash$ncase study represents one of the possible routes that can be followed when developing a software system with the OO-Method.},
author = {Pastor, Oscar and Espa{\~{n}}a, Sergio and Panach, Jos{\'{e}} Ignacio and Aquino, Nathalie},
doi = {10.1007/s00287-008-0275-8},
file = {:Users/vitor/Mendeley/Pastor et al. - 2008 - Model-driven development.pdf:pdf},
isbn = {0170-6012},
issn = {01706012},
journal = {Informatik-Spektrum},
keywords = {bibtex},
mendeley-tags = {bibtex},
number = {5},
pages = {394--407},
publisher = {Springer},
title = {{Model-driven development}},
url = {http://link.springer.com/article/10.1007/s00287-008-0275-8},
volume = {31},
year = {2008}
}
@inproceedings{peng-et-al:dddm07,
abstract = {Within Business Intelligence (BI) systems, a Key Performance Indicator (KPI) is a measurement of how well the organization, or a specific individual or process within that organization, performs an operational, tactical, or strategic activity that is critical for the current and future success of that organization [1]. The leading indicators are one type of KPIs that present key drivers of business value, are predictors of future outcomes, and offer the organization the unique opportunity to positively effect, or properly plan for, the future. Therefore, effective leading indicators are critical to the success of any business organization. However, identifying leading indicators is often non-trivial. It may require months to collect requirements, standardizing definitions and rules, prioritizing metrics, and soliciting feedback, etc. Moreover, because the time shifts between the leading indicators and the corresponding affected lagging indicators are vague and often inconstant for variability of business concerns, the traditional approach depending on domain experts' experiences is labor-intensive and error-prone. In this paper, we propose a semi-automatic system with an iterative learning process for analyzing operational metrics, factoring out the key performance indicators (KPIs) and then further discovering leading indicators. Two case studies are also conducted by applying the proposed methods in the production printing domain. The proposed system has two key differentiations and novelties: (1) the semi-automatic framework simplifies many traditional labor-intensive and error-prone steps by using temporal data mining techniques combined with specific domain knowledge, thus enabling timely access to operational metrics, KPI analysis, and powerful leading indicator discovery; (2) an iterative learning methodology not only continuingly uncovers the “root” leading indicators, but also enables the flexibility and adaptability for metric updates and additional data collection points.},
address = {San Jose, CA, USA},
annote = {Interesting reference on KPIs. Maybe seminal work.},
author = {Peng, Wei and Sun, Tong and Rose, Philip and Li, Tao},
booktitle = {Proc. of the 2007 International Workshop on Domain Driven Data Mining},
doi = {10.1145/1288552.1288557},
file = {:Users/vitor/Mendeley/Peng et al. - 2007 - A Semi-automatic System with an Iterative Learning Method for Discovering the Leading Indicators in Business Proces.pdf:pdf},
isbn = {9781595938466},
keywords = {bibtex,commented,domain driven data mining,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {aug},
pages = {33--42},
publisher = {ACM},
title = {{A Semi-automatic System with an Iterative Learning Method for Discovering the Leading Indicators in Business Processes}},
url = {http://portal.acm.org/citation.cfm?doid=1288552.1288557},
year = {2007}
}
@inproceedings{peng-et-al:re10,
abstract = {Quality requirements of a software system cannot be optimally met, especially when it is running in an uncertain and changing environment. In principle, a controller at runtime can monitor the change impact on quality requirements of the system, update the expectations and priorities from the environment, and take reasonable actions to improve the overall satisfaction. In practice, however, existing controllers are mostly designed for tuning low-level performance indicators rather than high-level requirements. By linking the overall satisfaction to a business value indicator as feedback, we propose a control theoretic self-tuning method that can dynamically adjust the tradeoff decisions among different quality requirements. A preference-based reasoning algorithm is involved to configure hard goals accordingly to guide the following architecture reconfiguration.},
address = {Sydney, Australia},
author = {Peng, Xin and Chen, Bihuan and Yu, Yijun and Zhao, Wenyun},
booktitle = {Proc. of the 18th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2010.22},
file = {:Users/vitor/Mendeley/Peng et al. - 2010 - Self-Tuning of Software Systems through Goal-based Feedback Loop Control.pdf:pdf},
isbn = {978-1-4244-8022-7},
keywords = {bibtex,commented,control theory,goal reasoning,self-tuning},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {104--107},
publisher = {IEEE},
title = {{Self-Tuning of Software Systems through Goal-based Feedback Loop Control}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5636884},
year = {2010}
}
@article{peng-et-al:ist11,
abstract = {Context: In the long run, features of a software product line (SPL) evolve with respect to changes in stake- holder requirements and system contexts. Neither domain engineering nor requirements engineering handles such co-evolution of requirements and contexts explicitly, making it especially hard to reason about the impact of co-changes in complex scenarios. Objective: In this paper, we propose a problem-oriented and value-based analysis method for variability evolution analysis. The method takes into account both kinds of changes (requirements and contexts) during the life of an evolving software product line. Method: The proposed method extends the core requirements engineering ontology with the notions to represent variability-intensive problem decomposition and evolution. On the basis of problemorienta- tion, the analysis method identifies candidate changes, detects influenced features, and evaluates their contributions to the value of the SPL. Results and Conclusion: The process of applying the analysis method is illustrated using a concrete case study of an evolving enterprise software system, which has confirmed that tracing back to requirements and contextual changes is an effective way to understand the evolution of variability in the software product line.},
author = {Peng, Xin and Yu, Yijun and Zhao, Wenyun},
doi = {10.1016/j.infsof.2011.01.001},
file = {:Users/vitor/Mendeley/Peng, Yu, Zhao - 2011 - Analyzing evolution of variability in a software product line From contexts and requirements to features.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {bibtex,commented,context,evolution,feature,requirements,software product line,variability},
mendeley-tags = {bibtex,commented},
month = {jul},
number = {7},
pages = {707--721},
publisher = {Elsevier},
title = {{Analyzing evolution of variability in a software product line: From contexts and requirements to features}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584911000024},
volume = {53},
year = {2011}
}
@techreport{peruch-pg07,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Peruch, Leonardo Ara{\'{u}}jo},
file = {:Users/vitor/Mendeley/Peruch - 2007 - Aplica{\c{c}}{\~{a}}o e An{\'{a}}lise do M{\'{e}}todo FrameWeb com Diferentes Frameworks Web.pdf:pdf},
institution = {Projeto de Gradua{\c{c}}{\~{a}}o (orientador principal: Giancarlo Guizzardi), Departamento de Inform{\'{a}}tica, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{Aplica{\c{c}}{\~{a}}o e An{\'{a}}lise do M{\'{e}}todo FrameWeb com Diferentes Frameworks Web}},
year = {2007}
}
@inproceedings{petersen-et-al:ease08,
abstract = {BACKGROUND: A software engineering systematic map is a defined method to build a classification scheme and structure a software engineering field of interest. The analysis of results focuses on frequencies of publications for categories within the scheme. Thereby, the coverage of the research field can be determined. Different facets of the scheme can also be combined to answer more specific research questions. OBJECTIVE: We describe how to conduct a systematic mapping study in software engineering and provide guidelines. We also compare systematic maps and systematic reviews to clarify how to chose between them. This comparison leads to a set of guidelines for systematic maps. METHOD: We have defined a systematic mapping process and applied it to complete a systematic mapping study. Furthermore, we compare systematic maps with systematic reviews by systematically analyzing existing systematic reviews. RESULTS: We describe a process for software engineering systematic mapping studies and compare it to systematic reviews. Based on this, guidelines for conducting systematic maps are defined. CONCLUSIONS: Systematic maps and reviews are different in terms of goals, breadth, validity issues and implications. Thus, they should be used complementarily and require different methods (e.g., for analysis).},
address = {Bari, Italy},
author = {Petersen, Kai and Feldt, Robert and Mujtaba, Shahid and Mattsson, Michael},
booktitle = {Proc. of the 12th International Conference on Evaluation and Assessment in Software Engineering},
file = {:Users/vitor/Mendeley/Petersen et al. - 2008 - Systematic Mapping Studies in Software Engineering.pdf:pdf},
keywords = {bibtex,evidence based software engineering,summarized,systematic mapping studies,systematic reviews},
mendeley-tags = {bibtex,summarized},
month = {jun},
pages = {68--77},
publisher = {British Computer Society Swinton},
title = {{Systematic Mapping Studies in Software Engineering}},
url = {http://dl.acm.org/citation.cfm?id=2227115.2227123},
year = {2008}
}
@article{petersen-et-al:jist15,
abstract = {Context: Systematic mapping studies are used to structure a research area, while systematic reviews are focused on gathering and synthesizing evidence. The most recent guidelines for systematic mapping are from 2008. Since that time, many suggestions have been made of how to improve systematic literature reviews (SLRs). There is a need to evaluate how researchers conduct the process of systematic mapping and identify how the guidelines should be updated based on the lessons learned from the existing systematic maps and SLR guidelines. Objective: To identify how the systematic mapping process is conducted (including search, study selection, analysis and presentation of data, etc.); to identify improvement potentials in conducting the systematic mapping process and updating the guidelines accordingly. Method: We conducted a systematic mapping study of systematic maps, considering some practices of systematic review guidelines as well (in particular in relation to defining the search and to conduct a quality assessment). Results: In a large number of studies multiple guidelines are used and combined, which leads to different ways in conducting mapping studies. The reason for combining guidelines was that they differed in the recommendations given. Conclusion: The most frequently followed guidelines are not sufficient alone. Hence, there was a need to provide an update of how to conduct systematic mapping studies. New guidelines have been proposed consolidating existing findings.},
author = {Petersen, Kai and Vakkalanka, Sairam and Kuzniarz, Ludwik},
doi = {10.1016/j.infsof.2015.03.007},
file = {:Users/vitor/Mendeley/Petersen, Vakkalanka, Kuzniarz - 2015 - Guidelines for conducting systematic mapping studies in software engineering An update.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {bibtex},
mendeley-tags = {bibtex},
pages = {1--18},
publisher = {Elsevier},
title = {{Guidelines for conducting systematic mapping studies in software engineering: An update}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584915000646},
volume = {64},
year = {2015}
}
@inproceedings{pimentel-et-al:istar13,
abstract = {The growing interest in developing adaptive systems has led to numerous proposals for approaches aimed at supporting their development. Some approaches define adaptation mechanisms in terms of architectural design, consisting of concepts such as components, connectors and states. Other approaches are requirements-based, thus concerned with goals, tasks, contexts and preferences as concepts in terms of which adaptation is defined. By considering only a problem- or a solution- oriented view, such proposals are limited in specifying adaptive behavior. In this paper we present ongoing work on supporting the design and runtime execution of adaptive software systems both at a requirements and architectural level, as wells as its challenges, ranging from architectural derivation from requirements to refined adaptation control mechanisms.},
address = {Valencia, Spain},
annote = {Short paper},
author = {Pimentel, Jo{\~{a}}o and Angelopoulos, Konstantinos and Souza, V{\'{i}}tor E. S. and Mylopoulos, John and Castro, Jaelson F. B.},
booktitle = {Proc. of the 6th International i* Workshop},
editor = {Castro, Jaelson F. B. and Jennifer, Horkoff; and Maiden, Neil and Yu, Eric S. K.},
file = {:Users/vitor/Mendeley/Pimentel et al. - 2013 - From Requirements to Architectures for Better Adaptive Software Systems.pdf:pdf},
keywords = {adaptation control mechanisms,adaptive systems,architectural design,bibtex,export,requirements},
mendeley-tags = {bibtex,export},
month = {jun},
pages = {91--96},
publisher = {CEUR},
title = {{From Requirements to Architectures for Better Adaptive Software Systems}},
url = {http://ceur-ws.org/Vol-978/},
volume = {978},
year = {2013}
}
@inproceedings{pimentel-et-al:sac14,
abstract = {The derivation of statecharts from requirements has been addressed from many perspectives. All of them assume that the derivation process is a linear series of refinements resulting in a single statechart, thereby missing the opportunity to explore alternatives in the design space. We propose a multi-dimensional approach that exploits inherent variability of the design space, where alternative refinements are considered for the same intermediate problem, resulting in multiple solutions (statecharts) from a single initial problem (requirements). In order to accomplish this, we propose an extended form of goal model where architects can incrementally refine the original requirements by considering behavioral alternatives leading to design solutions. The proposed refinement process is illustrated through an example from the literature. Experimentation with randomly generated models suggests that the proposal is scalable.},
address = {Gyeongju, Korea},
annote = {Qualis 2012: A1},
author = {Pimentel, Jo{\~{a}}o and Castro, Jaelson F. B. and Mylopoulos, John and Angelopoulos, Konstantinos and Souza, V{\'{i}}tor E. S.},
booktitle = {Proc. of the 29th Annual ACM Symposium on Applied Computing},
doi = {10.1145/2554850.2555056},
file = {:Users/vitor/Mendeley/Pimentel et al. - 2014 - From requirements to statecharts via design refinement.pdf:pdf},
isbn = {9781450324694},
keywords = {bibtex,export},
mendeley-tags = {bibtex,export},
month = {mar},
pages = {995--1000},
publisher = {ACM},
title = {{From requirements to statecharts via design refinement}},
url = {http://dl.acm.org/citation.cfm?doid=2554850.2555056},
year = {2014}
}
@article{pimentel-et-al:re12,
abstract = {Some quality attributes are known to have an impact on the overall architecture of a system, so that they are required to be properly handled from the early beginning of the software development. For example, adaptability is a key concern for autonomic and adaptive systems, which brings to them the capability to alter their behavior in response to changes on their surrounding environments. In this paper, we propose a Strategy for Transition between Requirements and Architectural Models for Adaptive systems (STREAM-A). In particular, we use goal models based on the i* (i-Star) framework to support the design and evolution of systems that require adaptability. To obtain software architectures for such systems, the STREAM-A approach uses model transformations from i* models to architectural models expressed in Acme. Both the requirements and the architectural model are refined to accomplish the adaptability requirement.},
author = {Pimentel, Jo{\~{a}}o and Lucena, M{\'{a}}rcia and Castro, Jaelson F. B. and Silva, Carla and Santos, Emanuel and Alencar, Fernanda},
doi = {10.1007/s00766-011-0126-z},
file = {:Users/vitor/Mendeley/Pimentel et al. - 2012 - Deriving software architectural models from requirements models for adaptive systems the STREAM-A approach(2).pdf:pdf},
issn = {0947-3602},
journal = {Requirements Engineering},
keywords = {Adaptive systems,Architectural design,Mapping between requirements model and architectur,Model-driven engineering,Requirements engineering,bibtex,commented},
mendeley-tags = {bibtex,commented},
number = {4},
pages = {259--281},
publisher = {Springer},
title = {{Deriving software architectural models from requirements models for adaptive systems: the STREAM-A approach}},
url = {http://link.springer.com/article/10.1007{\%}2Fs00766-011-0126-z},
volume = {17},
year = {2012}
}
@inproceedings{pourshahid-et-al:mcetech08,
abstract = {A number of recent initiatives in both academia and industry have sought to achieve improvements in e- businesses through the utilization of Business Process Management (BPM) methodologies and tools. How- ever there are still some inadequacies that need to be addressed when it comes to achieving alignment between business goals and business processes. The User Requirements Notation (URN) has some unique features and capabilities beyond what is available in other notations that can help address alignment issues. In this paper, a URN-based framework and its support- ing toolset are introduced which provide business process monitoring and performance management capabilities integrated across the BPM lifecycle. The framework extends the URN notation with Key Performance Indicators (KPI) and other concepts to measure, and align processes and goals. A healthcare case study is used to illustrate and evaluate the frame- work. Early results indicate the feasibility of the approach.},
address = {Montreal, QC, Canada},
author = {Pourshahid, Alireza and Amyot, Daniel and Peyton, Liam and Ghanavati, Sepideh and Chen, Pengfei and Weiss, Michael and Forster, Alan J.},
booktitle = {Proc. of the 2008 International MCETECH Conference on e-Technologies},
doi = {10.1109/MCETECH.2008.30},
file = {:Users/vitor/Mendeley/Pourshahid et al. - 2008 - Toward an integrated User Requirements Notation framework and tool for Business Process Management.pdf:pdf},
isbn = {978-0-7695-3082-6},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {jan},
pages = {3--15},
publisher = {IEEE},
title = {{Toward an integrated User Requirements Notation framework and tool for Business Process Management}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4483413},
year = {2008}
}
@techreport{prado-pg15,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {do Prado, Rodolfo Costa},
file = {:Users/vitor/Mendeley/Prado - 2015 - Aplica{\c{c}}{\~{a}}o do m{\'{e}}todo FrameWeb no desenvolvimento de um sistema de informa{\c{c}}{\~{a}}o utilizando o framework VRaptor 4.pdf:pdf},
institution = {Projeto de Gradua{\c{c}}{\~{a}}o, Departamento de Inform{\'{a}}tica, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{Aplica{\c{c}}{\~{a}}o do m{\'{e}}todo FrameWeb no desenvolvimento de um sistema de informa{\c{c}}{\~{a}}o utilizando o framework VRaptor 4}},
year = {2015}
}
@incollection{prakash-et-al:er04,
abstract = {We propose a requirements elicitation process for a data warehouse (DW) that identifies its information contents. These contents support the set of decisions that can be made. Thus, if the information needed to take every decision is elicited, then the total information determines DW contents. We propose an Informational Scenario as the means to elicit information for a decision. An informational scenario is written for each decision and is a sequence of pairs of the form {\textless} Query , Response {\textgreater}. A query requests for information necessary to take a decision and the response is the information itself. The set of responses for all decisions identifies DW contents. We show that informational scenarios are merely another sub class of the class of scenarios.},
annote = {10.1007/978-3-540-30464-7{\_}17},
author = {Prakash, Naveen and Singh, Yogesh and Gosain, Anjana},
booktitle = {Conceptual Modeling -- ER 2004},
doi = {10.1007/978-3-540-30464-7_17},
editor = {Atzeni, Paolo and Chu, Wesley and Lu, Hongjun and Zhou, Shuigeng and Ling, Tok-Wang},
file = {:Users/vitor/Mendeley/Prakash, Singh, Gosain - 2004 - Informational Scenarios for Data Warehouse Requirements Elicitation.pdf:pdf},
isbn = {978-3-540-23723-5},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
pages = {205--216},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Informational Scenarios for Data Warehouse Requirements Elicitation}},
url = {http://www.springerlink.com/content/1g44g3h0ah7y2k5u/},
volume = {3288},
year = {2004}
}
@book{pressman:book14,
abstract = {For almost three decades, Roger Pressman's Software Engineering: A Practitioner's Approach has been the world's leading textbook in software engineering. The new eighth edition represents a major restructuring and update of previous editions, solidifying the book's position as the most comprehensive guide to this important subject. The eighth edition of Software Engineering: A Practitioner's Approach has been designed to consolidate and restructure the content introduced over the past two editions of the book. The chapter structure will return to a more linear presentation of software engineering topics with a direct emphasis on the major activities that are part of a generic software process. Content will focus on widely used software engineering methods and will de-emphasize or completely eliminate discussion of secondary methods, tools and techniques. The intent is to provide a more targeted, prescriptive, and focused approach, while attempting to maintain SEPA's reputation as a comprehensive guide to software engineering. The 39 chapters of the eighth edition are organized into five parts - Process, Modeling, Quality Management, Managing Software Projects, and Advanced Topics. The book has been revised and restructured to improve pedagogical flow and emphasize new and important software engineering processes and practices.},
author = {Pressman, Roger S.},
edition = {8},
isbn = {0078022126},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {McGraw-Hill},
title = {{Software Engineering - A Practitioner's Approach}},
url = {http://highered.mheducation.com/sites/0078022126/information{\_}center{\_}view0/index.html},
year = {2014}
}
@book{pressman:book11,
abstract = {S{\'{e}}tima edi{\c{c}}{\~{a}}o do livro mais importante sobre engenharia de software da atualidade. Vers{\~{a}}o concebida tanto para alunos de gradua{\c{c}}{\~{a}}o quanto para profissionais da {\'{a}}rea. Oferece uma abordagem contempor{\^{a}}nea sobre produ{\c{c}}{\~{a}}o do software, gest{\~{a}}o da qualidade, gerenciamento de projetos etc., com did{\'{a}}tica eficiente e exerc{\'{i}}cios de grande aplica{\c{c}}{\~{a}}o pr{\'{a}}tica.},
author = {Pressman, Roger S.},
edition = {7{\textordfeminine} Edi{\c{c}}{\~{a}}o},
isbn = {9788563308337},
keywords = {bibtex},
mendeley-tags = {bibtex},
pages = {780},
publisher = {McGraw-Hill},
title = {{Engenharia de Software - Uma Abordagem Profissional}},
url = {http://www.grupoa.com.br/livros/engenharia-de-software-e-metodos-ageis/engenharia-de-software/9788563308337},
year = {2011}
}
@techreport{pulini-et-al-spec06,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Pulini, Igor Carlos and Ramos, Murilo Kill and {Anschau Jr.}, Querino},
institution = {P{\'{o}}s-gradua{\c{c}}{\~{a}}o em Java, Tecnologias e Desenvolvimento de Sistemas, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{Sistema de Assist{\^{e}}ncia ao Atendimento M{\'{e}}dico}},
year = {2006}
}
@incollection{qureshi-et-al:caise11,
abstract = {The vision for self-adaptive systems (SAS) is that they should continuously adapt their behavior at runtime in response to changing user's requirements, operating contexts, and resource availability. Realizing this vision requires that we understand precisely how the various steps in the engineering of SAS depart from the established body of knowledge in information systems engineering. We focus in this paper on the requirements engineering for SAS. We argue that SAS need to have an internal representation of the requirements problem that they are solving for their users. We formally define a minimal set of concepts and relations needed to formulate the requirements problem, its solutions, the changes in its formulation that arise from changes in the operating context, requirements, and resource availability. We thereby precisely define the runtime requirements adaptation problem that a SAS should be engineered to solve.},
annote = {10.1007/978-3-642-21640-4{\_}5},
author = {Qureshi, Nauman A. and Jureta, Ivan J. and Perini, Anna},
booktitle = {Advanced Information Systems Engineering},
doi = {10.1007/978-3-642-21640-4_5},
editor = {Mouratidis, Haralambos and Rolland, Colette},
file = {:Users/vitor/Mendeley/Qureshi, Jureta, Perini - 2011 - Requirements Engineering for Self-Adaptive Systems Core Ontology and Problem Statement.pdf:pdf},
isbn = {978-3-642-21639-8},
keywords = {adaptation problem,bibtex,highlight,not-commented,requirements engineering,runtime,self-adaptive systems},
mendeley-tags = {bibtex,highlight,not-commented},
pages = {33--47},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Requirements Engineering for Self-Adaptive Systems: Core Ontology and Problem Statement}},
url = {http://www.springerlink.com/content/fu3145486226141n/},
volume = {6741},
year = {2011}
}
@inproceedings{qureshi-et-al:rrt11,
abstract = {Increasing proliferation of mobile applications challenge the role of requirements engineering (RE) in developing customizable and adaptive software applications for the end-users. Such adaptive applications need to alter their behavior while monitoring and evaluating the changes in the environment at runtime by being aware of their end-user's needs, context and resources. More specifically, these applications should be able to: (i) reason about their own requirements and refine and validate them at run-time by involving end-users, if necessary; (ii) provide solutions for the refined or changed requirements at runtime, for instance by exploiting available services. In this position paper we focus on the first issue. We propose to extend our previous work on adaptive requirements with preference-based reasoning and automated planning to enable a continuous adaptive reasoning of requirements at runtime. We describe this vision using a navigation system example and highlight challenges.},
address = {Trento, Italy},
author = {Qureshi, Nauman A. and Liaskos, Sotirios and Perini, Anna},
booktitle = {Proc. of the 2nd International Workshop on Requirements@Run.Time},
doi = {10.1109/ReRunTime.2011.6046243},
file = {:Users/vitor/Mendeley/Qureshi, Liaskos, Perini - 2011 - Reasoning About Adaptive Requirements for Self-Adaptive Systems at Runtime.pdf:pdf},
isbn = {978-1-4577-0942-5},
keywords = {bibtex,feedback,not-commented,planning,requirements engineering,self-adaptive systems},
mendeley-tags = {bibtex,not-commented},
month = {aug},
pages = {16--22},
publisher = {IEEE},
title = {{Reasoning About Adaptive Requirements for Self-Adaptive Systems at Runtime}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6046243},
year = {2011}
}
@inproceedings{qureshi-perini:seams09,
abstract = {Challenges in the engineering of self-adaptive software have been recently discussed and summarized in a semi- nal research road map. Following it, we focus on requirements engineering issues, with a two-fold, long term objective. The first objective is to support the system analyst to engineer adaptive requirements at requirements-time, the second is to make software able to reason on requirements at run-time in order to enable a goal-oriented adaptation. Along the first objective, in this position paper we pro- pose a characterization of adaptive requirements. Moreover, we investigate how available techniques aimed at eliciting and specifying domain properties, stakeholders goals and preferences, can provide a practical support to the analyst while capturing adaptive requirements.},
address = {Vancouver, Canada},
author = {Qureshi, Nauman A. and Perini, Anna},
booktitle = {Proc. of the 2009 ICSE Workshop on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1109/SEAMS.2009.5069081},
file = {:Users/vitor/Mendeley/Qureshi, Perini - 2009 - Engineering Adaptive Requirements.pdf:pdf},
isbn = {978-1-4244-3724-5},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {may},
pages = {126--131},
publisher = {IEEE},
title = {{Engineering Adaptive Requirements}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5069081},
year = {2009}
}
@inproceedings{qureshi-perini:re10,
abstract = {Service-Based Applications (SBA) are inherently open and distributed, as they rely on third-party services that are available over the Internet, and have to cope with the dynamism of such operating environment. This motivates the need for SBA to be self-adaptive to accommodate changes in service availability and performance, in consumers' needs and preferences, and more generally in the operational environment, which may occur at run-time. Engineering such applications significantly challenges the role of requirements engineering (RE). Usually, RE is carried out at the outset of the whole development process, but in the context of SBA, RE activities are also needed at run-time thus enabling a seamless SBA evolution. In this paper, we investigate RE for SBA at run-time proposing a method that supports the continuous refinement of requirements artifacts at run-time, which involves consumers and the SBA itself as primary stakeholders.},
address = {Sydney, Australia},
author = {Qureshi, Nauman A. and Perini, Anna},
booktitle = {Proc. of the 18th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2010.23},
file = {:Users/vitor/Mendeley/Qureshi, Perini - 2010 - Requirements Engineering for Adaptive Service Based Applications.pdf:pdf},
isbn = {978-1-4244-8022-7},
keywords = {bibtex,commented,requirements engineering,self-adaptive systems,service based applications},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {108--111},
publisher = {IEEE},
title = {{Requirements Engineering for Adaptive Service Based Applications}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5636635},
year = {2010}
}
@inproceedings{ramirez-cheng:seams10,
abstract = {Increasingly, software systems should self-adapt to satisfy new requirements and environmental conditions that may arise after deployment. Due to their high complexity, adaptive programs are difficult to specify, design, verify, and validate. Moreover, the current lack of reusable design expertise that can be leveraged from one adaptive system to another further exacerbates the problem. We studied over thirty adaptation-related research and project implementations available from the literature and open sources to harvest adaptation-oriented design patterns that support the development of adaptive systems. These adaptation-oriented patterns facilitate the separate development of the functional and adaptive logic. In order to support the assurance of adaptive systems, each design pattern includes templates that formally specify invariant properties of adaptive systems. To demonstrate their usefulness, we have applied a subset of our adaptation-oriented patterns to the design and implementation of ZAP.com, an adaptive news web server.},
address = {Cape Town, South Africa},
author = {Ramirez, Andres J. and Cheng, Betty H. C.},
booktitle = {Proc. of the 2010 ICSE Workshop on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1145/1808984.1808990},
file = {:Users/vitor/Mendeley/Ramirez, Cheng - 2010 - Design Patterns for Developing Dynamically Adaptive Systems.pdf:pdf},
isbn = {9781605589718},
keywords = {adaptive systems,autonomic systems,bibtex,commented,design patterns},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {49--58},
publisher = {ACM},
title = {{Design Patterns for Developing Dynamically Adaptive Systems}},
url = {http://portal.acm.org/citation.cfm?doid=1808984.1808990},
year = {2010}
}
@article{reiter:ai87,
abstract = {Suppose one is given a description of a system, together with an observation of the system's behaviour which conflicts with the way the system is meant to behave. The diagnostic problem is to determine those components of the system which, when assumed to be functioning abnormally, will explain the discrepancy between the observed and correct system behaviour. We propose a general theory for this problem. The theory requires only that the system be described in a suitable logic. Moreover, there are many such suitable logics, e.g. first-order, temporal, dynamic, etc. As a result, the theory accommodates diagnostic reasoning in a wide variety of practical settings, including digital and analogue circuits, medicine, and database updates. The theory leads to an algorithm for computing all diagnoses, and to various results concerning principles of measurement for discriminating among competing diagnoses. Finally, the theory reveals close connections between diagnostic reasoning and nonmonotonic reasoning.},
author = {Reiter, Raymond},
doi = {10.1016/0004-3702(87)90062-2},
file = {:Users/vitor/Mendeley/Reiter - 1987 - A Theory of Diagnosis from First Principles.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {bibtex,summarized,x-commented},
mendeley-tags = {bibtex,summarized,x-commented},
month = {apr},
number = {1},
pages = {57--95},
publisher = {Elsevier},
title = {{A Theory of Diagnosis from First Principles}},
url = {http://www.sciencedirect.com/science/article/pii/0004370287900622},
volume = {32},
year = {1987}
}
@inproceedings{resnik:ijcai95,
abstract = {This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66).},
address = {Montreal, QC, Canada},
author = {Resnik, Philip},
booktitle = {Proc. of the 14th International Joint Conference on Artificial Intelligence},
file = {:Users/vitor/Mendeley/Resnik - 1995 - Using Information Content to Evaluate Semantic Similarity in a Taxonomy.pdf:pdf},
keywords = {bibtex,summarized},
mendeley-tags = {bibtex,summarized},
month = {aug},
pages = {448--453},
publisher = {Morgan Kaufmann Publishers},
title = {{Using Information Content to Evaluate Semantic Similarity in a Taxonomy}},
url = {http://arxiv.org/abs/cmp-lg/9511007v1},
volume = {1},
year = {1995}
}
@misc{reynolds:website11a,
author = {Reynolds},
file = {:Users/vitor/Mendeley/Reynolds - 2011 - Categorised, posted at the blog ``Random Acts of Reality'', httpweb.archive.orgweb20110520163639httprandomreality.blog.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{Categorised, posted at the blog ``Random Acts of Reality'', http://web.archive.org/web/20110520163639/http://randomreality.blogware.com/blog/{\_}archives/2004/2/18/21077.html (archived at: May 20th, 2011)}},
url = {http://randomreality.blogware.com/blog/{\_}archives/2004/2/18/21077.html},
year = {2011}
}
@misc{reynolds:website11b,
author = {Reynolds},
file = {:Users/vitor/Mendeley/Reynolds - 2011 - ORCON!, posted at the blog ``Random Acts of Reality'', httpweb.archive.orgweb20110520165433httprandomreality.blogware..pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{ORCON!, posted at the blog ``Random Acts of Reality'', http://web.archive.org/web/20110520165433/http://randomreality.blogware.com/blog/{\_}archives/2004/3/15/21076.html (archived at: May 20th, 2011)}},
url = {http://randomreality.blogware.com/blog/{\_}archives/2004/3/15/21076.html},
year = {2011}
}
@book{ibm03,
doi = {10.1147/sj.421.0003},
editor = {Ritsko, John J.},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {IBM},
title = {{IBM Systems Journal, Volume 42, Issue 1}},
url = {http://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=5386828},
year = {2003}
}
@inproceedings{robinson:hicss05,
abstract = {With the increasing complexity of information systems, it is becoming increasingly unclear as to how information system behaviors relate to stated requirements. Although requirements documents and Business Activity Monitoring can provide static and dynamic evidence for requirements compliance, neither provides a formal, real-time presentation of requirements satisfaction. The REQMON research project is constructing and validating methods and tools for requirements specification and real-time monitoring. The challenge is to simplify monitoring system construction while ensuring the fidelity and expressiveness of its feedback. To address this challenge, our integrative approach leverages a formal monitoring abstraction layer, dynamically configurable distributed monitors, and commercial software to define a theory for specifying, developing, and analyzing requirements monitoring systems. This article presents an implementation of rule-based monitors, which are derived from system requirements. Such an implementation can simplify the specification of temporal requirements monitors and can be efficient, as our analysis shows.},
address = {Waikoloa, HI, USA},
author = {Robinson, William N.},
booktitle = {Proc. of the 38th Annual Hawaii International Conference on System Sciences},
doi = {10.1109/HICSS.2005.306},
file = {:Users/vitor/Mendeley/Robinson - 2005 - Implementing Rule-Based Monitors within a Framework for Continuous Requirements Monitoring.pdf:pdf},
isbn = {0-7695-2268-8},
keywords = {bibtex,summarized,x-commented},
mendeley-tags = {bibtex,summarized,x-commented},
month = {jan},
pages = {188a},
publisher = {IEEE},
title = {{Implementing Rule-Based Monitors within a Framework for Continuous Requirements Monitoring}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1385616},
year = {2005}
}
@article{robinson:eceasst08,
abstract = {Monitoring human-computer interaction aids the analysis for understanding how well software meets its purpose. In particular, monitoring human-computer interactions with respect to a user's goal model helps to determine user satisfaction. By formalizing a goal model, runtime monitors can be automatically derived. The REQMON system monitors the satisfaction of goal models. Recently, an OCL compiler was developed for REQMON. The OCL was extended slightly to address temporal and real-time constraints. Now, goal models can be represented in the extended OCL, from which runtime monitors can be compiled. The resulting REQMON system appears to be easier to use comes the abstract.},
address = {Nashville, USA},
author = {Robinson, William N.},
file = {:Users/vitor/Mendeley/Robinson - 2008 - Extended OCL for Goal Monitoring.pdf:pdf},
journal = {Electronic Communications of the EASST},
keywords = {bibtex,goal monitoring,message-based temporal logic,ocl,x-commented},
mendeley-tags = {bibtex,x-commented},
publisher = {Springer},
title = {{Extended OCL for Goal Monitoring}},
url = {http://journal.ub.tu-berlin.de/eceasst/article/view/105},
volume = {9},
year = {2008}
}
@article{robinson:computer10,
abstract = {Most large software systems result from weaving together many independently developed systems. Like Shelley's Frankenstein, such systems risk inheriting undesirable properties. Requirements monitoring can sound the alert should these creations fail to meet their obligations.},
author = {Robinson, William N.},
doi = {10.1109/MC.2009.373},
file = {:Users/vitor/Mendeley/Robinson - 2010 - A Roadmap for Comprehensive Requirements Monitoring.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {may},
number = {5},
pages = {64--72},
publisher = {IEEE},
title = {{A Roadmap for Comprehensive Requirements Monitoring}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5339126},
volume = {43},
year = {2010}
}
@article{robinson:re06,
abstract = {Requirements compliant software is becoming a necessity. Fewer and fewer organizations will run their critical transactions on software that has no visible relationship to its requirements. Businesses wish to see their software being consistent with their policies. Moreover, partnership agreements are pressuring less mature organizations to improve their systems. Businesses that rely on web services, for example, are vulnerable to the problems of their web service providers. While electronic commerce has increased the speed of on-line transactions, the technology for monitoring requirements compliance—especially for transactions—has lagged behind. To address the requirements monitoring problem for enterprise information systems, we integrate techniques for requirements analysis and software execution monitoring. Our framework assists analysts in the development of requirements monitors for enterprise services. The deployed system raises alerts when services succeed or fail to satisfy their specified requirements, thereby making software requirements visible. The framework usage is demonstrated with an analysis of ebXML marketplace specifications. An analyst applies goal analysis to discover potential service obstacles, and then derives requirements monitors and a distributed monitoring system. Once deployed, the monitoring system provides alerts when obstacles occur. A summary of the framework implementation is presented, along with analysis of two monitor component implementations. We conclude that the approach implemented in the framework, called ReqMon, provides real-time feedback on requirements satisfaction, and thereby provides visibility into requirements compliance of enterprise information systems.},
annote = {10.1007/s00766-005-0016-3},
author = {Robinson, William N.},
doi = {10.1007/s00766-005-0016-3},
file = {:Users/vitor/Mendeley/Robinson - 2006 - A requirements monitoring framework for enterprise systems.pdf:pdf},
issn = {0947-3602},
journal = {Requirements Engineering},
keywords = {bibtex,case,commented,electronic commerce,requirements monitoring,summarized,web services},
mendeley-tags = {bibtex,commented,summarized},
number = {1},
pages = {17--41},
publisher = {Springer},
title = {{A requirements monitoring framework for enterprise systems}},
url = {http://www.springerlink.com/content/7h650756076h1516/},
volume = {11},
year = {2006}
}
@incollection{robinson-fickas:dreatyp09,
abstract = {Requirements engineers gain insights and make improvements on their requirements specifications, as they are applied in natural contexts. Software artifacts are particularly useful requirements instantiations because feedback can be obtained directly from software. Software talks to its designers about its requirements. We illustrate requirements feedback with a case study in assistive technology (AT). A specialized emailing system was designed for cognitively impaired patients in an effort to decrease their social isolation, which often occurs after a brain injury. The patients continue to expand their email system usage, which is remarkable for AT. We attribute this unusual success to the feedback obtained directly from the software, through monitoring user goal models. Such monitoring has allowed the developers to understand and evolve their software to meet the changing user needs. It illustrates how an operational artifact, like software, can drive design evolution.},
annote = {10.1007/978-3-540-92966-6{\_}12},
author = {Robinson, William N. and Fickas, Stephen},
booktitle = {Design Requirements Engineering: A Ten-Year Perspective},
doi = {10.1007/978-3-540-92966-6_12},
editor = {Lyytinen, Kalle and Loucopoulos, Pericles and Mylopoulos, John and Robinson, Bill and Aalst, Wil and Rosemann, Michael and Shaw, Michael J and Szyperski, Clemens},
file = {:Users/vitor/Mendeley/Robinson, Fickas - 2009 - Designs Can Talk A Case of Feedback for Design Evolution in Assistive Technology.pdf:pdf},
isbn = {978-3-540-92966-6},
keywords = {bibtex,design science,evolution,not-commented,requirements monitoring},
mendeley-tags = {bibtex,not-commented},
pages = {215--237},
publisher = {Springer},
series = {Lecture Notes in Business Information Processing},
title = {{Designs Can Talk: A Case of Feedback for Design Evolution in Assistive Technology}},
url = {http://www.springerlink.com/content/vl220x114j238346/},
volume = {14},
year = {2009}
}
@article{robinson-purao:tsc11,
abstract = {Business processes are increasingly distributed and open, making them prone to failure. Monitoring is, therefore, an important concern not only for the processes themselves but also for the services that comprise these processes. We present a framework for multilevel monitoring of these service systems. It formalizes interaction protocols, policies, and commitments that account for standard and extended effects following the language-action perspective, and allows specification of goals and monitors at varied abstraction levels. We demonstrate how the framework can be implemented and evaluate it with multiple scenarios that include specifying and monitoring open-service policy commitments.},
author = {Robinson, William N. and Purao, Sandeep},
doi = {10.1109/TSC.2010.41},
file = {:Users/vitor/Mendeley/Robinson, Purao - 2011 - Monitoring Service Systems from a Language-Action Perspective.pdf:pdf},
issn = {1939-1374},
journal = {IEEE Transactions on Services Computing},
keywords = {bibtex,commented,language action,monitoring,processes,services,speech acts},
mendeley-tags = {bibtex,commented},
month = {jan},
number = {1},
pages = {17--30},
publisher = {IEEE},
title = {{Monitoring Service Systems from a Language-Action Perspective}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5560636},
volume = {4},
year = {2011}
}
@inproceedings{rocha-et-al:www04,
abstract = {This paper presents a search architecture that combines classical search techniques with spread activation techniques applied to a semantic model of a given domain. Given an ontology, weights are assigned to links based on certain properties of the ontology, so that they measure the strength of the relation. Spread activation techniques are used to find related concepts in the ontology given an initial set of concepts and corresponding initial activation values. These initial values are obtained from the results of classical search applied to the data associated with the concepts in the ontology. Two test cases were implemented, with very positive results. It was also observed that the proposed hybrid spread activation, combining the symbolic and the sub-symbolic approaches, achieved better results when compared to each of the approaches alone.},
address = {New York, NY, USA},
author = {Rocha, Cristiano and Schwabe, Daniel and Aragao, Marcus Poggi},
booktitle = {Proc. of the 13th International Conference on World Wide Web},
doi = {10.1145/988672.988723},
file = {:Users/vitor/Mendeley/Rocha, Schwabe, Aragao - 2004 - A hybrid approach for searching in the semantic web.pdf:pdf},
isbn = {158113844X},
keywords = {algorithms,bibtex,experimentation,network analysis,ontologies,semantic associations,semantic search,semantic web,spread activation algorithms,summarized},
mendeley-tags = {bibtex,summarized},
month = {may},
pages = {374--383},
publisher = {ACM},
title = {{A hybrid approach for searching in the semantic web}},
url = {http://portal.acm.org/citation.cfm?doid=988672.988723},
year = {2004}
}
@techreport{rocha-sandrini-spec06,
address = {Vit{\'{o}}ria, ES, Brazil},
author = {Rocha, Fabrizio Lima and Sandrini, Lucas Mancini},
institution = {P{\'{o}}s-gradua{\c{c}}{\~{a}}o em Java, Tecnologias e Desenvolvimento de Sistemas, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {advised,bibtex},
mendeley-tags = {advised,bibtex},
title = {{Distribev – Um Sistema De Comercializa{\c{c}}{\~{a}}o De Bebidas Atrav{\'{e}}s Da Internet}},
year = {2006}
}
@incollection{rodriguez-et-al:acmfa07,
abstract = {The early attainment of requirements in a software development process allows us to improve the quality of the product. Although many methods through which to elicit requirements exist, few of them are specifically designed for security requirements. This paper describes a method - M-BPSec - which permits the elicitation of security requirements which form part of a business process description carried out with a UML 2.0 Activity Diagram. M-BPSec is made up of stages, actors, tools and artifacts which, when applied in a coordinated manner, allow us to specify security requirements in business processes and to obtain class and use cases from this specification.},
address = {Berlin},
author = {Rodr{\'{i}}guez, Alfonso and Fern{\'{a}}ndez-Medina, Eduardo and Piattini, Mario},
booktitle = {Advances in Conceptual Modeling – Foundations and Applications},
doi = {10.1007/978-3-540-76292-8_13},
editor = {Hainaut, Jean-Luc and Rundensteiner, Elke and Kirchberg, Markus and Bertolotto, Michela and Brochhausen, Mathias and Chen, Yi-Ping and Cherfi, Samira and Doerr, Martin and Han, Hyoil and Hartmann, Sven and Parsons, Jeffrey and Poels, Geert and Rolland, Colette and Trujillo, Juan and Yu, Eric and Zim{\'{a}}nyie, Esteban},
file = {::;:Users/vitor/Mendeley/Rodr{\'{i}}guez, Fern{\'{a}}ndez-Medina, Piattini - 2007 - M-BPSec A Method for Security Requirement Elicitation from a UML 2.0 Business Process S.pdf:pdf},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
pages = {106--115},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{M-BPSec: A Method for Security Requirement Elicitation from a UML 2.0 Business Process Specification}},
url = {http://www.springerlink.com/content/7346700850064778/},
volume = {4802},
year = {2007}
}
@techreport{rohleder-et-al:report06,
abstract = {This requirements specification document describes the functions and requirements specified for this Ambulance Dispatch System (ADS). This dispatch system is needed to help ensure that the ambulance dispatching company meets all federal mandates about the speed at which an ambulance is dispatched. In order to make this possible, the system greatly decreases the amount of paperwork that must be filed. This system shall also help the company ensure that they are providing an adequate amount of ambulances for each of their service areas by enabling the management to track the status of each ambulance and a log of ambulance activity.},
author = {Rohleder, Chris and Smith, Jamie and Dix, Jeff},
file = {:Users/vitor/Mendeley/Rohleder, Smith, Dix - 2006 - Requirements Specification - Ambulance Dispatch System.pdf:pdf},
institution = {Software Engineering (CS 3354) Course Project, University of Texas at Dallas, USA (available at: http://www.utdallas.edu/{\~{}}cjr041000/)},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{Requirements Specification - Ambulance Dispatch System}},
url = {http://www.utdallas.edu/{~}cjr041000/Requirements Specification.pdf},
year = {2006}
}
@inproceedings{rohloff-et-al:otm07,
abstract = {This paper presents a comparison of performance of various triple- store technologies currently in either production release or beta test. Our comparison of triple-store technologies is biased toward a deployment scenariowhere the triple-store needs to load data and respond to queries over a very large knowledge base (on the order of hundreds of millions of triples.) The comparisons in this paper are based on the Lehigh University Benchmark (LUBM) software tools. We used the LUBM university ontology, datasets, and standard queries to per- form our comparisons.We find that over our test regimen, the triple-stores based on the DAML DB and BigOWLIM technologies exhibit the best performance among the triple-stores tested.},
address = {Vilamoura, Portugal},
author = {Rohloff, Kurt and Dean, Mike and Emmons, Ian and Ryder, Dorene and Sumner, John},
booktitle = {Proc. of the 2007 On the Move to Meaningful Internet Systems Workshops},
doi = {10.1007/978-3-540-76890-6_38},
file = {:Users/vitor/Mendeley/Rohloff et al. - 2007 - An Evaluation of Triple-Store Technologies for Large Data Stores.pdf:pdf},
isbn = {3540768890},
issn = {03029743},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {nov},
pages = {1105--1114},
publisher = {Springer},
title = {{An Evaluation of Triple-Store Technologies for Large Data Stores}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-76890-6{\_}38},
year = {2007}
}
@inproceedings{rosenmuller-et-al:gpce11,
abstract = {Software product lines (SPLs) and adaptive systems aim at variability to cope with changing requirements. Variability can be described in terms of features, which are central for development and configuration of SPLs. In traditional SPLs, features are bound statically before runtime. By contrast, adaptive systems support feature binding at runtime and are sometimes called dynamic SPLs (DSPLs). DSPLs are usually built from coarse-grained components, which reduces the number of possible application scenarios. To overcome this limitation, we closely integrate static binding of traditional SPLs and runtime adaptation of DSPLs. We achieve this integration by statically generating a tailor-made DSPL from a highly customizable SPL. The generated DSPL provides only the runtime variability required by a particular application scenario and the execution environment. The DSPL supports self-configuration based on coarse-grained modules. We provide a feature-based adaptation mechanism that reduces the effort of computing an optimal configuration at runtime. In a case study, we demonstrate the practicability of our approach and show that a seamless integration of static binding and runtime adaptation reduces the complexity of the adaptation process.},
address = {Portland, OR, USA},
author = {Rosenm{\"{u}}ller, Marko and Siegmund, Norbert and Pukall, Mario and Apel, Sven},
booktitle = {Proc. of the 10th ACM International Conference on Generative Programming and Component Engineering},
doi = {10.1145/2047862.2047866},
file = {:Users/vitor/Mendeley/Rosenm{\"{u}}ller et al. - 2011 - Tailoring Dynamic Software Product Lines.pdf:pdf},
isbn = {9781450306898},
keywords = {bibtex,dynamic binding,feature-oriented programming,not-commented,software product lines},
mendeley-tags = {bibtex,not-commented},
month = {oct},
pages = {3--12},
publisher = {ACM},
title = {{Tailoring Dynamic Software Product Lines}},
url = {http://dl.acm.org/citation.cfm?doid=2047862.2047866},
year = {2011}
}
@book{rosenthal:book05,
abstract = {David Rosenthal is one of the leading contributors to the philosophical study of consciousness. This volume gathers together his work on the subject from the past two decades, and represents the definitive presentation of his influential theory of consciousness as higher-order thought. Two of the essays appear here for the first time; there is also a substantial new introduction, drawing out the connections between the essays and highlighting their implications.},
author = {Rosenthal, David},
edition = {1st},
isbn = {978-0-19-823696-2},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Oxford University Press},
title = {{Consciousness and Mind}},
url = {http://www.oup.com/us/catalog/general/subject/Philosophy/Mind/?view=usa{\&}ci=9780198236962},
year = {2005}
}
@article{ross-schoman:tse77,
abstract = {Requirements definition encompasses all aspects of system development prior to actual system design. We see the lack of an adequate approach to requirements definition as the source of major difficulties in current systems worlk This paper examines the needs for requirements definition, and proposes meeting those objectives with three interrelated subjects: context analysis, functional specification, and design constraints. Requirements definition replaces the widely used, but never well-defined, term "requirements analysis."},
author = {Ross, Douglas T. and {Schoman Jr.}, Kenneth E.},
doi = {10.1109/TSE.1977.229899},
file = {:Users/vitor/Mendeley/Ross, Schoman Jr. - 1977 - Structured Analysis for Requirements Definition.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
keywords = {bibtex,functional specification,not-commented,requirements analysis,requirements definition,structured analysis},
mendeley-tags = {bibtex,not-commented},
number = {1},
pages = {6--15},
title = {{Structured Analysis for Requirements Definition}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1702398},
volume = {SE-3},
year = {1977}
}
@inproceedings{sabatucci-cossentino:seams15,
abstract = {Self-adaptation is a prominent property for developing complex distributed software systems. Notable approaches to deal with self-adaptation are the runtime goal model artifacts. Goals are generally invariant along the system lifecycle but contain points of variability for allowing the system to decide among many alternative behaviors. This work investigates how it is possible to provide goal models at run-time that do not contain tasks, i.e. The description of how to address goals, thus breaking the design-time tie up between Tasks and Goals, generally outcome of a means-end analysis. In this vision the system is up to decide how to combine its available Capabilities: the Proactive Means-End Reasoning. The impact of this research line is to implement a goal-oriented form of self-adaptation where goal models can be injected at runtime. The paper also introduces MUSA, a Middleware for User-driven Service self-Adaptation.},
address = {Florence, Italy},
author = {Sabatucci, Luca and Cossentino, Massimo},
booktitle = {Proc. of the 10th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1109/SEAMS.2015.9},
file = {:Users/vitor/Mendeley/Sabatucci, Cossentino - 2015 - From Means-End Analysis to Proactive Means-End Reasoning.pdf:pdf},
isbn = {978-0-7695-5567-6},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {2--12},
publisher = {IEEE},
title = {{From Means-End Analysis to Proactive Means-End Reasoning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7194652},
year = {2015}
}
@article{salehi-et-al:ijast13,
abstract = {A recommender system is a guide and assistance for choosing the required product or service for improving the electronic commerce systems. Most of the recommender systems use the history of customer purchase and a few are based on Semantic relatedness of purchased commodities. In this paper a semantic recommender system based on Ant Colony and Ontology dependencies is used for improvement of electronic commerce. This system comprises heuristic, stochastic, reinforcement learning in Ant Colony theory and semantic dependency in ontology characteristics. The presented system is able to recommend similar, complement and bundled products. This characteristic can overcome problems such as cold start, scalability and scarcity of information. In this paper applied tests results show the performance and efficiency of presented algorithms.},
author = {Salehi, Mojtaba and Fathi, Abdolhossein and Abdali-Mohammadi, Fardin},
editor = {Fang, Wai-Chi},
file = {:Users/vitor/Mendeley/Salehi, Fathi, Abdali-Mohammadi - 2013 - ANTSREC A Semantic Recommender System Based on Ant Colony Meta-Heuristic in Electronic Commerce.pdf:pdf},
journal = {International Journal of Advanced Science and Technology},
keywords = {ant colony,bibtex,electronic commerce,ontology,recommender system,semantic relatedness,summarized},
mendeley-tags = {bibtex,summarized},
pages = {119--130},
publisher = {SERSC},
title = {{ANTSREC: A Semantic Recommender System Based on Ant Colony Meta-Heuristic in Electronic Commerce}},
url = {http://www.sersc.org/journals/IJAST/vol56.php},
volume = {56},
year = {2013}
}
@article{salehie-tahvildari:taas09,
abstract = {Software systems dealing with distributed applications in changing environments normally require human supervision to continue operation in all conditions. These (re-)configuring, troubleshoot- ing, and in general maintenance tasks lead to costly and time-consuming procedures during the operating phase. These problems are primarily due to the open-loop structure often followed in software development. Therefore, there is a high demand for management complexity reduction, management automation, robustness, and achieving all of the desired quality requirements within a reasonable cost and time range during operation. Self-adaptive software is a response to these demands; it is a closed-loop system with a feedback loop aiming to adjust itself to changes during its operation. These changes may stem from the software system's self (internal causes, e.g., fail- ure) or context (external events, e.g., increasing requests from users). Such a system is required to monitor itself and its context, detect significant changes, decide how to react, and act to ex- ecute such decisions. These processes depend on adaptation properties (called self-* properties), domain characteristics (context information or models), and preferences of stakeholders. Noting these requirements, it is widely believed that new models and frameworks are needed to design self- adaptive software. This survey article presents a taxonomy, based on concerns of adaptation, that is, how, what, when and where, towards providing a unified view of this emerging area. Moreover, as adaptive systems are encountered in many disciplines, it is imperative to learn from the theories and models developed in these other areas. This survey article presents a landscape of research in self-adaptive software by highlighting relevant disciplines and some prominent research projects. This landscape helps to identify the underlying research gaps and elaborates on the corresponding challenges.},
author = {Salehie, Mazeiar and Tahvildari, Ladan},
doi = {10.1145/1516533.1516538},
file = {:Users/vitor/Mendeley/Salehie, Tahvildari - 2009 - Self-Adaptive Software Landscape and Research Challenges.pdf:pdf},
issn = {15564665},
journal = {ACM Transactions on Autonomous and Adaptive Systems},
keywords = {adaptation processes,bibtex,commented,design,management,performance,reliability,research challenges,self-adaptive software,self-properties,summarized,survey},
mendeley-tags = {bibtex,commented,summarized},
month = {may},
number = {2},
pages = {1--42},
publisher = {ACM},
title = {{Self-Adaptive Software: Landscape and Research Challenges}},
url = {http://portal.acm.org/citation.cfm?doid=1516533.1516538},
volume = {4},
year = {2009}
}
@article{salehie-tahvildari:spe12,
abstract = {Self-adaptive software aims at managing itself at run time to behave according to the specified requirements with minimum human intervention. Such a system is closed-loop in the sense that self (i.e. software entities) and context (i.e. environment) are continuously monitored in order to adapt properly to changes. Several researchers in this area subscribe to the view that representing adaptation goals explicitly and tracing them at run time are essential to engineering desired self-adaptive software. We believe that this is particularly helpful in decision-making and planning for adaptation changes. This article mainly focuses on the deciding process in self-adaptive software, and proposes a goal-based decision model called the Goal-Action- Attribute Model (GAAM). This model represents and relates adaptation goals, self/context attributes, and adaptation actions. GAAM can represent the action preferences using cardinal or ordinal utility functions. An action selection mechanism is also proposed, which uses GAAM to select the appropriate action(s) for satisfying the specified goals. The mechanism is based on a cooperative decision-making schema. The GAAM and action selection mechanism are evaluated using a simulated multi-tier enterprise application, and two sample ordinal and cardinal preference lists. The findings are promising considering the obtained results, and other impacts of the approach on engineering self-adaptive software.},
author = {Salehie, Mazeiar and Tahvildari, Ladan},
doi = {10.1002/spe.1066},
file = {:Users/vitor/Mendeley/Salehie, Tahvildari - 2012 - Towards a Goal-Driven Approach to Action Selection in Self-Adaptive Software.pdf:pdf},
journal = {Software: Practice and Experience},
keywords = {action selection,bibtex,commented,goal-driven model,self-adaptive software},
mendeley-tags = {bibtex,commented},
number = {2},
pages = {211--233},
publisher = {Wiley},
title = {{Towards a Goal-Driven Approach to Action Selection in Self-Adaptive Software}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/spe.1066/abstract},
volume = {42},
year = {2012}
}
@inproceedings{salifu-et-al:vamos07,
abstract = {This paper investigates the potential use of problem descriptions to represent and analyse variability in context-aware software products. By context-aware, we refer to recognition of changes in properties of external domains, which are recognised as affecting the behaviour of products. There are many reasons for changes in the operating environment, from fluctuating resources upon which the product relies, to different operating locations or the presence of objects. There is an increasing expectation for software intensive-devices to be context-aware which, in turn, adds further variability to problem description and analysis. However, we argue in this paper that the capture of contextual variability on current variability representations and analyses has yet to be explored. We illustrate the representation of this type of variability in a pilot study, and conclude with lessons learnt and an agenda for further work.},
address = {Limerick, Ireland},
author = {Salifu, Mohammed and Nuseibeh, Bashar and Rapanotti, Lucia and Tun, Than T.},
booktitle = {Proc. of the 1st International Workshop on Variability Modelling of Software-intensive Systems},
file = {:Users/vitor/Mendeley/Salifu et al. - 2007 - Using Problem Descriptions to Represent Variability for Context-Aware Applications.pdf:pdf},
keywords = {bibtex,commented,context-awareness,contextual variability,problem,product-families,solution variants,summarized,variants},
mendeley-tags = {bibtex,commented,summarized},
month = {jan},
pages = {(available online: http://oro.open.ac.uk/id/eprint},
publisher = {The Open University, UK},
title = {{Using Problem Descriptions to Represent Variability for Context-Aware Applications}},
url = {http://oro.open.ac.uk/id/eprint/15298},
year = {2007}
}
@inproceedings{santos-et-al:erbr13,
abstract = {[Context] Business process models are an important source of information for the development of information systems. Good business processes need to be up-to-date and automated to represent the organizational environment. Representing and configuring business processes variability for a specific organization allows the proper execution of processes. In addition, dynamic environment calls for exible configuration processes that can meet stakeholders' goals. [Question/Problem] Even though current approaches allow the representation of variability of business process models, the selection of business variants in a given context remains a challenging issue. [Main idea] In this proposal, we advocate the use of Non-Functional Requirements (NFR) and contextawareness information to drive the configuration of process models at run-time. In particular, we evaluate the use of NFRs to describe the stakeholders' preferences. [Contribution] We propose a model-driven business process configuration approach that is driven by NFRs and contextual information.},
address = {Rio de Janeiro, RJ, Brasil},
author = {Santos, Emanuel and Pimentel, Jo{\~{a}}o and Pereira, Tarc{\'{i}}sio and Oliveira, Karolyne and Castro, Jaelson F. B.},
booktitle = {Proc. of Requirements Engineering@Brazil 2013},
file = {:Users/vitor/Mendeley/Santos et al. - 2013 - Business process configuration with NFRs and context-awareness.pdf:pdf},
keywords = {bibtex,business process configuration,context-awareness,non-functional requirements,summarized},
mendeley-tags = {bibtex,summarized},
month = {jul},
pages = {1--6},
publisher = {CEUR},
title = {{Business process configuration with NFRs and context-awareness}},
url = {http://ceur-ws.org/Vol-1005/},
year = {2013}
}
@inproceedings{sawyer-et-al:re10,
abstract = {Requirements are sensitive to the context in which the system-to-be must operate. Where such context is well understood and is static or evolves slowly, existing RE techniques can be made to work well. Increasingly, however, development projects are being challenged to build systems to operate in contexts that are volatile over short periods in ways that are imperfectly understood. Such systems need to be able to adapt to new environmental contexts dynamically, but the contextual uncertainty that demands this self-adaptive ability makes it hard to formulate, validate and manage their requirements. Different contexts may demand different requirements trade-offs. Unanticipated contexts may even lead to entirely new requirements. To help counter this uncertainty, we argue that requirements for self-adaptive systems should be run-time entities that can be reasoned over in order to understand the extent to which they are being satisfied and to support adaptation decisions that can take advantage of the systems' self-adaptive machinery. We take our inspiration from the fact that explicit, abstract representations of software architectures used to be considered design-time-only entities but computational reflection showed that architectural concerns could be represented at run-time too, helping systems to dynamically reconfigure themselves according to changing context. We propose to use analogous mechanisms to achieve requirements reflection. In this paper we discuss the ideas that support requirements reflection as a means to articulate some of the outstanding research challenges.},
address = {Sidney, Australia},
author = {Sawyer, Pete and Bencomo, Nelly and Whittle, Jon and Letier, Emmanuel and Finkelstein, Anthony},
booktitle = {Proc. of the 18th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2010.21},
file = {:Users/vitor/Mendeley/Sawyer et al. - 2010 - Requirements-Aware Systems A research agenda for RE for self-adaptive systems.pdf:pdf},
isbn = {978-1-4244-8022-7},
keywords = {bibtex,commented,reflection,requirements,run-time,self-adaptive systems},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {95--103},
publisher = {IEEE},
title = {{Requirements-Aware Systems: A research agenda for RE for self-adaptive systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5636882},
year = {2010}
}
@misc{schaad:presentation12,
author = {Schaad, Andreas},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{TAM2: Automated Threat Analysis, Oral presentation during SE-1 session at the 27th Symposium On Applied Computing}},
year = {2012}
}
@article{scherp-et-al:ao11,
abstract = {One of the key factors that hinders integration of distributed, heterogeneous information systems is the lack of a formal basis for modeling the complex, structured knowledge that is to be exchanged. To alleviate this situation, we present an approach based on core ontologies. Core ontologies are characterized by a high degree of axiomatization and formal precision. This is achieved by basing on a foundational ontology. In addition, core ontologies should follow a pattern-oriented design approach. By this, they are modular and extensible. Core ontologies allow for reusing the structured knowledge they define as well as integrating existing domain knowledge. The structured knowledge of the core ontologies is clearly separated from the domain-specific knowledge. Such core ontologies allow for both formally conceptualize their particular fields and to be flexibly combined to cover the needs of concrete, complex application domains. Over the last years, we have developed three independent core ontologies for events and objects, multimedia annotations and personal information management. In this paper, we present the simultaneous use and integration of our core ontologies at the example of a complex, distributed socio-technical system of emergency response. We describe our design approach for core ontologies and discuss the lessons learned in designing them. Finally, we elaborate on the beauty aspects of our core ontologies.},
author = {Scherp, Ansgar and Saathoff, Carsten and Franz, Thomas and Staab, Steffen},
doi = {10.3233/AO-2011-0096},
journal = {Applied Ontology},
keywords = {bibtex,core ontologies,ontology design approach,ontology design patterns,ontology interplay},
mendeley-tags = {bibtex},
number = {3},
pages = {177--221},
publisher = {IOS Press},
title = {{Designing core ontologies}},
url = {http://content.iospress.com/articles/applied-ontology/ao096},
volume = {6},
year = {2011}
}
@book{icac11,
abstract = {On behalf of the steering committee and the program committee, it is our great pleasure to welcome you to the 8th ACM International Conference on Autonomic Computing -- ICAC 2011. We are pleased to hold this established conference at Karlsruhe, Germany. About ten years ago, the research area of autonomic computing has been initiated by Paul Horn, IBM's senior vice president of research. This conference series is demonstrating the impressive and lasting impact of the Autonomic Computing Initiative. We are delighted that one of the authors of the seminal paper on Autonomic Computing, Jeff Kephart, will reflect in his keynote on "Autonomic Computing: The First Decade". Independently, another research initiative evolved in Germany started by a joint position paper of the German Informatics Society (GI) and the Information Technology Society (ITG) on "Organic Computing", which is driven by similar insights as Autonomic Computing. The sixth and final year of the resulting priority research program of the German Research Foundation (DFG) has been a motivation for having ICAC 2011 in Germany. We are pleased that Christian M{\"{u}}ller-Schloer, one of the founders of Organic Computing will share his thoughts on the future of this research area in his keynote on "Organic Computing: Quo Vadis?" Both keynote talks will inspire thoughts on future directions of these fascinating research initiatives which have found widespread use in a broad range of application areas. We are looking forward to an attractive conference program: Out of 89 submissions, 20 papers were accepted as full papers and 7 as short papers. We also welcome the participants of the five workshops that complement the main conference with topics from economics (ACE), bio-inspired methods in distributed system (BADS), feedback control of computer networks (FeBID), an eenergy market challenge (IEEMC), and organic computing (OC).},
address = {Karlsruhe, Germany},
editor = {Schmeck, Hartmut and Rosenstiel, Wolfgang and Abdelzaher, Tarek and Hellerstein, Joseph L.},
isbn = {978-1-4503-0607-2},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {ACM},
title = {{Proceedings of the 8th ACM International Conference on Autonomic Computing}},
url = {http://dl.acm.org/citation.cfm?id=1998582},
year = {2011}
}
@inproceedings{schmerl-garlan:seke02,
abstract = {In an increasing number of domains software is now required to be self-adapting and self-healing. While in the past such abilities were incorporated into software on a per system basis, proliferation of such systems calls for more generalized mechanisms to manage dynamic adaptation. General mechanisms have the advantage that they can be reused in numerous systems, analyzed separately from the system being adapted, and easily changed to incorporate new adaptations. Moreover, they provide a natural home for encoding the expertise of system designers and implementers about adaptation strategies and policies. In this paper, we show how current software architecture tools can be extended to provide such generalized dynamic adaptation mechanisms.},
address = {Ischia, Italy},
author = {Schmerl, Bradley and Garlan, David},
booktitle = {Proc. of the 14th International Conference on Software Engineering and Knowledge Engineering},
doi = {10.1145/568760.568804},
file = {:Users/vitor/Mendeley/Schmerl, Garlan - 2002 - Exploiting Architectural Design Knowledge to Support Self-Repairing Systems.pdf:pdf},
isbn = {1581135564},
keywords = {bibtex,dynamic adaptation,not-commented,reflective systems,software architecture,software architecture tools},
mendeley-tags = {bibtex,not-commented},
month = {jun},
pages = {241--248},
publisher = {ACM},
title = {{Exploiting Architectural Design Knowledge to Support Self-Repairing Systems}},
url = {http://portal.acm.org/citation.cfm?doid=568760.568804},
year = {2002}
}
@article{schmidt:cscw02,
annote = {10.1023/A:1021272909573},
author = {Schmidt, Kjeld},
doi = {10.1023/A:1021272909573},
issn = {0925-9724},
journal = {Computer Supported Cooperative Work (CSCW)},
keywords = {bibtex},
mendeley-tags = {bibtex},
number = {3},
pages = {285--298},
publisher = {Springer},
title = {{The Problem with `Awareness': Introductory Remarks on `Awareness in CSCW'}},
url = {http://www.springerlink.com/content/r87177482060n508/},
volume = {11},
year = {2002}
}
@inproceedings{schmitz-et-al:re08,
abstract = {Since nowadays more and more control systems are realised within software on electronic control units, a conceptual integration of control systems engineering and software engineering must be aimed at. Within this work, we build on a recent proposal to use the software requirements formalism i* to enable a combined investigation of control systems' and software requirements. While i*'s modelling means have turned out to be sufficiently expressive, two characteristics of control systems still need to be addressed: firstly, how to incorporate domain knowledge especially about the system to be controlled in the requirements development process and secondly, how to specifically support small and medium-sized companies (SMEs) that are the main driver for innovations in this domain. Due to their innovativeness and flexibility, the SMEs usually follow a project-oriented customer-specific development approach. To be nonetheless cost-effective, especially during the offer development phase, we develop a mechanism and a tool to compare a current requirements model with requirements models of control systems from earlier projects. Altogether this reduces time and increases reliability in regard to the identification of reusable software artefacts.},
address = {Barcelona, Spain},
author = {Schmitz, Dominik and Nissen, Hans W. and Jarke, Matthias and Rose, Thomas and Drews, Peter and Hesseler, Frank J. and Reke, Michael},
booktitle = {Proc. of the 16th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2008.27},
file = {:Users/vitor/Mendeley/Schmitz et al. - 2008 - Requirements Engineering for Control Systems Development in Small and Medium-Sized Enterprises.pdf:pdf},
isbn = {978-0-7695-3309-4},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {229--234},
publisher = {IEEE},
title = {{Requirements Engineering for Control Systems Development in Small and Medium-Sized Enterprises}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4685674},
year = {2008}
}
@incollection{schmitz-et-al:mdafa09,
abstract = {When developing control systems software, mathematically based modelling tools such as Matlab/Simulink are used for design, simulation, and implementation. Thus, a continuous model-based approach does not need to map requirements to, for example, UML class diagrams but to this mathematical representation. In this paper, we build on previous work that has applied the requirements formalism i* to the development of control systems software and present a mapping from i* models to Matlab/Simulink models. During a first manual transformation step, design alternatives are resolved. The second, automated step generates a Matlab/Simulink skeleton model from the i* model. Finally, an interactive step allows incorporating existing hardware and platform components into the skeleton. As a running example, we consider the development of a parking assistant.},
annote = {10.1007/978-3-642-02674-4{\_}18},
author = {Schmitz, Dominik and Zhang, Ming and Rose, Thomas and Jarke, Matthias and Polzer, Andreas and Palczynski, Jacob and Kowalewski, Stefan and Reke, Michael},
booktitle = {Model Driven Architecture - Foundations and Applications},
doi = {10.1007/978-3-642-02674-4_18},
editor = {Paige, Richard and Hartman, Alan and Rensink, Arend},
file = {:Users/vitor/Mendeley//Schmitz et al. - 2009 - Mapping Requirement Models to Mathematical Models in Control System Development.pdf:pdf},
isbn = {978-3-642-02673-7},
keywords = {bibtex,not-commented,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
pages = {253--264},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Mapping Requirement Models to Mathematical Models in Control System Development}},
url = {http://www.springerlink.com/content/n700t71905361uj7/},
volume = {5562},
year = {2009}
}
@incollection{sebastiani-et-al:aise04,
abstract = {Goal models have been used in Computer Science in order to represent software requirements, business objectives and design qualities. In previous work we have presented a formal framework for reasoning with goal models, in a qualitative or quantitative way, and we have introduced an algorithm for forward propagating values through goal models. In this paper we focus on the qualitative framework and we propose a technique and an implemented tool for addressing two much more challenging problems: (1) find an initial assignment of labels to leaf goals which satisfies a desired final status of root goals by upward value propagation, while respecting some given constraints; and (2) find an minimum cost assignment of labels to leaf goals which satisfies root goals. The paper also presents preliminary experimental results on the performance of the tool using the goal graph generated by a case study involving the Public Transportation Service of Trentino (Italy).},
annote = {10.1007/978-3-540-25975-6{\_}4},
author = {Sebastiani, Roberto and Giorgini, Paolo and Mylopoulos, John},
booktitle = {Advanced Information Systems Engineering},
doi = {10.1007/978-3-540-25975-6_4},
editor = {Persson, Anne and Stirna, Janis},
file = {:Users/vitor/Mendeley/Sebastiani, Giorgini, Mylopoulos - 2004 - Simple and Minimum-Cost Satisfiability for Goal Models.pdf:pdf},
isbn = {978-3-540-22151-7},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
pages = {675--693},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Simple and Minimum-Cost Satisfiability for Goal Models}},
url = {http://www.springerlink.com/content/kllxamyqbw61npxq/},
volume = {3084},
year = {2004}
}
@inproceedings{semmak-et-al:modiseeus08,
abstract = {This work is done as part of the Tacos project1 whose aims is to define a component-based approach to specify trustworthy systems from the requirements phase to the specification phase, in the Cycab transportation domain. This paper mainly deals with the improvement of requirements elicitation in the context of Cycab domain. For that purpose, we propose to extend the Kaos goal oriented metamodel in order to enable explicit representation of variability at the early-phase of requirements engineering. This extension allows specifying a requirements family model which integrates both reusable assets and a variability model. The latter expresses the relevant domain facets along with different variants to realize them. The facets allow to structure and organize domain knowledge for reusability. The variability model then enables designers to explicitly state strategic decisions for requirements model development and then choose more accurately the relevant options of the system to-be.},
address = {Montpellier, France},
author = {Semmak, Farida and Gnaho, Christophe and Laleau, R{\'{e}}gine},
booktitle = {Proc. of the International Workshop on Model Driven Information Systems Engineering: Enterprise, User and System Models},
editor = {Ebersold, Sophie and Front, Agn{\`{e}}s and Lopist{\'{e}}guy, Philippe and Nurcan, Selmin},
file = {:Users/vitor/Mendeley/Semmak, Gnaho, Laleau - 2008 - Extended Kaos to Support Variability for Goal Oriented Requirements Reuse.pdf:pdf},
keywords = {bibtex,commented,family model,land transportation domain.,requirements engineering,summarized,variability},
mendeley-tags = {bibtex,commented,summarized},
month = {jun},
pages = {22--33},
publisher = {CEUR},
title = {{Extended Kaos to Support Variability for Goal Oriented Requirements Reuse}},
url = {http://ceur-ws.org/Vol-341/},
year = {2008}
}
@incollection{shen-et-al:tpsr11,
abstract = {Dynamic Software Product Line (DSPL) provides a new paradigm for developing self-adaptive systems with the principles of software product line engineering. DSPL emphasizes variability analysis and design at development time and variability binding and reconfiguration at runtime, thus requires some kinds of variability mechanisms to map high-level variations (usually represented by features) to low-level implementation and support runtime reconfiguration. Existing work on DSPL usually assumes that variation features can be directly mapped to coarse-grained elements like services, components or plug-ins, making the methods hard to be applied for traditional software systems. In this paper, we propose a feature-oriented method to support runtime variability reconfiguration in DSPLs. The method introduces the concept of role model, an intermediate level between feature variations and implementations to improve their traceability. On the other hand, the method involves a reference implementation framework based on dynamic aspect mechanisms to implement the runtime reconfiguration. We illustrate the process of applying the proposed method with a concrete case study, which helps to validate the effectiveness of our method.},
annote = {10.1007/978-3-642-21347-2{\_}5},
author = {Shen, Liwei and Peng, Xin and Liu, Jindu and Zhao, Wenyun},
booktitle = {Top Productivity through Software Reuse},
doi = {10.1007/978-3-642-21347-2_5},
editor = {Schmid, Klaus},
file = {:Users/vitor/Mendeley/Shen et al. - 2011 - Towards Feature-Oriented Variability Reconfiguration in Dynamic Software Product Lines.pdf:pdf},
isbn = {978-3-642-21346-5},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
pages = {52--68},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Towards Feature-Oriented Variability Reconfiguration in Dynamic Software Product Lines}},
url = {http://www.springerlink.com/content/mvvw25110314lgm6/},
volume = {6727},
year = {2011}
}
@inproceedings{sillitti-et-al:metrics05,
abstract = {This paper investigates commonalities and differences between agile and documentation-driven approaches in managing uncertainty in requirement gathering. The research method is a survey collected interviewing sixteen project managers of Italian software companies, 8 using agile methods, and 8 using documentation-driven methods. The results show that agile and document-driven companies consider in a different way the problem of changing requirements and the related uncertainty; thus, they manage differently requirements gathering and the relationship with the customer},
address = {Como, Italy},
author = {Sillitti, A. and Ceschi, M. and Russo, B. and Succi, G.},
booktitle = {Proc. of the 11th IEEE International Software Metrics Symposium},
doi = {10.1109/METRICS.2005.29},
file = {:Users/vitor/Mendeley/Sillitti et al. - 2005 - Managing Uncertainty in Requirements A Survey in Documentation-Driven and Agile Companies.pdf:pdf},
isbn = {0-7695-2371-4},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {17--26},
publisher = {IEEE},
title = {{Managing Uncertainty in Requirements: A Survey in Documentation-Driven and Agile Companies}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1509295},
year = {2005}
}
@inproceedings{silva-et-al:wer11,
abstract = {A goal oriented approach can be used as a way to discover variable and common requirements of a software product line (SPL), as well as to reduce costs associated with the configuration of a specific product in a product family. A goal oriented requirements engineering approach which has been used to develop complex system is the i* framework. It provides a manner to identify and specify the stakeholders' goals in relation to the intended system, as well as the characteristics of the system itself. This work proposes an extension of the i* modeling language, called i*-c (i* with cardinality), that allows inserting cardinality in some of its modeling elements. The G2SPL (Goals to Software Product Line) approach defines a process to identify and model common and variable features of a SPL using i* models with cardinality, as well as guides the configuration of a specific product in the SPL.},
address = {Rio de Janeiro, RJ, Brasil},
author = {Silva, Carla and Borba, Clarissa and Castro, Jaelson F. B.},
booktitle = {Anais do WER11 - Workshop em Engenharia de Requisitos},
file = {:Users/vitor/Mendeley/Silva, Borba, Castro - 2011 - A Goal Oriented Approach to Identify and Configure Feature Models for Software Product Lines.pdf:pdf},
keywords = {bibtex,commented,goal oriented approaches,i* framework,software product line},
mendeley-tags = {bibtex,commented},
pages = {395--406},
title = {{A Goal Oriented Approach to Identify and Configure Feature Models for Software Product Lines}},
url = {http://wer.inf.puc-rio.br/WERpapers/papers{\_}by{\_}conference.lp?conference=WER11},
year = {2011}
}
@inproceedings{simperl-et-al:coopis09,
abstract = {In this paper we give an account of the current state of practice in ontology engineering (OE) based on the findings of a 6 months empirical survey that analyzed 148 OE projects. The survey focused on process-related issues and looked into the impact of research achievements on real-world OE projects, the complexity of particular ontology development tasks, the level of tool support, and the usage scenarios for ontologies. The main contributions of this survey are twofold: 1) the size of the data set is larger than every other similar endeavor; 2) the findings of the survey confirm that OE is an established engineering discipline w.r.t the maturity and level of acceptance of its main components, methodologies, etc. whereas further research should target economic aspects of OE and the customization of existing technology to the specifics of vertical domains.},
address = {Rhodes, Greece},
author = {Simperl, Elena and Mochol, Malgorzata and B{\"{u}}rger, Tobias and Popov, Igor O.},
booktitle = {Proc. of the 17th International Conference on Cooperative Information Systems (CoopIS 09)},
doi = {10.1007/978-3-642-05151-7_17},
file = {:Users/vitor/Mendeley/Simperl et al. - 2009 - Achieving Maturity The State of Practice in Ontology Engineering in 2009.pdf:pdf},
keywords = {bibtex,commented,ontology engineering,state of the art,survey},
mendeley-tags = {bibtex,commented},
month = {oct},
pages = {983--991},
publisher = {Springer},
title = {{Achieving Maturity: The State of Practice in Ontology Engineering in 2009}},
url = {http://link.springer.com/10.1007/978-3-642-05151-7{\_}17},
year = {2009}
}
@misc{sindre-opdahl:report07,
abstract = {The project will develop and evaluate methodology and tool support for security requirements engineering, integrated with mainstream software development methods. The main features of the contribution will be as follows: * The methodology shall be lightweight, meant to be used primarily by mainstream software developers rather than by security experts * The methodology shall be integrated with popular methodologies for software development in general, so that security requirements can be considered in the normal run of development activities rather than as a separate activity on the side * Tools delivered in the project will not be developed from scratch but rather as add-ons to existing modelling and requirements management tools. This makes it more realistic to achieve industry-strength functionality and usability within a limited budget, and also ensures that tools will be applicable in a larger development context * Thorough evaluations (e.g., experiments, case studies) shall ensure that the methodology provides empirically founded advice on when and how to apply various techniques and tools. The project is planned for 3 years from August 2008 and includes one PhD fellowship and one postdoc position for 3 years each. The project leader is Professor Guttorm Sindre at the Norwegian University of Science and Technology (NTNU), and the other senior participant is Professor Andreas L. Opdahl at the University of Bergen (UiB), co-authors of some much cited publications on techniques for eliciting security requirements.},
author = {Sindre, Guttorm and Opdahl, Andreas L},
file = {::;:Users/vitor/Mendeley/Sindre, Opdahl - 2007 - ReqSec - Requirements for Secure Information Systems, Project Proposal for FRITEK.pdf:pdf},
institution = {Norwegian University of Science and Technology (available online: http://www.idi.ntnu.no/{\~{}}guttors/reqsec/plan.pdf)},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
title = {{ReqSec - Requirements for Secure Information Systems, Project Proposal for FRITEK}},
url = {http://www.idi.ntnu.no/{~}guttors/reqsec/plan.pdf},
year = {2007}
}
@phdthesis{singh:mastersthesis07,
abstract = {To assess the scalability of using AspectJ, we refactored concerns that crosscut over half of the plug-ins that comprise the Eclipse IDE. Eclipse is a suitable candidate for furthering other studies on AspectJ's scalability because the system has an additional modularization mechanism typical of large systems that introduces new complexities for defining advice and aspects. We evaluated quantitative and qualitative properties of our AO refactored version of Eclipse and compared them to their equivalents in the original, OO version of Eclipse. Quantitatively, we evaluated execution time and memory usage. Qualitatively, we evaluated changes in scattering, coupling, and abstractions. Our assessment of the scalability of AspectJ shows that using the language in Eclipse resulted in changes in performance and improvements in code similar to those seen in previous studies on the scalability of AspectJ. This leads us to conclude that AspectJ scales up to large systems. We also conclude that it may be necessary for the system to be aware of aspects in order to deal with defining advice that cross system boundaries.},
author = {Singh, Arjun},
file = {:Users/vitor/Mendeley/Singh - 2007 - The Scalability of AspectJ.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
number = {April},
school = {University of British Columbia, Canada},
title = {{The Scalability of AspectJ}},
type = {Masters Thesis},
year = {2007}
}
@incollection{sousa-et-al:sdtj09,
abstract = {This paper presents a framework for engineering resource-adaptive software targeted at small mobile devices. Rather than building a solution from scratch, we extend and integrate existing work on software infrastructures for ubiquitous computing, and on resource-adaptive applications. This paper addresses two research questions: first, is it feasibility to coordinate resource allocation and adaptation policies among several applications in a way that is both effective and efficient. And second, can end-users understand and control such adaptive behaviors dynamically, depending on user-defined goals for each activity. The evaluation covered both the systems and the usability perspectives, the latter by means of a user study. The contributions of this work are: first, a set of design guidelines, including APIs for integrating new applications; second, a concrete infrastructure that implements the guidelines. And third, a way to model quality of service tradeoffs based on utility theory, which our research indicates end-users with diverse backgrounds are able to leverage for guiding the adaptive behaviors towards activity-specific quality goals.},
annote = {10.1007/978-3-642-05201-9{\_}5},
author = {Sousa, Jo{\~{a}}o P. and Balan, Rajesh K. and Poladian, Vahe and Garlan, David and Satyanarayanan, Mahadev},
booktitle = {Software and Data Technologies},
doi = {10.1007/978-3-642-05201-9_5},
editor = {Cordeiro, Jos{\'{e}} and Shishkov, Boris and Ranchordas, AlpeshKumar and Helfert, Markus},
file = {:Users/vitor/Mendeley/Sousa et al. - 2009 - A Software Infrastructure for User–Guided Quality–of–Service Tradeoffs.pdf:pdf},
isbn = {978-3-642-05201-9},
keywords = {bibtex,commented,mobile computing,resource adaptation,self-adaptive systems,software architecture,user studies},
mendeley-tags = {bibtex,commented},
pages = {48--61},
publisher = {Springer},
series = {Communications in Computer and Information Science},
title = {{A Software Infrastructure for User–Guided Quality–of–Service Tradeoffs}},
url = {http://www.springerlink.com/content/gk8333w36g690743/},
volume = {47},
year = {2009}
}
@inproceedings{sousa-garlan:wicsa02,
abstract = {Ubiquitous computing poses a number of challenges for software architecture. One of the most important is the ability to design software systems that ac- commodate dynamically-changing resources. Resource variability arises natu- rally in a ubiquitous computing setting through user mobility (a user moves from one computing environment to another), and through the need to exploit time-varying resources in a given environment (such as wireless bandwidth). Traditional approaches to handling resource variability in applications attempt to address the problem by imposing uniformity on the environment. We argue that those approaches are inadequate, and describe an alternative architectural framework that is better matched to the needs of ubiquitous computing. A key feature of the architecture is that user tasks become first class entities. User proxies, or Auras, use models of user tasks to set up, monitor and adapt com- puting environments proactively. The architectural framework has been im- plemented and is currently being used as a central component of Project Aura, a campus-wide ubiquitous computing effort.},
address = {Montreal, QC, Canada},
author = {Sousa, Jo{\~{a}}o P. and Garlan, David},
booktitle = {Proc. of the 3rd Working IEEE/IFIP Conference on Software Architecture (WICSA '02)},
editor = {Bosch, Jan and Gentleman, W. Morven and Hofmeister, Christine and Kuusela, Juha},
file = {:Users/vitor/Mendeley/Sousa, Garlan - 2002 - Aura an Architectural Framework for User Mobility in Ubiquitous Computing Environments.pdf:pdf},
keywords = {architectural framework,architectural style,bibtex,commented,mobility,ubiquitous computing},
mendeley-tags = {bibtex,commented},
month = {aug},
pages = {29--43},
publisher = {Kluwer},
title = {{Aura: an Architectural Framework for User Mobility in Ubiquitous Computing Environments}},
url = {http://dl.acm.org/citation.cfm?id=693943},
year = {2002}
}
@phdthesis{souza:phdthesis12,
abstract = {Nowadays, there are more and more software systems operating in highly open, dynamic and unpredictable environments. Moreover, as technology advances, requirements for these systems become ever more ambitious. We have reached a point where system complexity and environmental uncertainty are major challenges for the Information Technology industry. A solution proposed to deal with this challenge is to make systems (self-)adaptive, meaning they would evaluate their own behavior and performance, in order to re-plan and reconfigure their operations when needed. In order to develop an adaptive system, one needs to account for some kind of feedback loop. A feedback loop constitutes an architectural prosthetic to a system proper, introducing monitoring and adaptation functionalities to the overall system. Even if implicit or hidden in the system's architecture, adaptive systems must have a feedback loop among their components in order to evaluate their behavior and act accordingly. In this thesis, we take a Requirements Engineering perspective to the design of adaptive software systems and, given that feedback loops constitute an (architectural) solution for adaptation, we ask the question: what is the requirements problem this solution is intended to solve? To answer this question, we define two new classes of requirements: Awareness Requirements prescribe the indicators of requirements convergence that the system must strive to achieve, whereas Evolution Requirements represent adaptation strategies in terms of changes in the requirements models themselves. Moreover, we propose that System Identification be conducted to elicit parameters and analyze how changes in these parameters affect the monitored indicators, representing such effect using differential relations. These new elements represent the requirements for adaptation, making feedback loops a first-class citizen in the requirements specification. Not only they assist requirements engineers in the task of elicitation and communication of adaptation requirements, but with the proper machine-readable representations, they can serve as input to a framework that implements the generic functionalities of a feedback loop, reasoning about requirements at runtime. We have developed one such framework, called Zanshin, and validated our proposals through experiments based on a well-known case study adopted from the literature.},
annote = {PhD Thesis},
author = {Souza, V{\'{i}}tor E. S.},
file = {:Users/vitor/Mendeley/Souza - 2012 - Requirements-based Software System Adaptation.pdf:pdf},
keywords = {adaptive systems,awareness,bibtex,evolution,export,feedback loops,qualia,requirements,system identification,zanshin},
mendeley-tags = {bibtex,export},
school = {University of Trento, Italy},
title = {{Requirements-based Software System Adaptation}},
url = {http://eprints-phd.biblio.unitn.it/809/},
year = {2012}
}
@techreport{souza:report12,
abstract = {In our PhD research, we have been working on a control-theoretic approach for the development of adaptive systems with a Requirements Engineering perspective. The approach consists of three phases – Awareness Requirements elicitation, System Identification and Evolution Requirements elicitation — which are conducted in parallel with vanilla requirements activities to design a system that is able to adapt at runtime to undesirable situations. To facilitate this adaptation, the system models are done in a way that can be exploited at runtime by an adaptation framework. In the context of this research, we have conducted an experiment in the modeling of an adaptive system based on the well-known London Ambulance Service Computer Aided Dispatch (LAS-CAD) case. This report presents the requirements elicited and modeled for an Adaptive Computer-aided Amblance Dispatch system (A-CAD) that has been designed using the aforementioned process.},
address = {Trento, Italy},
annote = {Technical Report},
author = {Souza, V{\'{i}}tor E. S.},
file = {:Users/vitor/Mendeley/Souza - 2012 - An Experiment on the Development of an Adaptive System based on the LAS-CAD.pdf:pdf},
institution = {University of Trento (available at: http://disi.unitn.it/{\~{}}vitorsouza/a-cad/)},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{An Experiment on the Development of an Adaptive System based on the LAS-CAD}},
url = {http://www.inf.ufes.br/{~}vitorsouza/a-cad/},
year = {2012}
}
@techreport{souza:report10b,
annote = {Technical Report},
author = {Souza, V{\'{i}}tor E. S.},
file = {:Users/vitor/Mendeley/Souza - 2010 - Conceptual Modeling 2010 Assignment Report.pdf:pdf},
institution = {University of Trento, Italy},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{Conceptual Modeling 2010 Assignment Report}},
year = {2010}
}
@techreport{souza:report03,
address = {Vit{\'{o}}ria, ES},
annote = {Technical Report},
author = {Souza, V{\'{i}}tor E. S.},
institution = {Caderno de Resumos - XIII Jornada de inicia{\c{c}}{\~{a}}o Cient{\'{i}}fica, Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {bibtex,export,portuguese},
mendeley-tags = {bibtex,export,portuguese},
pages = {72--72},
title = {{Uso de Ontologias no Desenvolvimento de Software}},
year = {2003}
}
@techreport{souza:gradproject04,
abstract = {Ontologias t{\^{e}}m sido bastante utilizadas na Engenharia de Software, por{\'{e}}m, sua constru{\c{c}}{\~{a}}o n{\~{a}}o {\'{e}} tarefa simples. Dentro do contexto do ambiente de desenvolvimento de software ODE foi criado ODEd, um editor de ontologias desenvolvido para apoiar a orienta{\c{c}}{\~{a}}o a dom{\'{i}}nio no ambiente. Este trabalho prop{\~{o}}e adequar ODEd ao meta-modelo da UML e adicionar algumas novas funcionalidades para melhor apoiar as fases de formaliza{\c{c}}{\~{a}}o e avalia{\c{c}}{\~{a}}o de ontologias, atrav{\'{e}}s da constru{\c{c}}{\~{a}}o de um Editor de Axiomas e da integra{\c{c}}{\~{a}}o de uma m{\'{a}}quina de infer{\^{e}}ncia.},
address = {Vit{\'{o}}ria, ES},
annote = {Undergraduate Monograph},
author = {Souza, V{\'{i}}tor E. S.},
file = {:Users/vitor/Mendeley/Souza - 2004 - Estendendo ODEd Axiomatiza{\c{c}}{\~{a}}o e Adequa{\c{c}}{\~{a}}o ao Meta-Modelo da UML.pdf:pdf},
institution = {Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {bibtex,export,portuguese},
mendeley-tags = {bibtex,export,portuguese},
title = {{Estendendo ODEd: Axiomatiza{\c{c}}{\~{a}}o e Adequa{\c{c}}{\~{a}}o ao Meta-Modelo da UML}},
year = {2004}
}
@techreport{souza:masterthesis07,
abstract = {As primeiras gera{\c{c}}{\~{o}}es de aplica{\c{c}}{\~{o}}es para a Web foram constru{\'{i}}das de maneira ad-hoc, sem uma metodologia ou processo de software para dar apoio {\`{a}} equipe de desenvolvimento. Para atender {\`{a}} necessidade de abordagens disciplinadas e sistem{\'{a}}ticas, uma nova disciplina foi criada: a Engenharia Web (Web Engineering ou WebE). Nessa nova {\'{a}}rea de pesquisa, muitos m{\'{e}}todos t{\^{e}}m sido propostos para an{\'{a}}lise, projeto e desenvolvimento de Sistemas de Informa{\c{c}}{\~{a}}o baseados na Web (Web-based Information Systems – WISs). Juntamente com essas pesquisas, tecnologias para codifica{\c{c}}{\~{a}}o de aplica{\c{c}}{\~{o}}es Web tamb{\'{e}}m se desenvolveram. A utiliza{\c{c}}{\~{a}}o de frameworks ou arquiteturas baseadas em containers para prover uma infraestrutura s{\'{o}}lida como base para as aplica{\c{c}}{\~{o}}es {\'{e}} estado-da-pr{\'{a}}tica. No entanto, n{\~{a}}o foi encontrado na literatura um m{\'{e}}todo de Engenharia Web que tire vantagens do uso desses frameworks durante a fase de projeto de sistema. Este trabalho apresenta um m{\'{e}}todo para o projeto de WISs baseados em frameworks chamado FrameWeb. O m{\'{e}}todo prop{\~{o}}e uma arquitetura b{\'{a}}sica para desenvolvimento de WISs, um conjunto de atividades e um perfil UML para quatro tipos de modelos de projeto que trazem conceitos utilizados por algumas categorias de frameworks. A id{\'{e}}ia {\'{e}} que o uso de FrameWeb favore{\c{c}}a um aumento da produtividade da equipe de desenvolvimento por utilizar uma linguagem de modelagem que permite aos projetistas produzir diagramas que representam conceitos dos frameworks e aos desenvolvedores ou ferramentas CASE diretamente traduzir esses diagramas para c{\'{o}}digo. Considerando os investimentos em pesquisas na {\'{a}}rea da Web Sem{\^{a}}ntica nos {\'{u}}ltimos anos e que a vis{\~{a}}o que {\'{e}} proposta para essa evolu{\c{c}}{\~{a}}o da Web n{\~{a}}o se tornar{\'{a}} uma realidade enquanto os autores de websites n{\~{a}}o adicionarem sem{\^{a}}ntica {\`{a}}s suas p{\'{a}}ginas, achamos importante incluir diretrizes sobre como desenvolver WISs com sem{\^{a}}ntica associada usando FrameWeb. Portanto, este trabalho tamb{\'{e}}m prop{\~{o}}e S-FrameWeb, que estende FrameWeb com o intuito de construir WISs Sem{\^{a}}nticos baseados em frameworks.},
address = {Vit{\'{o}}ria, ES},
annote = {Masters Dissertation},
author = {Souza, V{\'{i}}tor E. S.},
file = {:Users/vitor/Mendeley/Souza - 2007 - FrameWeb um M{\'{e}}todo baseado em Frameworks para o Projeto de Sistemas de Informa{\c{c}}{\~{a}}o Web.pdf:pdf},
institution = {Universidade Federal do Esp{\'{i}}rito Santo},
keywords = {FrameWeb,S-FrameWeb,bibtex,engenharia web,export,m{\'{e}}todo,portuguese,projeto,sistemas de informa{\c{c}}{\~{a}}o web,web sem{\^{a}}ntica},
mendeley-tags = {bibtex,export,portuguese},
title = {{FrameWeb: um M{\'{e}}todo baseado em Frameworks para o Projeto de Sistemas de Informa{\c{c}}{\~{a}}o Web}},
url = {http://portais.ufes.br/PRPPG/ext/mono.php?progpess=2032{\&}curso=9{\&}prog=30001013007P0},
year = {2007}
}
@inproceedings{souza:icsesrc12,
abstract = {Complexity is now one of the major challenges for the IT industry [1]. Systems might become too complex to be managed by humans and, thus, will have to be self-managed: Self-configure themselves for operation, self-protect from attacks, self-heal from errors and self-tune for optimal performance [2]. (Self-)Adaptive systems evaluate their own behavior and change it when the evaluation indicates that it is not accomplishing the software's purpose or when better functionality and performance are possible [3]. To that end, we need to monitor the behavior of the running system and compare it to an explicit formulation of requirements and domain assumptions [4]. Feedback loops (e.g., the MAPE loop [2]) constitute an architectural solution for this and, as proposed by past research [5], should be a first class citizen in the design of such systems. We advocate that adaptive systems should be designed this way from as early as Requirements Engineering and that reasoning over requirements is fundamental for run-time adaptation. We therefore propose an approach for the design of adaptive systems based on requirements and inspired in control theory [6]. Our proposal is goal-oriented and targets softwareintensive socio-technical systems [7], in an attempt to integrate control-loop approaches with decentralized agents inspired approaches [8]. Our final objective is a set of extensions to state-of-the-art goal-oriented modeling languages that allow practitioners to clearly specify the requirements of adaptive systems and a run-time framework that helps developers implement such requirements. In this 2-page abstract paper, we summarize this approach.},
address = {Zurich, Switzerland},
annote = {Short paper},
author = {Souza, V{\'{i}}tor E. S.},
booktitle = {Proc. of the 34th International Conference on Software Engineering (ACM Student Research Competition)},
doi = {10.1109/ICSE.2012.6227218},
file = {:Users/vitor/Mendeley/Souza - 2012 - A requirements-based approach for the design of adaptive systems.pdf:pdf},
isbn = {978-1-4673-1067-3},
keywords = {bibtex,export},
mendeley-tags = {bibtex,export},
month = {jun},
pages = {1635--1637},
publisher = {IEEE},
title = {{A requirements-based approach for the design of adaptive systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6227218},
year = {2012}
}
@techreport{souza:report10,
address = {Trento, Italy},
annote = {PhD Qualifying Paper},
author = {Souza, V{\'{i}}tor E. S.},
file = {:Users/vitor/Mendeley/Souza - 2010 - Awareness Requirements for Self-Adaptive Socio-technical Systems.pdf:pdf},
institution = {(Qualifying Paper), DISI, University of Trento},
keywords = {autonomic,awareness,bibtex,modeling,requirements engineering,self-adaptive,socio-techinical systems,software engineering},
mendeley-tags = {bibtex},
title = {{Awareness Requirements for Self-Adaptive Socio-technical Systems}},
year = {2010}
}
@inproceedings{souza-falbo:ideas05,
abstract = {Recently, we have seen an increasing interest in ontologies as artifacts to represent knowledge and as critical elements in knowledge management, requirements engineering and several other application areas. In Domain- Oriented Software Development Environments, ontologies are used as domain models that can be used to guide requirements engineering. Thus, in this kind of environment, tools supporting ontology development are necessary. In the context of ODE (Ontology-based software Development Environment), we developed ODEd, an ontology editor. The initial version of ODEd, however, offered limited support for defining axioms and for ontology evaluation. In order to overcome such limitations, we improved ODEd adding an axiom editor to it. In this paper we discuss how this axiom editor supports axiom definition and ontology evaluation using an inference engine.},
address = {Valpara{\'{i}}so, Chile},
annote = {Qualis 2012: B4},
author = {Souza, V{\'{i}}tor E. S. and Falbo, Ricardo A.},
booktitle = {Proc. of the 8th Iberoamerican Workshop in Requirement Engineering and Software Environments},
file = {:Users/vitor/Mendeley/Souza, Falbo - 2005 - Supporting Ontology Axiomatization and Evaluation in ODEd.pdf:pdf},
keywords = {bibtex,export},
mendeley-tags = {bibtex,export},
pages = {59--70},
title = {{Supporting Ontology Axiomatization and Evaluation in ODEd}},
year = {2005}
}
@inproceedings{souza-falbo:webmedia05,
abstract = {In the last few years, Web applications have evolved from static hypertext documents to complex information systems. This evolution leads to the necessity of methodologies specifically designed for development of Web-based systems, focusing on agility in the process. This paper presents an agile approach for the development of Web applications that applies the concept of agile modeling, adopts a standard software architecture and is heavily based on frameworks, speeding up system analysis, design and implementation.},
address = {Po{\c{c}}os de Caldas, MG, Brazil},
annote = {Qualis 2012: B3},
author = {Souza, V{\'{i}}tor E. S. and Falbo, Ricardo A.},
booktitle = {Proc. of the 11th Brazilian Symposium on Multimedia and the Web},
doi = {10.1145/1114223.1114237},
file = {:Users/vitor/Mendeley/Souza, Falbo - 2005 - An Agile Approach for Web Systems Engineering.pdf:pdf},
keywords = {bibtex,export},
mendeley-tags = {bibtex,export},
pages = {1--3},
publisher = {ACM},
title = {{An Agile Approach for Web Systems Engineering}},
url = {http://portal.acm.org/citation.cfm?doid=1114223.1114237},
year = {2005}
}
@inproceedings{souza-falbo:sbes03,
abstract = {Ontologias t{\^{e}}m sido bastante utilizadas na Engenharia de Software, por{\'{e}}m sua constru{\c{c}}{\~{a}}o n{\~{a}}o {\'{e}} tarefa simples. No contexto do ambiente de desenvolvimento de software ODE, foi desenvolvido ODEd, um editor de ontologias. Contudo, ODEd trabalha de forma limitada a defini{\c{c}}{\~{a}}o de axiomas. Esse artigo apresenta AxE, um editor de axiomas que complementa ODEd, permitindo a constru{\c{c}}{\~{a}}o de axiomas e a avalia{\c{c}}{\~{a}}o de ontologias atrav{\'{e}}s do uso de uma m{\'{a}}quina de infer{\^{e}}ncia integrada.},
address = {Manaus, Brazil},
annote = {Qualis 2012: B2},
author = {Souza, V{\'{i}}tor E. S. and Falbo, Ricardo A.},
booktitle = {Anais da X Sess{\~{a}}o de Ferramentas do Simp{\'{o}}sio Brasileiro de Engenharia de Software},
file = {:Users/vitor/Mendeley/Souza, Falbo - 2003 - Construindo Axiomas e Avaliando Ontologias em ODEd.pdf:pdf},
keywords = {bibtex,export,portuguese},
mendeley-tags = {bibtex,export,portuguese},
pages = {7--12},
title = {{Construindo Axiomas e Avaliando Ontologias em ODEd}},
year = {2003}
}
@inproceedings{souza-falbo:eatis07,
abstract = {Web application development has long evolved from CGI scripting in structured programming languages to a whole new discipline called Web Engineering. Today, large and complex distributed systems are being built for the web, mostly with the use of frameworks or a container-based architecture. This paper proposes a method for the design of Web applications based on the use of frameworks, including a modeling language that extends UML to build diagrams that specifically depict framework-related components.},
address = {Faro, Portugal},
annote = {Qualis 2012: B4},
author = {Souza, V{\'{i}}tor E. S. and Falbo, Ricardo A.},
booktitle = {Proc. of the 2007 Euro American Conference on Telematics and Information Systems},
doi = {10.1145/1352694.1352698},
file = {:Users/vitor/Mendeley/Souza, Falbo - 2007 - FrameWeb - A Framework-based Design Method for Web Engineering.pdf:pdf},
isbn = {9781595935984},
keywords = {bibtex,export},
mendeley-tags = {bibtex,export},
month = {may},
publisher = {ACM},
title = {{FrameWeb - A Framework-based Design Method for Web Engineering}},
url = {http://dl.acm.org/citation.cfm?id=1352698},
year = {2007}
}
@inproceedings{souza-et-al:emmsad07,
abstract = {The rapid evolution of the area of Web Engineering has motivated the proposal of several methods and frameworks for the development of Web Information Systems (WISs). In particular, it is becoming more and more common to use container­based architectures and frameworks when it comes to their development. Following this idea, we have proposed a method for designing framework­based WISs, called FrameWeb. and, in this paper, we present FrameWeb's UML profile for modeling framework components in design models.},
address = {Trondheim, Norway},
annote = {Qualis 2012: B4},
author = {Souza, V{\'{i}}tor E. S. and Falbo, Ricardo A. and Guizzardi, Giancarlo},
booktitle = {Proc. of the 12th International Workshop on Exploring Modeling Methods in Systems Analysis and Design},
editor = {Proper, Erik and Halpin, Terry and Krogstie, John},
file = {:Users/vitor/Mendeley/Souza, Falbo, Guizzardi - 2007 - A UML Profile for Modeling Framework-based Web Information Systems.pdf:pdf},
keywords = {bibtex,export,frameworks,modeling language,uml profile,web engineering,web information systems},
mendeley-tags = {bibtex,export},
month = {jun},
pages = {149--158},
publisher = {CEUR},
title = {{A UML Profile for Modeling Framework-based Web Information Systems}},
url = {http://ceur-ws.org/Vol-365/},
year = {2007}
}
@incollection{souza-et-al:iism09,
abstract = {In the Web Engineering area, many methods and frameworks to support Web Information Systems (WISs) development have already been proposed. Particularly, the use of frameworks and container-based architectures is state-of-the-practice. In this chapter, we present a method for designing framework- based WISs called FrameWeb, which defines a standard architecture for framework-based WISs and a modeling language that extends UML to build diagrams that specifically depict framework-related components. Considering that the Semantic Web has been gaining momentum in the last few years, we also propose an extension to FrameWeb, called S-FrameWeb, that aims to support the development of Semantic WISs.},
annote = {Book Chapter},
author = {Souza, V{\'{i}}tor E. S. and Falbo, Ricardo A. and Guizzardi, Giancarlo},
booktitle = {Innovations in Information Systems Modeling: Methods and Best Practices},
chapter = {11},
doi = {10.4018/978-1-60566-278-7},
edition = {1},
editor = {Halpin, Terry and Proper, Eric and Krogstie, John},
isbn = {9781605662787},
keywords = {bibtex,export},
mendeley-tags = {bibtex,export},
pages = {203--237},
publisher = {IGI Global},
title = {{Designing Web Information Systems for a Framework-based Construction}},
url = {http://www.igi-global.com/reference/details.asp?id=33232},
year = {2009}
}
@inproceedings{souza-guizzardi:erbr13,
abstract = {Pesquisadores t{\^{e}}m cada vez mais direcionado sua aten{\c{c}}{\~{a}}o ao uso de modelos em tempo de execu{\c{c}}{\~{a}}o (runtime), provendo ferramentas e frameworks que auxiliam os desenvolvedores na tarefa de construir software alinhado a seus requisitos/arquitetura. Em particular, algumas pesquisas em Engenharia de Requisitos concentraram-se em desenvolver sistemas de software que possuam a capacidade de ler seus pr{\'{o}}prios modelos de requisitos e tomar decis{\~{o}}es a partir de uma an{\'{a}}lise do mesmo. {\'{E}} uma tend{\^{e}}ncia comum, por exemplo, na {\'{a}}rea de sistemas adaptativos, para a qual contribu{\'{i}}mos recentemente. Neste artigo, propomos um novo projeto de pesquisa sobre o uso de modelos de requisitos em tempo de execu{\c{c}}{\~{a}}o, discutindo seus potenciais benef{\'{i}}cios e os desafios envolvidos.},
address = {Rio de Janeiro, RJ, Brasil},
annote = {Short paper},
author = {Souza, V{\'{i}}tor E. S. and Guizzardi, Renata S. S.},
booktitle = {Proc. of Requirements Engineering@Brazil 2013},
file = {:Users/vitor/Mendeley/Souza, Guizzardi - 2013 - Usando Modelos de Requisito em Tempo de Execu{\c{c}}{\~{a}}o Potencial e Desafios.pdf:pdf},
keywords = {bibtex,export,modelos,objetivos,requisitos,sistemas colaborativos de gest{\~{a}}o do conhecimento,tempo de execu{\c{c}}{\~{a}}o},
mendeley-tags = {bibtex,export},
month = {jun},
pages = {1--6},
publisher = {CEUR},
title = {{Usando Modelos de Requisito em Tempo de Execu{\c{c}}{\~{a}}o: Potencial e Desafios}},
url = {http://ceur-ws.org/Vol-1005/},
year = {2013}
}
@article{souza-et-al:csrd13,
abstract = {It is often the case that stakeholders want to strengthen/weaken or otherwise change their requirements for a system-to-be when certain conditions apply at runtime. For example, stakeholders may decide that if requirement R is violated more than N times in a week, it should be relaxed to a less demanding one R −. Such evolution requirements play an important role in the lifetime of a software system in that they define possible changes to requirements, along with the conditions under which these changes apply. In this paper we focus on this family of requirements, how to model them and how to operationalize them at runtime. In addition, we evaluate our proposal with a case study adopted from the literature.},
annote = {Qualis 2012: B4},
author = {Souza, V{\'{i}}tor E. S. and Lapouchnian, Alexei and Angelopoulos, Konstantinos and Mylopoulos, John},
doi = {10.1007/s00450-012-0232-2},
file = {:Users/vitor/Mendeley/Souza et al. - 2013 - Requirements-driven software evolution.pdf:pdf},
issn = {1865-2034},
journal = {Computer Science - Research and Development},
keywords = {adaptive systems,bibtex,evolution,export,modeling,requirements,requirements engineering},
mendeley-tags = {bibtex,export},
month = {nov},
number = {4},
pages = {311--329},
publisher = {Springer},
title = {{Requirements-driven software evolution}},
url = {http://link.springer.com/10.1007/s00450-012-0232-2},
volume = {28},
year = {2013}
}
@inproceedings{souza-et-al:er11,
abstract = {Control Theory and feedback control in particular have been steadily gaining momentum in software engineering for adaptive systems. Feedback controllers work by continuously measuring system outputs, comparing them with reference targets and adjusting control inputs if there is a mismatch. In Control Theory, quantifying the effects of control input on measured output is a process known as system identification . This process usually relies either on detailed and complex system models or on system observation. In this paper, we adopt a Requirements Engineering perspective and ideas from Qualitative Reasoning to propose a language and a systematic system identification method for adaptive software systems that can be applied at the requirements level, with the system not yet developed and its behavior not completely known.},
address = {Brussels, Belgium},
annote = {Qualis 2012: A2},
author = {Souza, V{\'{i}}tor E. S. and Lapouchnian, Alexei and Mylopoulos, John},
booktitle = {Proc. of the 30th International Conference on Conceptual Modeling},
doi = {10.1007/978-3-642-24606-7_26},
editor = {Jeusfeld, Manfred and Delcambre, Lois and Ling, Tok-Wang},
file = {:Users/vitor/Mendeley/Souza, Lapouchnian, Mylopoulos - 2011 - System Identification for Adaptive Software Systems a Requirements Engineering Perspective(2).pdf:pdf},
isbn = {978-3-642-24605-0},
keywords = {bibtex,export},
mendeley-tags = {bibtex,export},
month = {nov},
pages = {346--361},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{System Identification for Adaptive Software Systems: a Requirements Engineering Perspective}},
url = {http://www.springerlink.com/content/a67g08l5624l2741/},
volume = {6998},
year = {2011}
}
@inproceedings{souza-et-al:seams12,
abstract = {It is often the case that stakeholders want to strengthen/weaken or otherwise change their requirements for a system-to-be when certain conditions apply at runtime. For example, stakeholders may decide that if requirement R is violated more than N times in a week, it should be relaxed to a less demanding one R-. Such evolution requirements play an important role in the lifetime of a software system in that they define possible changes to requirements, along with the conditions under which these changes apply. In this paper we focus on this family of requirements, how to model them and how to operationalize them at runtime. In addition, we evaluate our proposal with a case study adopted from the literature.},
address = {Zurich, Switzerland},
annote = {Qualis 2012: B3},
author = {Souza, V{\'{i}}tor E. S. and Lapouchnian, Alexei and Mylopoulos, John},
booktitle = {Proc. of the 7th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1109/SEAMS.2012.6224402},
file = {:Users/vitor/Mendeley/Souza, Lapouchnian, Mylopoulos - 2012 - (Requirement) Evolution Requirements for Adaptive Systems.pdf:pdf},
keywords = {adaptive systems,bibtex,evolution,export,modeling,requirements,requirements engineering},
mendeley-tags = {bibtex,export},
month = {jun},
pages = {155--164},
publisher = {IEEE},
title = {{(Requirement) Evolution Requirements for Adaptive Systems}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6224402},
year = {2012}
}
@techreport{souza-et-al:report10,
abstract = {Recently, there has been a growing interest in self-adaptive systems. Roadmap papers in this area point to feedback loops as a promising way of operationalizing adaptivity in such systems. In this paper, we present a new type of re- quirement – called Awareness Requirement – that can refer to other requirements and their success/failures, constitut- ing requirements for such feedback loops. We propose a way to elicit and formalize such requirements and validate our proposal using a monitoring framework. We further discuss how feedback loops could be implemented to provide adap- tivity mechanisms to systems.},
address = {Trento, Italy},
annote = {Technical Report},
author = {Souza, V{\'{i}}tor E. S. and Lapouchnian, Alexei and Mylopoulos, John},
file = {:Users/vitor/Mendeley/Souza, Lapouchnian, Mylopoulos - 2010 - Awareness Requirements for Adaptive Systems.pdf:pdf},
institution = {DISI-10-049, University of Trento (available at http://eprints.biblio.unitn.it/archive/00001893/)},
keywords = {awareness,bibtex,feedback loops,modeling,monitoring,requirements engineering,self-adaptive systems},
mendeley-tags = {bibtex},
title = {{Awareness Requirements for Adaptive Systems}},
url = {http://eprints.biblio.unitn.it/archive/00001893/},
year = {2010}
}
@inproceedings{souza-et-al:coopis12,
abstract = {Coping with run-time uncertainty pose an ever-present threat to the fulfillment of requirements for most software systems (embedded, robotic, socio-technical, etc.). This is particularly true for large-scale, cooperative information systems. Adaptation mechanisms constitute a general solution to this problem, consisting of a feedback loop that monitors the environment and compensates for deviating system behavior. In our research, we apply a requirements engineering perspective to the problem of designing adaptive systems, focusing on developing a qualitative software-centric, feedback loop mechanism as the architecture that operationalizes adaptivity. In this paper, we propose a framework that provides qualitative adaptation to target systems based on information from their requirements models. The key characteristc of this framework is extensibility, allowing for it to cope with qualitative information about the impact of control (input) variables on indicators (output variables) in different levels of precision. Our proposal is evaluated with a variant of the London Ambulance System case study.},
address = {Rome, Italy},
annote = {Qualis 2012: B1},
author = {Souza, V{\'{i}}tor E. S. and Lapouchnian, Alexei and Mylopoulos, John},
booktitle = {Proc. of the 20th International Conference on Cooperative Information Systems},
doi = {10.1007/978-3-642-33606-5_21},
editor = {Meersman, Robert and Panetto, Herv{\'{e}} and Dillon, Tharam and Rinderle-Ma, Stefanie and Dadam, Peter and Zhou, Xiaofang and Pearson, Siani and Ferscha, Alois and Bergamaschi, Sonia and Cruz, Isabel F.},
file = {:Users/vitor/Mendeley/Souza, Lapouchnian, Mylopoulos - 2012 - Requirements-Driven Qualitative Adaptation.pdf:pdf},
isbn = {978-3-642-33605-8},
keywords = {adaptive systems,bibtex,export,feedback loops,goal models,qualitative reasoning,requirements},
mendeley-tags = {bibtex,export},
month = {sep},
pages = {342--361},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Requirements-Driven Qualitative Adaptation}},
url = {http://link.springer.com/chapter/10.1007{\%}2F978-3-642-33606-5{\_}21},
volume = {7565},
year = {2012}
}
@incollection{souza-et-al:sefsas13,
abstract = {The functional specification of any software system operationalizes stakeholder requirements. In this paper we focus on a class of requirements that lead to feedback loop operationalizations. These Awareness Requirements talk about the runtime success/failure of other requirements and domain assumptions. Our proposal includes a language for expressing awareness requirements, as well as techniques for elicitation and implementation based on the EEAT requirements monitoring framework.},
annote = {Book Chapter},
author = {Souza, V{\'{i}}tor E. S. and Lapouchnian, Alexei and Robinson, William N. and Mylopoulos, John},
booktitle = {Software Engineering for Self-Adaptive Systems II},
doi = {10.1007/978-3-642-35813-5_6},
editor = {Lemos, Rog{\'{e}}rio and Giese, Holger and M{\"{u}}ller, Hausi A. and Shaw, Mary},
file = {:Users/vitor/Mendeley/Souza et al. - 2013 - Awareness Requirements.pdf:pdf},
isbn = {978-3-642-35812-8},
keywords = {bibtex,export},
mendeley-tags = {bibtex,export},
pages = {133--161},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Awareness Requirements}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-35813-5{\_}6},
volume = {7475},
year = {2013}
}
@techreport{souza-et-al:report11,
abstract = {Recently, there has been a growing interest in self-adaptive systems. Roadmap papers in this area point to feedback loops as a promising way of operationalizing adaptivity in such systems. In this paper, we deﬁne a new type of requirement — called Awareness Requirement — that can refer to other requirements and their success/failures. We propose a way to elicit and formalize such requirements and oﬀer a requirements monitoring framework to support them.},
address = {Trento, Italy},
annote = {Technical Report},
author = {Souza, V{\'{i}}tor E. S. and Lapouchnian, Alexei and Robinson, William N. and Mylopoulos, John},
file = {:Users/vitor/Mendeley/Souza et al. - 2011 - Awareness Requirements for Adaptive Systems(2).pdf:pdf},
institution = {DISI-11-352, University of Trento},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{Awareness Requirements for Adaptive Systems}},
url = {http://disi.unitn.it/{~}vitorsouza/wp-content/uploads/souza-et-al-seams2011techrep.pdf},
year = {2011}
}
@inproceedings{souza-et-al:seams11,
abstract = {Recently, there has been a growing interest in self-adaptive systems. Roadmap papers in this area point to feedback loops as a promising way of operationalizing adaptivity in such systems. In this paper, we define a new type of requirement — called Awareness Requirement — that can refer to other requirements and their success/failures. We propose a way to elicit and formalize such requirements and offer a requirements monitoring framework to support them.},
address = {Honolulu, HI, USA},
annote = {Qualis 2012: B3},
author = {Souza, V{\'{i}}tor E. S. and Lapouchnian, Alexei and Robinson, William N. and Mylopoulos, John},
booktitle = {Proc. of the 6th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1145/1988008.1988018},
file = {:Users/vitor/Mendeley/Souza et al. - 2011 - Awareness Requirements for Adaptive Systems.pdf:pdf},
isbn = {9781450305754},
keywords = {adaptive systems,awareness,bibtex,export,modeling,monitoring,requirements engineering},
mendeley-tags = {bibtex,export},
month = {may},
pages = {60--69},
publisher = {ACM},
title = {{Awareness Requirements for Adaptive Systems}},
url = {http://portal.acm.org/citation.cfm?id=1988018},
year = {2011}
}
@inproceedings{souza-et-al:wism07,
abstract = {The Web Engineering area is evolving fast. Many methods and frameworks to support Web Information Systems (WISs) development have already been proposed. Particularly, the use of frameworks and container­based architectures is state­of­the­practice. Motivated by this scenario, we have proposed a method for designing framework­based WISs called FrameWeb. However, we should consider that the Semantic Web has been gaining momentum in the last few years. The idea is that the information on the Web should be available in machine­processable formats so that software agents could reason with it. This paper presents an extension to FrameWeb, called S­ FrameWeb, that aims to support the development of Semantic WISs.},
address = {Trondheim, Norway},
annote = {Qualis 2012: B4},
author = {Souza, V{\'{i}}tor E. S. and Louren{\c{c}}o, Thiago W. and Falbo, Ricardo A. and Guizzardi, Giancarlo},
booktitle = {Proc. of the 2007 International Workshop on Web Information Systems Modeling},
file = {:Users/vitor/Mendeley/Souza et al. - 2007 - S-FrameWeb a Framework-Based Design Method for Web Engineering with Semantic Web Support.pdf:pdf},
keywords = {bibtex,export,frameworks,web engineering,web information systems},
mendeley-tags = {bibtex,export},
month = {jun},
pages = {55--66},
title = {{S-FrameWeb: a Framework-Based Design Method for Web Engineering with Semantic Web Support}},
url = {http://people.few.eur.nl/frasincar/workshops/wism2007/wism2007proceedings.pdf},
year = {2007}
}
@inproceedings{souza-et-al:sac12,
abstract = {A data warehouse (DW) system stores data from multiple data sources in integrated form and provides capabilities for monitoring business operations to ensure compliance to strategic goals. As such, DWs constitute a fundamental building block for Business Intelligence (BI) operations. In this paper, we introduce the notion of Awareness Requirements (AwReqs) in the requirements analysis and elicitation phase for DWs. In this context, AwReqs provide analysts with the means for eliciting and modeling requirements over performance measures (indicators) to appraise the success or failure of strategic goals. To demonstrate the benefit of our approach, we present a typical business example throughout the paper and show how we can establish in the early stages of DW design the adequacy of the design for BI operations.},
address = {Riva del Garda, Italy},
annote = {Qualis 2012: A1},
author = {Souza, V{\'{i}}tor E. S. and Maz{\'{o}}n, Jose-Norberto and Garrig{\'{o}}s, Irene and Trujillo, Juan and Mylopoulos, John},
booktitle = {Proc. of the 2012 ACM Symposium on Applied Computing},
doi = {10.1145/2245276.2231944},
file = {:Users/vitor/Mendeley/Souza et al. - 2012 - Monitoring Strategic Goals in Data Warehouses with Awareness Requirements.pdf:pdf},
keywords = {awareness,bibtex,data warehouse,export,goals,key performance indicators,monitoring,requirements},
mendeley-tags = {bibtex,export},
month = {mar},
pages = {1075--1082},
publisher = {ACM},
title = {{Monitoring Strategic Goals in Data Warehouses with Awareness Requirements}},
url = {http://dl.acm.org/citation.cfm?doid=2245276.2231944},
year = {2012}
}
@inproceedings{souza-mylopoulos:er09,
abstract = {Monitoring and diagnosing (M{\&}D) software based on requirement models is a problem that has recently received a lot of attention in field of Requirement Engineering. In this context, Wang et al. [1] propose a M{\&}D framework that uses goal models to diagnose failures in software at different levels of granularity. In this paper we extend Wang's framework to monitor and diagnose malicious attacks. Our extensions include the addition of anti-goals to model attacker intentions, as well as context-based modeling of the domain within which our system operates. The extended framework has been implemented and evaluated through a series of experiments intended to test its scalability.},
address = {Gramado, RS, Brazil},
annote = {Qualis 2012: A2},
author = {Souza, V{\'{i}}tor E. S. and Mylopoulos, John},
booktitle = {Proc. of the 28th International Conference on Conceptual Modeling},
doi = {10.1007/978-3-642-04840-1_9},
editor = {Laender, Alberto and Castano, Silvana and Dayal, Umeshwar and Casati, Fabio and de Oliveira, Jos{\'{e}}},
file = {:Users/vitor/Mendeley//Souza, Mylopoulos - 2009 - Monitoring and Diagnosing Malicious Attacks with Autonomic Software.pdf:pdf},
isbn = {978-3-642-04839-5},
keywords = {bibtex,export},
mendeley-tags = {bibtex,export},
month = {nov},
pages = {84--98},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Monitoring and Diagnosing Malicious Attacks with Autonomic Software}},
url = {http://www.springerlink.com/content/t0346q5900210112/},
volume = {5829},
year = {2009}
}
@inproceedings{souza-mylopoulos:rrt11,
abstract = {Several proposals for the design of adaptive systems rely on some kind of feedback loop that monitors the system output and adapts in case of failure. Roadmap papers in the area advocate the need to make such feedback loops first class entities in adaptive systems design. We go further by adopting a Requirements Engineering perspective that is not only based on feedback loops but also applies other concepts from Control Theory to the design of adaptive systems. Our plans include a framework that reasons over requirements at runtime to provide adaptivity to a system proper. In this position paper, we argue for a control-theoretic view for adaptive systems and outline our long-term research agenda, briefly presenting work that we have already accomplished and discussing our plans for the future.},
address = {Trento, Italy},
annote = {Short paper},
author = {Souza, V{\'{i}}tor E. S. and Mylopoulos, John},
booktitle = {Proc. of the 2nd International Workshop on Requirements@Run.Time},
doi = {10.1109/ReRunTime.2011.6046242},
file = {:Users/vitor/Mendeley/Souza, Mylopoulos - 2011 - From Awareness Requirements to Adaptive Systems a Control-Theoretic Approach.pdf:pdf},
isbn = {978-1-4577-0942-5},
keywords = {adaptive systems,awareness,bibtex,control theory,export,feedback loop,requirements},
mendeley-tags = {bibtex,export},
month = {aug},
pages = {9--15},
publisher = {IEEE},
title = {{From Awareness Requirements to Adaptive Systems: a Control-Theoretic Approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6046242},
year = {2011}
}
@article{souza-mylopoulos:spe13,
abstract = {We have been witnessing growing interest in systems that can adapt their behavior to deal with deviations between their performance and their requirements at run-time. Such adaptive systems usually need to support some form of a feedback loop that monitors the system's output for problems and carries out adaptation actions when necessary. Being an important feature, adaptivity needs to be considered in early stages of development. Therefore, adopting a requirements engineering perspective, we have proposed an approach and a framework (both called Zanshin) for the engineering of adaptive systems based on a feedback loop architecture. As part of our framework's evaluation, we have applied the Zanshin approach to the design of an adaptive computer-aided ambulance dispatch system, whose requirements were based on a well-known case study from the literature. In this paper, we report on the application of Zanshin for the design of an adaptive computer-aided ambulance dispatch system, presenting elements of the design, as well as the results from simulations of run-time scenarios.},
annote = {ISSN online 1097-024X
Qualis 2012: A2
Qualis 2013: B1},
author = {Souza, V{\'{i}}tor E. S. and Mylopoulos, John},
doi = {10.1002/spe.2245},
editor = {Wellings, Andy},
file = {:Users/vitor/Mendeley/Souza, Mylopoulos - 2013 - Designing an adaptive computer-aided ambulance dispatch system with Zanshin an experience report.pdf:pdf},
issn = {00380644},
journal = {Software: Practice and Experience},
keywords = {adaptive systems,bibtex,case studies,export,feedback loops,requirements awareness,software evolution,software reconfiguration,software requirements,system identification},
mendeley-tags = {bibtex,export},
month = {may},
number = {5},
pages = {689--725},
publisher = {Wiley},
title = {{Designing an adaptive computer-aided ambulance dispatch system with Zanshin: an experience report}},
url = {http://doi.wiley.com/10.1002/spe.2245},
volume = {45},
year = {2013}
}
@inproceedings{souza-et-al:nldb08,
abstract = {In order to generate semantic annotations for a collection of documents, one needs an annotation schema consisting of a semantic model (a.k.a. ontology) along with lists of linguistic indicators (keywords and patterns) for each concept in the ontology. The focus of this paper is the automatic generation of the linguistic indicators for a given semantic model and a corpus of documents. Our approach needs a small number of user-deﬁned seeds and bootstraps itself by exploiting a novel clustering technique. The baseline for this work is the Cerno project [8] and the clustering algorithm LIMBO [2]. We also present results that compare the output of the clustering algorithm with linguistic indicators created manually for two case studies.},
address = {London, UK},
annote = {Qualis 2012: B1},
author = {Souza, V{\'{i}}tor E. S. and Zeni, Nicola and Kiyavitskaya, Nadzeya and Andritsos, Periklis and Mich, Luisa and Mylopoulos, John},
booktitle = {Proc. of the 13th International Conference on Natural Language and Information Systems},
chapter = {10},
doi = {10.1007/978-3-540-69858-6_10},
file = {:Users/vitor/Mendeley/Souza et al. - 2008 - Automating the Generation of Semantic Annotation Tools Using a Clustering Technique.pdf:pdf},
keywords = {bibtex,export},
mendeley-tags = {bibtex,export},
month = {jun},
pages = {91--96},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Automating the Generation of Semantic Annotation Tools Using a Clustering Technique}},
url = {http://www.springerlink.com/content/1p90245239308288/},
volume = {5039},
year = {2008}
}
@inproceedings{staikopoulos-et-al:mrt08,
abstract = {In complex service-oriented systems, a number of layers of abstraction may be considered, in particular the models of the organisations involved, how interactions are coordinated and the services which are used and made available, are all relevant to the construction of complex service-oriented systems. As each of these layers is built upon another there is a clear need to provide a maintenance mechanism, capable of maintaining consistency across the concepts used in each layer. In addition, over time designs may change because of the introduction of new requirements and the availability and capabilities of services may change due to implementation modifications or service failures, leading to the need to consider a two-way adaptation, namely between the system design and its run-time. The contribution of this paper is the description of our (novel) mutual adaptation mechanism and, using an industry scenario based on the proposed ALIVE framework, its illustration in use of the kinds of adaptation.},
address = {Toulouse, France},
author = {Staikopoulos, Athanasios and Saudrais, Sebastien and Clarke, Siobhan and Padget, Julian and Cliffe, Owen and {De Vos}, M},
booktitle = {Proc. of the 3rd Workshop on Models@run.time},
file = {:Users/vitor/Mendeley/Staikopoulos et al. - 2008 - Mutual Dynamic Adaptation of Models and Service Enactment in ALIVE.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {sep},
pages = {26--35},
title = {{Mutual Dynamic Adaptation of Models and Service Enactment in ALIVE}},
url = {http://opus.bath.ac.uk/11399/},
year = {2008}
}
@inproceedings{stevens-et-al:acmse07,
abstract = {Many strategies have been proposed to address the problems associated with managing increasingly complex computing systems. IBM's Autonomic Computing (AC) paradigm is one such strategy that seeks to alleviate system administrators from many of the burdensome tasks associated with manually managing highly complex systems. Researchers have been heavily investigating many areas of AC systems but there remains a lack of development in the area of testing these systems at runtime. Dynamic self-configuration, self-healing, self-optimizing, and self-protecting features of autonomic systems require that validation be an integral part of these types of systems. In this paper we propose a methodology for testing AC systems at runtime using copies of managed resources. We realize the architecture of a self-testing framework using a small AC system. Our system is based on the concept of an autonomic container, which is a data structure that possesses autonomic characteristics and added ability to self-test.},
address = {Winston-Salem, NC, USA},
author = {Stevens, Ronald and Parsons, Brittany and King, Tariq M.},
booktitle = {Proc. of the 45th Annual Southeast Regional Conference},
doi = {10.1145/1233341.1233343},
file = {:Users/vitor/Mendeley/Stevens, Parsons, King - 2007 - A Self-Testing Autonomic Container.pdf:pdf},
isbn = {9781595936295},
keywords = {autonomic computing,bibtex,commented,testing,validation},
mendeley-tags = {bibtex,commented},
month = {mar},
pages = {1--6},
publisher = {ACM},
title = {{A Self-Testing Autonomic Container}},
url = {http://portal.acm.org/citation.cfm?doid=1233341.1233343},
year = {2007}
}
@incollection{striewe-et-al:mrt08,
address = {Toulouse, France},
author = {Striewe, Michael and Balz, Moritz and Goedicke, Michael},
booktitle = {Proc. of the 3rd Workshop on Models@run.time},
file = {:Users/vitor/Mendeley/Striewe, Balz, Goedicke - 2008 - Embedding State Machine Models in Object-Oriented Source Code.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
pages = {6--15},
title = {{Embedding State Machine Models in Object-Oriented Source Code}},
url = {http://duepublico.uni-duisburg-essen.de/servlets/DozBibEntryServlet?mode=show{\&}id=19677{\&}lang=en},
year = {2008}
}
@incollection{suarezfigueroa-et-al:oenw12,
abstract = {In contrast to other approaches that provide methodological guidance for ontology engineering, the NeOn Methodology does not prescribe a rigid workflow, but instead it suggests a variety of pathways for developing ontologies. The nine scenarios proposed in the methodology cover commonly occurring situations, for example, when available ontologies need to be re-engineered, aligned, modularized, localized to support different languages and cultures, and integrated with ontology design patterns and non-ontological resources, such as folksonomies or thesauri. In addition, the NeOn Methodology framework provides (a) a glossary of processes and activities involved in the development of ontologies, (b) two ontology life cycle models, and (c) a set of methodological guidelines for different processes and activities, which are described (a) functionally, in terms of goals, inputs, outputs, and relevant constraints; (b) procedurally, by means of workflow specifications; and (c) empirically, through a set of illustrative examples.},
author = {Su{\'{a}}rez-Figueroa, Mari Carmen and G{\'{o}}mez-P{\'{e}}rez, Asunci{\'{o}}n and Fern{\'{a}}ndez-L{\'{o}}pez, Mariano},
booktitle = {Ontology Engineering in a Networked World},
doi = {10.1007/978-3-642-24794-1_2},
file = {:Users/vitor/Mendeley/Su{\'{a}}rez-Figueroa, G{\'{o}}mez-P{\'{e}}rez, Fern{\'{a}}ndez-L{\'{o}}pez - 2012 - The NeOn Methodology for Ontology Engineering.pdf:pdf},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {9--34},
publisher = {Springer},
title = {{The NeOn Methodology for Ontology Engineering}},
url = {http://link.springer.com/10.1007/978-3-642-24794-1{\_}2},
year = {2012}
}
@inproceedings{supakkul-chung:re12,
abstract = {Requirements engineers need to understand and model different aspects of organizations and systems under construction, and may need to use different modeling notations. However, most modeling tools support only one (or at most a few notations), hindering requirements engineers from using the most appropriate notations for the particular modeling task. The RE-Tools is an open-source toolkit implemented using a UML Profile for StarUML, an open-source UML modeling tool. The toolkit supports many leading requirements modeling notations, including the NFR Framework, the i* Framework, KAOS, Problem Frames, and UML. Each of these notations may be used for modeling independent corresponding diagrams or together with non-functional requirements (NFRs). The toolkit also supports the original qualitative reasoning of the NFR Framework and augments with a quantitative one.},
address = {Chicago, IL, USA},
author = {Supakkul, Sam and Chung, Lawrence},
booktitle = {2012 20th IEEE International Requirements Engineering Conference (RE)},
doi = {10.1109/RE.2012.6345831},
file = {:Users/vitor/Mendeley/Supakkul, Chung - 2012 - The RE-Tools A multi-notational requirements modeling toolkit.pdf:pdf},
isbn = {978-1-4673-2785-5},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {333--334},
publisher = {IEEE},
title = {{The RE-Tools: A multi-notational requirements modeling toolkit}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6345831},
year = {2012}
}
@article{susi-et-al:informatica05,
abstract = {Tropos is a software development methodology founded on the key concepts of agent-oriented software development. Speciﬁcally, Tropos emphasizes concepts for modelling and analysis during the early requirements phase. This phase precedes the prescriptive requirements speciﬁcation of the system-to-be. In this paper, we present the Tropos metamodel starting from the basic concepts of actor, goal, plan, resource and social dependency and then we illustrate its use by introducing an extension intended to introduce concepts for modelling security concerns. We also sketch the Tropos modelling environment and compare with the metamodels of other software development methodologies.},
author = {Susi, Angelo and Perini, Anna and Mylopoulos, John and Giorgini, Paolo},
file = {:Users/vitor/Mendeley/Susi et al. - 2005 - The Tropos Metamodel and its Use.pdf:pdf},
journal = {Informatica},
keywords = {agent oriented software engineering methodology,bibtex,commented,metamodel,summarized},
mendeley-tags = {bibtex,commented,summarized},
number = {4},
pages = {401--408},
publisher = {Slovenian Society Informatika},
title = {{The Tropos Metamodel and its Use}},
url = {http://www.informatica.si/vol29.htm{\#}No4},
volume = {29},
year = {2005}
}
@inproceedings{sykes-et-al:sac10,
abstract = {Among the many challenges of engineering dependable, self-managed, component-based systems is their need to make informed decisions about adaptive reconfigurations in response to changing requirements or a changing environment. Such decisions may be made on the basis of non-functional or QoS aspects of reconfiguration in addition to the purely functional properties needed to meet a goal. We present a practical approach for using non-functional information to guide a procedure for assembling, and subsequently modifying, configurations of software components, and compare the performance of two variants of the approach. In addition, we outline a scheme for monitoring non-functional properties in the running system such that more accurate information can be utilised in the next adaptation.},
address = {Sierre, Switzerland},
author = {Sykes, Daniel and Heaven, William and Magee, Jeff and Kramer, Jeff},
booktitle = {Proc. of the 2010 ACM Symposium on Applied Computing},
doi = {10.1145/1774088.1774180},
file = {:Users/vitor/Mendeley/Sykes et al. - 2010 - Exploiting Non-Functional Preferences in Architectural Adaptation for Self-Managed Systems.pdf:pdf},
isbn = {9781605586397},
keywords = {autonomous systems,bibtex,commented,dynamic reconfiguration,non-functional properties,self-adaptive,software architecture},
mendeley-tags = {bibtex,commented},
month = {mar},
pages = {431--438},
publisher = {ACM},
title = {{Exploiting Non-Functional Preferences in Architectural Adaptation for Self-Managed Systems}},
url = {http://portal.acm.org/citation.cfm?doid=1774088.1774180},
year = {2010}
}
@inproceedings{sykes-et-al:seams08,
abstract = {Autonomous or semi-autonomous systems are deployed in environments where contact with programmers or technicians is infrequent or undesirable. To operate reliably, such systems should be able to adapt to new circumstances on their own. This paper describes our combined approach for adaptable software architecture and task synthesis from high-level goals, which is based on a three-layer model. In the uppermost layer, reactive plans are generated from goals expressed in a temporal logic. The middle layer is responsible for plan execution and assembling a configuration of domain-specific software components, which reside in the lowest layer. Moreover, the middle layer is responsible for selecting alternative components when the current configuration is no longer viable for the circumstances that have arisen. The implementation demonstrates that the approach enables us to handle non-determinism in the environment and unexpected failures in software components.},
address = {Leipzig, Germany},
author = {Sykes, Daniel and Heaven, William and Magee, Jeff and Kramer, Jeff},
booktitle = {Proc. of the 2008 International Workshop on Software Engineering for Adaptive and Self-managing Systems},
doi = {10.1145/1370018.1370020},
file = {:Users/vitor/Mendeley/Sykes et al. - 2008 - From Goals To Components A Combined Approach To Self-Management.pdf:pdf},
isbn = {9781605580371},
keywords = {autonomous systems,bibtex,commented,dynamic reconfiguration,self-adaptive,self-healing,software architecture,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {may},
pages = {1--8},
publisher = {ACM},
title = {{From Goals To Components: A Combined Approach To Self-Management}},
url = {http://portal.acm.org/citation.cfm?doid=1370018.1370020},
year = {2008}
}
@inproceedings{sykes-et-al:savcbs07,
abstract = {Autonomous systems operate in an unpredictableworld, where communication with those people responsible for its software architecture may be infrequent or undesirable. If such a system is to continue reliable operation it must be able to derive and initiate adaptations to new circumstances on its own behalf. Much of the previous work on dynamic reconfigurations supposes that the programmer is able to express the possible adaptations before the system is deployed, or at least is able to add new adaptation strategies after deployment. We consider the challenges in providing an autonomous system with the capability to direct its own adaptation, and describe an initial implementation where change in the software architecture of an autonomous system is enacted as a result of executing a reactive plan.},
address = {Dubrovnik, Croatia},
author = {Sykes, Daniel and Heaven, William and Magee, Jeff and Kramer, Jeff},
booktitle = {Proc. of the 2007 Conference on Specification and Verification of Component-based Systems: 6th Joint Meeting of the European Conference on Software Engineering and the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
doi = {10.1145/1292316.1292318},
file = {:Users/vitor/Mendeley/Sykes et al. - 2007 - Plan-Directed Architectural Change For Autonomous Systems.pdf:pdf},
isbn = {9781595937216},
keywords = {autonomous systems,bibtex,commented,design,dynamic reconfiguration,management,reliability,self-adaptive,self-healing,software architecture},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {15--21},
publisher = {ACM},
title = {{Plan-Directed Architectural Change For Autonomous Systems}},
url = {http://portal.acm.org/citation.cfm?doid=1292316.1292318},
year = {2007}
}
@article{szvetits-zdun:ssm16,
abstract = {In the context of software development, models provide an abstract representation of a software system or a part of it. In the software development process, they are primarily used for documentation and communication purposes in analysis, design, and implementation activities. Model-Driven Engineering (MDE) further increases the importance of models, as in MDE models are not only used for documentation and communication, but as central artefacts of the software development process. Various recent research approaches take the idea of using models as central artefacts one step further by using models at runtime to cope with dynamic aspects of ever-changing software and its environment. In this article, we analyze the usage of models at runtime in the existing research literature using the Systematic Literature Review (SLR) research method. The main goals of our SLR are building a common classification and surveying the existing approaches in terms of objectives, techniques, architectures, and kinds of models used in these approaches. The contribution of this article is to provide an overview and classification of current research approaches using models at runtime and to identify research areas not covered by models at runtime so far.},
author = {Szvetits, Michael and Zdun, Uwe},
doi = {10.1007/s10270-013-0394-9},
file = {:Users/vitor/Mendeley/Szvetits, Zdun - 2016 - Systematic literature review of the objectives, techniques, kinds, and architectures of models at runtime.pdf:pdf},
issn = {1619-1366},
journal = {Software {\&} Systems Modeling},
keywords = {bibtex},
mendeley-tags = {bibtex},
number = {1},
pages = {31--69},
publisher = {Springer},
title = {{Systematic literature review of the objectives, techniques, kinds, and architectures of models at runtime}},
url = {http://link.springer.com/10.1007/s10270-013-0394-9},
volume = {15},
year = {2016}
}
@techreport{tallabaci-master12,
author = {Tallabaci, Genci},
file = {:Users/vitor/Mendeley/Tallabaci - 2012 - System Identification for the ATM System.pdf:pdf},
institution = {Masters Dissertation (Main advisor: John Mylopoulos), DISI, University of Trento, Italy},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{System Identification for the ATM System}},
year = {2012}
}
@inproceedings{tallabaci-souza:seams13,
abstract = {The Zanshin framework adopts a Requirements Engineering perspective to the design of adaptive systems and is centered around the idea of feedback loops. Evaluation experiments conducted so far have used simulations, limiting the strength of our conclusions on the viability of our proposal. In this paper, we report on the experience of applying Zanshin to an existing base system, a software that simulates an Automated Teller Machine (ATM), available online, drawing conclusions on the applicability of the framework's potential in real-life situations.},
address = {San Francisco, CA, USA},
annote = {Qualis 2012: B3},
author = {Tallabaci, Genci and Souza, V{\'{i}}tor E. S.},
booktitle = {Proc. of the 8th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1109/SEAMS.2013.6595496},
file = {:Users/vitor/Mendeley/Tallabaci, Souza - 2013 - Engineering Adaptation with Zanshin an Experience Report.pdf:pdf},
keywords = {ATM,adaptation,adaptive systems,bibtex,case study,experience report,experiment,export,framework,zanshin},
mendeley-tags = {bibtex,export},
month = {may},
pages = {93--102},
publisher = {IEEE},
title = {{Engineering Adaptation with Zanshin: an Experience Report}},
url = {http://dl.acm.org/citation.cfm?id=2487353},
year = {2013}
}
@article{tang-et-al:emmsad09,
abstract = {Today's large-scale computing systems are deployed in open, chang- ing and unpredictable environments. To operate reliably, such systems should be able to adapt to new circumstances on their own to get them running and keep them running. Self-adaptive software system has been proposed as a good solu- tion for this demand. However, very few techniques are available to date for sys- tematically building such kind of system. Aiming at this requirement, this paper presents a sound approach to derive a self-adaptive software architecture model from the requirements goal model in systematic way. At the same time, we illus- trate our approach by applying it to a simplified on-line shopping system.},
author = {Tang, Shan and Peng, Xin and Yu, Yijun and Zhao, Wenyun},
file = {:Users/vitor/Mendeley/Tang et al. - 2009 - Goal-Directed Modeling of Self-adaptive Software Architecture.pdf:pdf},
journal = {BPMDS 2009 and EMMSAD 2009, Lecture Notes in Business Information Processing},
keywords = {bibtex,commented,component,goal model,self-adaptive,software architecture},
mendeley-tags = {bibtex,commented},
pages = {313--325},
publisher = {Springer},
title = {{Goal-Directed Modeling of Self-adaptive Software Architecture}},
url = {http://www.emmsad.org/2009},
volume = {29},
year = {2009}
}
@techreport{taylor-tofts:report04,
abstract = {Self-managed systems are essentially closed loop control systems. When designing such systems we should ensure that they do not allow fundamentally bad properties, too slow convergence, oscillation, chaotic behaviour, stuck modes; just as for any control system. How can we perform these checks in the presence of arbitrary (Turing complete) control functions? We argue that the space of control functions and compositions should be restricted to those with known ‘good' properties and demonstrate such a space within cellular automata.},
author = {Taylor, Richard and Tofts, Chris},
booktitle = {Perspective},
file = {:Users/vitor/Mendeley/Taylor, Tofts - 2004 - Self Managed Systems - A Control Theory Perspective.pdf:pdf},
institution = {HPL-2004-49, HP Laboratories Bristol},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
title = {{Self Managed Systems - A Control Theory Perspective}},
url = {http://www.hpl.hp.com/techreports/2004/HPL-2004-49.pdf},
year = {2004}
}
@incollection{trajcevski-scheuermann:acml07,
abstract = {One distinct characteristics of the context-aware systems is their ability to react and adapt to the evolution of the environment, which is often a result of changes in the values of various (possibly correlated) attributes. Based on these changes, reactive systems typically take corrective actions, e.g., adjusting parameters in order to maintain the desired specifications of the system's state. Pro-active systems, on the other hand, may change the mode of interaction with the environment as well as the desired goals of the system. In this paper we describe our ( ECA ) 2 paradigm for reactive behavior with proactive impact and we present our ongoing work and vision for a system that is capable of context-aware adaptation, while ensuring the maintenance of a set of desired behavioral policies. Our main focus is on developing a formalism that provides tools for expressing normal, as well as defeasible and/or exceptional specification. However, at the same time, we insist on a sound semantics and the capability of answering hypothetical ”what-if” queries. Towards this end, we introduce the high-level language that can be used to describe the dynamics of the problem domain, specify triggers under the ( ECA ) 2 paradigm, and reason about the consequences of the possible evolutions.},
annote = {10.1007/978-3-540-77503-4{\_}4},
author = {Trajcevski, Goce and Scheuermann, Peter},
booktitle = {Active Conceptual Modeling of Learning},
doi = {10.1007/978-3-540-77503-4_4},
editor = {Chen, Peter and Wong, Leah},
file = {:Users/vitor/Mendeley/Trajcevski, Scheuermann - 2007 - Adaptive and Context-Aware Reconciliation of Reactive and Pro-active Behavior in Evolving Systems.pdf:pdf},
isbn = {978-3-540-77502-7},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {30--46},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Adaptive and Context-Aware Reconciliation of Reactive and Pro-active Behavior in Evolving Systems}},
url = {http://www.springerlink.com/content/e722257546x56q6g/},
volume = {4512},
year = {2007}
}
@inproceedings{trinkenreich-et-al:iceis15,
abstract = {Background: Maturity models for IT service such as CMMI-SVC and MR-MPS-SV are recent. Both include Measurement in their initial levels which requires identification of critical business process and definition of relevant metrics to support decision making but there is no clear direction or strict suggestion about what should be those critical business processes and metrics. Aims: We aim to identify adequate metrics to be used by organizations deploying IT service maturity models and the relationship between those metrics and processes of IT service maturity models or standards. Research questions are: (i) What metrics are being suggested for IT service quality improvement projects? (ii) How do they relate to IT service maturity models processes? Method: We have defined and executed a systematic mapping review protocol. We have selected papers based on defined criteria regarding their overall adequacy to the research questions. The protocol and its results were evaluated by a specialist on systematic mapping review and IT service maturity models. Results: Of 114 relevant studies, 13 had addressed the research questions. All of them had presented quality metrics, but none had presented tools or techniques for metrics identification. Conclusions: Systematic mapping result returned 133 metrics, 80 related to specific processes areas of service maturity models. Even being a broad result, not all models aspects were considered.},
address = {Barcelona, Spain},
author = {Trinkenreich, Bianca and Santos, Gleison and Barcellos, Monalessa Perini},
booktitle = {Proc. of the 17th International Conference on Enterprise Information Systems},
file = {:Users/vitor/Mendeley/Trinkenreich, Santos, Barcellos - 2015 - Metrics to Support IT Service Maturity Models A Systematic Mapping.pdf:pdf},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {apr},
title = {{Metrics to Support IT Service Maturity Models: A Systematic Mapping}},
url = {http://www.iceis.org/Program/2015/ICEIS{\_}paperList.htm},
year = {2015}
}
@inproceedings{uchitel-et-al:scesm03,
abstract = {Current approaches to scenario synthesis do not distinguish, in the resulting state machine models, proscribed behaviour from behaviour that has not yet been defined. In this paper we propose using partial labelled transition systems (PLTS) to capture what remains undefined of the system behaviour. In the context of scenario synthesis, we show that PLTSs can be used to provide feedback to stakeholders on the parts of the behaviour specification that need further elaboration. In this way we aim to support the iterative incremental elaboration of behaviour models.},
address = {Portland, OR, USA},
author = {Uchitel, Sebasti{\'{a}}n and Kramer, Jeff and Magee, Jeff},
booktitle = {Proc. of the 2nd International Workshop on Scenarios and State Machines: Models, Algorithms, and Tools},
file = {:Users/vitor/Mendeley/Uchitel, Kramer, Magee - 2003 - Modelling Undefined Behaviour in Scenario Synthesis.pdf:pdf},
keywords = {bibtex,not-commented,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
month = {may},
title = {{Modelling Undefined Behaviour in Scenario Synthesis}},
url = {http://pubs.doc.ic.ac.uk/undefined-behaviour/},
year = {2003}
}
@inproceedings{uno-et-al:icqs09,
abstract = {This paper proposes a systematic approach to derive feature models required in a software product line development. In our approach, we use goal graphs constructed by goal-oriented requirements analysis. We merge multiple goal graphs into a graph, and then regarding the leaves of the merged graph as the candidates of features, identify their commonality and variability based on the achievability of product goals. Through a case study of a portable music player domain, we obtained a feature model with high quality.},
address = {Jeju, South Korea},
author = {Uno, Kohei and Hayashi, Shinpei and Saeki, Motoshi},
booktitle = {Proc. of the 9th International Conference on Quality Software},
doi = {10.1109/QSIC.2009.61},
file = {:Users/vitor/Mendeley/Uno, Hayashi, Saeki - 2009 - Constructing Feature Models Using Goal-Oriented Analysis.pdf:pdf},
isbn = {978-1-4244-5912-4},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {aug},
pages = {412--417},
publisher = {IEEE},
title = {{Constructing Feature Models Using Goal-Oriented Analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5381388},
year = {2009}
}
@inproceedings{vanderraadt-et-al:re05,
abstract = {Emerging Web services technologies provide an open infrastructure for automated business interaction, thereby creating new opportunities for business actors to collaborate within a networked constellation of enterprises via the Internet. The basis for a viable network of Web services (the supporting information system of such a networked constellation of enterprises) is a value model that shows sound value propositions to all actors involved. Requirements engineering techniques can be developed to support: (1) exploring alternative business models, and (2) evaluating alternatives on their economic viability, leading into the design and implementation of technical systems. In this paper, we present a business-oriented approach supporting Web services idea exploration (BASSIE), which exploits the synergy between the agent- and goal-oriented i* framework and the value-based e3value framework. The approach iterates between exploration of structural alternatives and qualitative evaluation using i*, and quantitative modeling and evaluation of business value using e3value. The approach is illustrated with a real life case study in digital music distribution.},
address = {Paris, France},
author = {van der Raadt, Bas and Gordijn, Jaap and Yu, Eric S. K.},
booktitle = {Proc. of the 13th IEEE International Conference on Requirements Engineering},
doi = {10.1109/RE.2005.28},
file = {:Users/vitor/Mendeley/van der Raadt, Gordijn, Yu - 2005 - Exploring Web Services from a Business Value Perspective.pdf:pdf},
isbn = {0-7695-2425-7},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {aug},
pages = {53--62},
publisher = {IEEE},
title = {{Exploring Web Services from a Business Value Perspective}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1531027},
year = {2005}
}
@incollection{lamsweerde:cmfa09,
abstract = {This paper elaborates on some of the fundamental contributions made by John Mylopoulos in the area of Requirements Engineering. We specifically focus on the use of goal models and their soft goals for reasoning about alternative options arising in the requirements engineering process. A personal account of John's qualitative reasoning technique for comparing alternatives is provided first. A quantitative but lightweight technique for evaluating alternative options is then presented. This technique builds on mechanisms introduced by the qualitative scheme while overcoming some problems raised by it. A meeting scheduling system is used as a running example to illustrate the main ideas.},
author = {van Lamsweerde, Axel},
booktitle = {Conceptual Modeling: Foundations and Applications},
chapter = {20},
doi = {10.1007/978-3-642-02463-4_20},
editor = {Borgida, Alexander T. and Chaudhri, Vinay K. and Giorgini, Paolo and Yu, Eric S. K.},
file = {:Users/vitor/Mendeley/van Lamsweerde - 2009 - Reasoning About Alternative Requirements Options.pdf:pdf},
isbn = {978-3-642-02462-7},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {380--397},
publisher = {Springer},
title = {{Reasoning About Alternative Requirements Options}},
year = {2009}
}
@book{lamsweerde:book09,
abstract = {The book presents both the current state of the art in requirements engineering and a systematic method for engineering high-quality requirements, broken down into four parts. The first part introduces fundamental concepts and principles including the aim and scope of requirements engineering, the products and processes involved, requirements qualities to aim at and flaws to avoid, and the critical role of requirements engineering in system and software engineering. The second part of the book is devoted to system modeling in the specific context of engineering requirements. It presents a multi-view modeling framework that integrates complementary techniques for modeling the system-as-is and the system-to-be. The third part of the book reviews goal-based reasoning techniques to support the various steps of the KAOS method. The fourth part of the book goes beyond requirements engineering to discuss the mapping from goal-oriented requirements to software specifications and to software architecture. Online software will accompany the book and will add value to both classroom and self-study by enabling students to build models and specifications involved in the book's exercises and case studies, helping them to discover the latest RE technology solutions. Instructor resources such as slides, solutions, models and animations will be available from an accompanying website.},
author = {van Lamsweerde, Axel},
edition = {1},
isbn = {978-0470012703},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Wiley},
title = {{Requirements Engineering: From System Goals to UML Models to Software Specifications}},
url = {http://eu.wiley.com/WileyCDA/WileyTitle/productCd-EHEP000863.html},
year = {2009}
}
@inproceedings{vanlamsweerde:re01,
abstract = {Goals capture, at different levels of abstraction, the various objectives the system under consideration should achieve. Goal-oriented requirements engineering is concerned with the use of goals for eliciting, elaborating, structuring, specifying, analyzing, negotiating, documenting, and modifying requirements. This area has received increasing attention. The paper reviews various research efforts undertaken along this line of research. The arguments in favor of goal orientation are first briefly discussed. The paper then compares the main approaches to goal modeling, goal specification and goal-based reasoning in the many activities of the requirements engineering process. To make the discussion more concrete, a real case study is used to suggest what a goal-oriented requirements engineering method may look like. Experience, with such approaches and tool support are briefly discussed as well},
address = {Toronto, ON, Canada},
author = {van Lamsweerde, Axel},
booktitle = {Proc. of the 5th IEEE International Symposium on Requirements Engineering},
doi = {10.1109/ISRE.2001.948567},
file = {:Users/vitor/Mendeley/van Lamsweerde - 2001 - Goal-Oriented Requirements Engineering A Guided Tour.pdf:pdf},
isbn = {0-7695-1125-2},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {249--262},
publisher = {IEEE},
title = {{Goal-Oriented Requirements Engineering: A Guided Tour}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=948567},
year = {2001}
}
@inproceedings{vanLamsweerde-et-al:rhas03,
abstract = {Caring for security at requirements engineering time is a message that has finally received some attention recently. However, it is not yet very clear how to achieve this systematically through the various stages of the requirements engineering process. We briefly introduce some of the requirements such a process should meet for high assurance to be provided from the resulting requirements product. A constructive approach to security requirements elicitation, modeling and analysis is then outlined as an attempt to address such meta-requirements. The approach is based on a framework we developed before for generating and resolving obstacles to requirements achievement. Our framework integrates intentional obstacles (or “anti-goals”) set up by attackers to break security goals. Attack trees are derived systematically through anti-goal refinement until leaf nodes are reached that are software vulnerabilities observable by the attacker or anti-requirements implementable by this attacker. New security requirements are derived by resolution of the attack trees generated thereby.},
address = {Portland, OR, USA},
author = {van Lamsweerde, Axel and Brohez, Simon and {De Landtsheer}, Renaud and Janssens, David},
booktitle = {Proc. of the 2003 ICSE Workshop on Requirements for High Assurance Systems},
file = {::;:Users/vitor/Mendeley/van Lamsweerde et al. - 2003 - From System Goals to Intruder Anti-Goals Attack Generation and Resolution for Security Requirements Engin.pdf:pdf},
keywords = {anti-goals,attack,bibtex,commented,goals,requirements,security,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {sep},
pages = {49--56},
title = {{From System Goals to Intruder Anti-Goals: Attack Generation and Resolution for Security Requirements Engineering}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.3.5409},
year = {2003}
}
@inproceedings{vanlamsweerde-et-al:aaai91,
author = {van Lamsweerde, Axel and Dardenne, Anne and Delcourt, B. and Dubisy, F.},
booktitle = {Proc. of the AAAI Spring Symposium Series, Stanford University},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {mar},
pages = {59--62},
publisher = {AAAI},
title = {{The KAOS Project: Knowledge Acquisition in Automated Specification of Software}},
url = {http://www.info.ucl.ac.be/{~}avl/ReqEng.html},
year = {1991}
}
@inproceedings{vanlamsweerde-et-al:re95,
abstract = {Recently a number of requirements engineering languages and methods have flourished that not only address 'what' questions but also 'why', 'who' and 'when' questions. The objective of the paper is twofold: to assess the strengths and weaknesses of one of these methodologies on a nontrivial benchmark; and to illustrate and discuss a number of challenging issues that need to be addressed for such methodologies to become effective in supporting real, complex requirements engineering tasks. The problem considered here is that of a distributed meeting scheduler system; the methodology considered is the KAOS goal directed language and method. The issues raised from this case study include goal identification, the "deidelization" of unachievable goals, the handling of interfering goals, the impact of early formal reasoning, the merits of early reuse of abstract descriptions and categories, requirements traceability and the need to link requirements to retractable assumptions, and the potential benefits of hybrid acquisition strategies.},
address = {York, England},
author = {van Lamsweerde, Axel and Darimont, Robert and Massonet, Philippe},
booktitle = {Proc. of the 2nd IEEE International Symposium on Requirements Engineering},
doi = {10.1109/ISRE.1995.512561},
file = {:Users/vitor/Mendeley/van Lamsweerde, Darimont, Massonet - 1995 - Goal-Directed Elaboration of Requirements for a Meeting Scheduler Problems and Lessons Learn.pdf:pdf},
isbn = {0-8186-7017-7},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {mar},
pages = {194--203},
publisher = {IEEE},
title = {{Goal-Directed Elaboration of Requirements for a Meeting Scheduler: Problems and Lessons Learnt}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=512561},
year = {1995}
}
@inproceedings{vanlamsweerde-letier:risse02,
abstract = {Requirements engineering (RE) is concerned with the elicita- tion of the objectives to be achieved by the system envisioned, the opera- tionalization of such objectives into specifications of services and constraints, the assignment of responsibilities for the resulting require- ments to agents such as humans, devices and software, and the evolution of such requirements over time and across system families. Getting high- quality requirements is difficult and critical. Recent surveys have con- firmed the growing recognition of RE as an area of primary concern in software engineering research and practice. The paper reviews the important limitations of OO modeling and formal specification technology when applied to this early phase of the software lifecycle. It argues that goals are an essential abstraction for eliciting, elaborating, modeling, specifying, analyzing, verifying, negotiating and documenting robust and conflict-free requirements. A safety injection system for a nuclear power plant is used as a running example to illus- trate the key role of goals while engineering requirements for high assur- ance systems.},
address = {Venice, Italy},
author = {van Lamsweerde, Axel and Letier, Emmanuel},
booktitle = {Proc. of the 9th International Workshop on Radical Innovations of Software and Systems Engineering in the Future},
file = {:Users/vitor/Mendeley/van Lamsweerde, Letier - 2002 - From Object Orientation to Goal Orientation A Paradigm Shift for Requirements Engineering.pdf:pdf},
isbn = {3-540-21179-9},
keywords = {bibtex,commented,goal-oriented requirements engineering,high assurance systems,lightweight formal methods,safety,specification building process},
mendeley-tags = {bibtex,commented},
month = {oct},
pages = {4--8},
publisher = {Springer},
title = {{From Object Orientation to Goal Orientation: A Paradigm Shift for Requirements Engineering}},
url = {http://discovery.ucl.ac.uk/97080/},
year = {2002}
}
@article{vanlamsweerde-letier:tse00,
abstract = {Requirements engineering is concerned with the elicitation of high-level goals to be achieved by the envisioned system, the refinement of such goals and their operationalization into specifications of services and constraints and the assignment of responsibilities for the resulting requirements to agents such as humans, devices, and software. Requirements engineering processes often result in goals, requirements, and assumptions about agent behavior that are too ideal; some of them are likely not to be satisfied from time to time in the running system due to unexpected agent behavior. The lack of anticipation of exceptional behaviors results in unrealistic, unachievable, and/or incomplete requirements. As a consequence, the software developed from those requirements will not be robust enough and will inevitably result in poor performance or failures, sometimes with critical consequences on the environment. This paper presents formal techniques for reasoning about obstacles to the satisfaction of goals, requirements, and assumptions elaborated in the requirements engineering process. A first set of techniques allows obstacles to be generated systematically from goal formulations and domain properties. A second set of techniques allows resolutions to be generated once the obstacles have been identified thereby. Our techniques are based on a temporal logic formalization of goals and domain properties; they are integrated into an existing method for goal-oriented requirements elaboration with the aim of deriving more realistic, complete, and robust requirements specifications. A key principle in this paper is to handle exceptions at requirements engineering time and at the goal level, so that more freedom is left for resolving them in a satisfactory way. The various techniques proposed are illustrated and assessed in the context of a real safety-critical system.},
author = {van Lamsweerde, Axel and Letier, Emmanuel},
doi = {10.1109/32.879820},
file = {:Users/vitor/Mendeley/van Lamsweerde, Letier - 2000 - Handling Obstacles in Goal-Oriented Requirements Engineering.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {bibtex,defensive requirements specification,goal-oriented requirements engineering,high-level exception handling,lightweight formal methods,not-commented,obstacle-based requirements transformation,specification refinement},
mendeley-tags = {bibtex,not-commented},
number = {10},
pages = {978--1005},
publisher = {IEEE},
title = {{Handling Obstacles in Goal-Oriented Requirements Engineering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=879820},
volume = {26},
year = {2000}
}
@article{vanlamsweerde-willemet:tsc98,
abstract = {Scenarios are increasingly recognized as an effective means for eliciting, validating, and documenting software requirements. The paper focuses on the use of scenarios for requirements elicitation and explores the process of inferring formal specifications of goals and requirements from scenario descriptions. Scenarios are considered as typical examples of system usage; they are provided in terms of sequences of interaction steps between the intended software and its environment. Such scenarios are in general partial, procedural, and leave required properties about the intended system implicit. In the end such properties need to be stated in explicit, declarative terms for consistency/completeness analysis to be carried out. A formal method is proposed for supporting the process of inferring specifications of system goals and requirements inductively from interaction scenarios provided by stakeholders. The method is based on a learning algorithm that takes scenarios as examples/counterexamples and generates a set of goal specifications in temporal logic that covers all positive scenarios while excluding all negative ones. The output language in which goals and requirements are specified is the KAOS goal based specification language. The paper also discusses how the scenario based inference of goal specifications is integrated in the KAOS methodology for goal based requirements engineering. In particular, the benefits of inferring declarative specifications of goals from operational scenarios are demonstrated by examples of formal analysis at the goal level, including conflict analysis, obstacle analysis, the inference of higher level goals, and the derivation of alternative scenarios that better achieve the underlying goals},
author = {van Lamsweerde, Axel and Willemet, Laurent},
doi = {10.1109/32.738341},
file = {:Users/vitor/Mendeley/van Lamsweerde, Willemet - 1998 - Inferring Declarative Requirements Specifications from Operational Scenarios.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {bibtex,goal-oriented requirements engineering,inductive inference of specifications,lightweight formal methods,not-commented,scenario-based requirements elicitation,specification refinement and analysis},
mendeley-tags = {bibtex,not-commented},
number = {12},
pages = {1089--1114},
publisher = {IEEE},
title = {{Inferring Declarative Requirements Specifications from Operational Scenarios}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=738341},
volume = {24},
year = {1998}
}
@article{venkatraman-ramanujam:amr86,
abstract = {A two-dimensional classificatory scheme highlighting ten different approaches to the measurement of business performance in strategy research is developed. The first dimension concerns the use of financial versus broader operational criteria, while the second focuses on two alternate data sources (primary versus secondary). The scheme permits the classification of an exhaustive coverage of measurement approaches and is useful for discussing their relative merits and demerits. Implications for operationalizing business performance in future strategy research are discussed.},
annote = {No direct mention of KPIs.},
author = {Venkatraman, N. and Ramanujam, Vasudevan},
file = {:Users/vitor/Mendeley/Venkatraman, Ramanujam - 1986 - Measurement of Business Performance in Strategy Research A Comparison of Approaches.pdf:pdf},
issn = {03637425},
journal = {The Academy of Management Review},
keywords = {bibtex,not-commented,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
number = {4},
pages = {801--814},
publisher = {Academy of Management},
title = {{Measurement of Business Performance in Strategy Research: A Comparison of Approaches}},
url = {http://www.jstor.org/stable/258398},
volume = {11},
year = {1986}
}
@inproceedings{vierhauser-et-al:refsq14,
abstract = {[Context and motivation] Approaches for requirements monitoring check the compliance of systems with their requirements during operation. [Question/problem] Despite many advances, requirements monitoring remains challenging particularly for very-large-scale software systems (VLSS) with system-of-systems architectures. [Principal ideas/results] In this research preview we describe key characteristics of industrial VLSS and discuss implications for requirements monitoring. Furthermore, we report on our ongoing work of developing a requirements monitoring infrastructure addressing these characteristics. [Contribution] Our infrastructure supports runtime monitoring of requirements across systems; variability management of requirements-based monitors; and the integration of monitoring data from different sources in a VLSS.},
address = {Essen, Germany},
author = {Vierhauser, Michael and Rabiser, Rick and Gr{\"{u}}nbacher, Paul},
booktitle = {Proc. of the 20th International Working Conference on Requirements Engineering: Foundation for Software Quality},
doi = {10.1007/978-3-319-05843-6_7},
file = {:Users/vitor/Mendeley/Vierhauser, Rabiser, Gr{\"{u}}nbacher - 2014 - A Requirements Monitoring Infrastructure for Very-Large-Scale Software Systems.pdf:pdf},
keywords = {bibtex,commented,requirements monitoring,very-large-scale software systems},
mendeley-tags = {bibtex,commented},
month = {apr},
pages = {88--94},
publisher = {Springer},
title = {{A Requirements Monitoring Infrastructure for Very-Large-Scale Software Systems}},
url = {http://link.springer.com/chapter/10.1007/978-3-319-05843-6{\_}7},
volume = {8396 (LNCS},
year = {2014}
}
@inproceedings{villela-et-al:re08,
abstract = {Without distinguishing unstable from stable features and anticipating likely new features, building evolvability into software systems can be time-consuming and, above all, ineffective. This paper introduces a method based on a software evolution model whose goal is to help requirements engineers and product managers identify the unstable features of an embedded system and anticipate its potential adaptation needs in the future, with the aim of planning for changes beforehand. The core characteristic of this method is its support for systematic reasoning on requirements volatility and planning for changes. An application of the method in the domain of assisted living is described as a proof-of-concept, providing both a preliminary validation of the proposed solution and a useful example of its use.},
address = {Barcelona, Spain},
author = {Villela, Karina and Doerr, Joerg and Gross, Anne},
booktitle = {Proc. of the 16th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2008.57},
file = {:Users/vitor/Mendeley/Villela, Doerr, Gross - 2008 - Proactively Managing the Evolution of Embedded System Requirements.pdf:pdf},
isbn = {978-0-7695-3309-4},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {sep},
pages = {13--22},
publisher = {IEEE},
title = {{Proactively Managing the Evolution of Embedded System Requirements}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4685648},
year = {2008}
}
@misc{w3c-owl:website12,
author = {W3C},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{OWL 2 Web Ontology Language Document Overview (Second Edition), http://www.w3.org/TR/owl2-overview/ (last access: May 8th, 2015)}},
url = {http://www.w3.org/TR/owl2-overview/},
year = {2012}
}
@incollection{wang-et-al:er14,
abstract = {For many, software is just code, something intangible best defined in contrast with hardware, but it is not particularly illuminating. Microsoft Word turned 30 last year. During its lifetime it has been the subject of numerous changes, as its requirements, code and documentation have continuously evolved. Still a community of users recognizes it as “the same software product”, a persistent object undergoing several changes through a social process involving owners, developers, salespeople and users, and it is still producing recognizable effects that meet the same core requirements. It is this process that makes software something different than just a piece of code, and justifies its intrinsic nature as a social artifact. Building on Jackson's and Zave's seminal work on foundations of requirements engineering, we propose in this paper an ontology of software and related notions that accounts for such intuitions, and adopt it in software configuration management to provide a better understanding and control of software changes.},
address = {Cham},
author = {Wang, Xiaowei and Guarino, Nicola and Guizzardi, Giancarlo and Mylopoulos, John},
booktitle = {Conceptual Modeling -- ER 2014},
doi = {10.1007/978-3-319-12206-9},
editor = {Yu, Eric and Dobbie, Gillian and Jarke, Matthias and Purao, Sandeep},
file = {:Users/vitor/Mendeley/Wang et al. - 2014 - Software as a Social Artifact A Management and Evolution Perspective.pdf:pdf},
isbn = {978-3-319-12205-2},
keywords = {artifact,bibtex,commented,ontology,software,software configuration management,software evolution,software requirements,software versioning},
mendeley-tags = {bibtex,commented},
pages = {321--334},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Software as a Social Artifact: A Management and Evolution Perspective}},
url = {http://link.springer.com/10.1007/978-3-319-12206-9},
volume = {8824},
year = {2014}
}
@inproceedings{wang-et-al:fois14,
abstract = {Although software plays an essential role in modern society, its ontological nature is still unclear. For many, software is just code, but this is not illuminating. Several researchers have attempted to understand the core nature of software and programs in terms of concepts such as code, copy, medium and execution. More recently, a proposal was made to consider software as an abstract artifact, distinct from code, just because code may change while the software remains the same. We explore in this paper the implications of such a proposal in the light of software engineering and requirements engineering literature. We make a sharp distinction between different kinds of software artifacts (code, program, software system, and software product), and describe the ways they are inter-connected in the context of a software engineering process.},
address = {Rio de Janeiro, RJ, Brasil},
author = {Wang, Xiaowei and Guarino, Nicola and Guizzardi, Giancarlo and Mylopoulos, John},
booktitle = {Proc. of the 8th International Conference on Formal Ontology in Information Systems},
doi = {10.3233/978-1-61499-438-1-317},
editor = {Garbacz, Pawel and Kutz, Oliver},
file = {:Users/vitor/Mendeley/Wang et al. - 2014 - Towards an Ontology of Software a Requirements Engineering Perspective.pdf:pdf},
keywords = {artifact,bibtex,commented,ontology,requirements engineering,software,software engineering},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {317--329},
publisher = {IOS Press},
title = {{Towards an Ontology of Software: a Requirements Engineering Perspective}},
url = {http://ebooks.iospress.nl/volumearticle/37979},
volume = {267},
year = {2014}
}
@article{wang-et-al:ase09,
abstract = {We propose a framework adapted from Artificial Intelligence theories of action and diagnosis for monitoring and diagnosing failures of software requirements. Software requirements are specified using goal models where they are associated with preconditions and postconditions. The monitoring component generates log data that contains the truth values of specified pre/post-conditions, as well as system action executions. Such data can be generated at different levels of granularity, depending on diagnostic feedback. The diagnostic component diagnoses the denial of requirements using the log data, and identifies problematic components. To support diagnostic reasoning, we transform the diagnostic problem into a propositional satisfiability (SAT) problem that can be solved by existing SAT solvers. The framework returns sound and complete diagnoses accounting for observed aberrant system behaviors. Our solution is illustrated with two medium-sized publicly available case studies: a Web-based email client and an ATM simulation. Our experimental results demonstrate the scalability of our approach.},
annote = {10.1007/s10515-008-0042-8},
author = {Wang, Yiqiao and McIlraith, Sheila A. and Yu, Yijun and Mylopoulos, John},
doi = {10.1007/s10515-008-0042-8},
file = {:Users/vitor/Mendeley/Wang et al. - 2009 - Monitoring and diagnosing software requirements.pdf:pdf},
issn = {0928-8910},
journal = {Automated Software Engineering},
keywords = {bibtex,summarized,x-commented},
mendeley-tags = {bibtex,summarized,x-commented},
number = {1},
pages = {3--35},
publisher = {Springer},
title = {{Monitoring and diagnosing software requirements}},
url = {http://www.springerlink.com/content/v6j64723322025x0/},
volume = {16},
year = {2009}
}
@inproceedings{wang-mylopoulos:ase09,
abstract = {High variability software systems can deliver their functionalities in multiple ways by reconﬁguring their com- ponents. High variability has become important because of current trends towards software systems that come in product families, offer high levels of personalization, and ﬁt well within a service-oriented architecture. The purpose of our research is to propose a framework that exploits such variability to allow a software system to self-repair in cases of failure. We propose an autonomic architecture that consists of mon- itoring, diagnosis, reconﬁguration and execution components. This architecture uses requirements models as a basis for monitoring, diagnosis, and reconﬁguration. We illustrate our proposal with a medium-sized publicly available case study (an Automated Teller Machine (ATM) simulation). We evaluate the performance of our framework through a series of experiments. Our experimental results demonstrate that our approach scales to software systems with medium-size requirements.},
address = {Auckland, New Zealand},
author = {Wang, Yiqiao and Mylopoulos, John},
booktitle = {Proc. of the 2009 IEEE/ACM International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2009.66},
file = {:Users/vitor/Mendeley/Wang, Mylopoulos - 2009 - Self-Repair through Reconfiguration A Requirements Engineering Approach.pdf:pdf},
isbn = {978-1-4244-5259-0},
keywords = {adaptive systems,autonomic computing,bibtex,commented,requirement monitoring and diagnosis,self-reconﬁguration},
mendeley-tags = {bibtex,commented},
month = {nov},
pages = {257--268},
publisher = {IEEE},
title = {{Self-Repair through Reconfiguration: A Requirements Engineering Approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5431767},
year = {2009}
}
@inproceedings{welsh-et-al:re11,
abstract = {Requirements awareness should help optimize requirements satisfaction when factors that were uncertain at design time are resolved at runtime. We use the notion of claims to model assumptions that cannot be verified with confidence at design time. By monitoring claims at runtime, their veracity can be tested. If falsified, the effect of claim negation can be propagated to the system's goal model and an alternative means of goal realization selected automatically, allowing the dynamic adaptation of the system to the prevailing environmental context.},
address = {Trento, Italy},
author = {Welsh, Kristopher and Sawyer, Pete and Bencomo, Nelly},
booktitle = {Proc. of the 19th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2011.6051673},
file = {:Users/vitor/Mendeley/Welsh, Sawyer, Bencomo - 2011 - Run-time Resolution of Uncertainty.pdf:pdf},
isbn = {978-1-4577-0921-0},
keywords = {bibtex,commented,goals,requirements models,self-adaptive systems},
mendeley-tags = {bibtex,commented},
month = {aug},
pages = {355--356},
publisher = {IEEE},
title = {{Run-time Resolution of Uncertainty}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6051673},
year = {2011}
}
@inproceedings{wenjie-shi:isiita09,
abstract = {At present, most scholars know the important of requirements evolution, however, efficient methods to guide are still lacked. The paper presents the modeling of reflection requirement based on the {\^{A}}¿-calculus to capture the requirements evolution, and makes it carry out efficiently and controllable. Aimed at the evolution issues of OWL-S requirements specification, this paper proposes a {\^{A}}¿-Calculus based approach to specify the reflective requirements specification model composed with base-level, meta-level and casual connection between two levels. Meanwhile, Based on the process-passing mechanism in high-order {\^{A}}¿-calculus, the evolvement process of requirements specification can be specified. Compared with other related works, our approach is more suitable for the specific evolution mechanism of requirements, such as dynamic modifies requirements specification with consistency and correctness.},
address = {Nanchang, China},
author = {Wen-jie, Yuan and Shi, Ying},
booktitle = {Proc. of the 3rd International Symposium on Intelligent Information Technology Application},
doi = {10.1109/IITA.2009.402},
file = {:Users/vitor/Mendeley/Wen-jie, Shi - 2009 - Evolution-Oriented Reflective Requirements Specifications and its Formalization.pdf:pdf},
isbn = {978-0-7695-3859-4},
keywords = {OWL-S,bibtex,not-commented,reflection,requirements evolution},
mendeley-tags = {bibtex,not-commented},
pages = {164--167},
publisher = {IEEE},
title = {{Evolution-Oriented Reflective Requirements Specifications and its Formalization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5369489},
volume = {3},
year = {2009}
}
@inproceedings{weyns-et-al:seams10,
abstract = {Self-adaptability has been proposed as an effective approach to deal with the increasing complexity, distribution, and dynamicity of modern software systems. Although noteworthy successes have been achieved in many fronts, there is a lack of understanding on how to engineer distributed self-adaptive software systems in which central control is not possible. In this paper, we first describe the key attributes of decentralized self-adaptive systems that set them apart from their centralized counterparts. We illustrate these attributes using two case studies on decentralized self-adaptation. The first case study is an instance of a self-healing system dealing with automated traffic management control. The second case study is an instance of a self-optimizing system that improves the quality of service of a decentralized software system through redeployment of its software components. We generalize the lessons learned from our experiences in the form of a reference model. In light of this model, we present numerous challenges that forms the focus of future research in this area.},
address = {Cape Town, South Africa},
author = {Weyns, Danny and Malek, Sam and Andersson, Jesper},
booktitle = {Proc. of the 2010 ICSE Workshop on Software Engineering for Adaptive and Self-Managing Systems},
doi = {10.1145/1808984.1808994},
file = {:Users/vitor/Mendeley/Weyns, Malek, Andersson - 2010 - On Decentralized Self-Adaptation Lessons from the Trenches and Challenges for the Future.pdf:pdf},
isbn = {9781605589718},
keywords = {bibtex,commented,decentralized control,self-adaptation},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {84--93},
publisher = {ACM},
title = {{On Decentralized Self-Adaptation: Lessons from the Trenches and Challenges for the Future}},
url = {http://portal.acm.org/citation.cfm?doid=1808984.1808994},
year = {2010}
}
@article{whisnant-et-al:ibmsj03,
abstract = {The ability to reconﬁgure software is useful for a variety of reasons, including adapting applications to changing environments, performing on-line software upgrades, and extending base application functionality with additional nonfunctional services. Reconﬁguring distributed applications, however, can be difﬁcult in practice because of the dependencies that exist among the processes in the system. This paper formally describes a model for capturing the structure and run-time behavior of a distributed system. The structure is deﬁned by a set of elements containing the state variables in the system. The run-time behavior is deﬁned by threads that execute atomic actions called operations. Operations invoke code blocks to bring about state changes in the system, and these state changes are conﬁned to a single element and thread. By creating input/output signatures based upon the variable access patterns of the code blocks, dataﬂow dependencies among operations can be derived for a given conﬁguration of the system. Proposed reconﬁgurations can be evaluated through off-line tests using the formal model to determine whether the new mapping of operations-to-code blocks disrupts existing dataﬂow dependencies in the system. System administrators— or software components that control adaptivity in autonomic systems— can use the results of these tests to gauge the impact of a proposed reconﬁguration on the existing system. The system model presented in this paper underpins the design of reconﬁgurable ARMOR (Adaptive Reconﬁgurable Mobile Objects of Reliability) processes that provide ﬂexible error detection and recovery services to user applications.},
address = {Riverton, NJ, USA},
author = {Whisnant, Keith and Kalbarczyk, Zbigniew T and Iyer, Ravishankar K},
doi = {10.1147/sj.421.0045},
file = {:Users/vitor/Mendeley/Whisnant, Kalbarczyk, Iyer - 2003 - A system model for dynamically reconfigurable software.pdf:pdf},
issn = {0018-8670},
journal = {IBM Systems Journal},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
number = {1},
pages = {45--59},
publisher = {IEEE},
title = {{A system model for dynamically reconfigurable software}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5386846},
volume = {42},
year = {2003}
}
@inproceedings{white-at-al:icac04,
abstract = {We describe an architectural approach to achieving the goals of autonomic computing. The architecture that we outline describes interfaces and behavioral requirements for individual system components, describes how interactions among components are established, and recommends design patterns that engender the desired system-level properties of self- configuration, self-optimization, self-healing and self- protection. We have validated many of these ideas in two prototype autonomic computing systems.},
address = {New York, NY, USA},
author = {White, Steve R. and Hanson, James E. and Whalley, Ian and Chess, David M. and Kephart, Jeffrey O.},
booktitle = {Proc. of the 2004 International Conference on Autonomic Computing},
doi = {10.1109/ICAC.2004.1301340},
file = {:Users/vitor/Mendeley/White et al. - 2004 - An Architectural Approach to Autonomic Computing.pdf:pdf},
isbn = {0-7695-2114-2},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {may},
pages = {2--9},
publisher = {IEEE},
title = {{An Architectural Approach to Autonomic Computing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1301340},
year = {2004}
}
@inproceedings{whittle-et-al:soccer08,
abstract = {Self-adaptive systems have the capability to autonomously modify their behaviour at run-time in response to changes in their environment. Such systems are now commonly built in domains as diverse as enterprise computing, automotive control systems, and environmental monitoring systems. To date, however, there has been limited attention paid to how to engineer requirements for such systems. As a result, self-adaptivity is often constructed in an ad-hoc manner. In this paper, we argue that a more rigorous treatment of requirements relating to self-adaptivity is needed and that, in particular, requirements languages for self-adaptive systems should include explicit constructs for specifying and dealing with the uncertainty inherent in self-adaptive systems. We present some initial thoughts on a new requirements language for self-adaptive systems and illustrate it using examples from the services domain.},
address = {Barcelona, Spain},
author = {Whittle, Jon and Sawyer, Pete and Bencomo, Nelly and Cheng, Betty H. C.},
booktitle = {Proc. of the 2008 International Workshop on Service-Oriented Computing: Consequences for Engineering Requirements},
doi = {10.1109/SOCCER.2008.1},
file = {:Users/vitor/Mendeley/Whittle et al. - 2008 - A Language for Self-Adaptive System Requirements.pdf:pdf},
isbn = {978-1-4244-4082-5},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {sep},
pages = {24--29},
publisher = {IEEE},
title = {{A Language for Self-Adaptive System Requirements}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4797489},
year = {2008}
}
@inproceedings{whittle-et-al:re09,
abstract = {Self-adaptive systems have the capability to autonomously modify their behaviour at run-time in response to changes in their environment. Self-adaptation is particularly necessary for applications that must run continuously, even under adverse conditions and changing requirements; sample domains include automotive systems, telecommunications, and environmental monitoring systems. While a few techniques have been developed to support the monitoring and analysis of requirements for adaptive systems, limited attention has been paid to the actual creation and specification of requirements of self-adaptive systems. As a result, self-adaptivity is often constructed in an ad-hoc manner. In this paper, we argue that a more rigorous treatment of requirements explicitly relating to self-adaptivity is needed and that, in particular, requirements languages for self-adaptive systems should include explicit constructs for specifying and dealing with the uncertainty inherent in self-adaptive systems. We present RELAX, a new requirements language for self-adaptive systems and illustrate it using examples from the smart home domain.},
address = {Atlanta, GA, USA},
author = {Whittle, Jon and Sawyer, Pete and Bencomo, Nelly and Cheng, Betty H. C. and Bruel, Jean-Michel},
booktitle = {Proc. of the 17th IEEE International Requirements Engineering Conference},
doi = {10.1109/RE.2009.36},
file = {:Users/vitor/Mendeley/Whittle et al. - 2009 - RELAX Incorporating Uncertainty into the Specification of Self-Adaptive Systems.pdf:pdf},
isbn = {978-0-7695-3761-0},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
month = {aug},
pages = {79--88},
publisher = {IEEE},
title = {{RELAX: Incorporating Uncertainty into the Specification of Self-Adaptive Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5328591},
year = {2009}
}
@article{whittle-et-al:rej10,
abstract = {Self-adaptive systems have the capability to autonomously modify their behavior at run-time in response to changes in their environment. Self-adaptation is particularly necessary for applications that must run continuously, even under adverse conditions and changing requirements; sample domains include automotive systems, telecommunications, and environmental monitoring systems. While a few techniques have been developed to support the monitoring and analysis of requirements for adaptive systems, limited attention has been paid to the actual creation and specification of requirements of self-adaptive systems. As a result, self-adaptivity is often constructed in an ad-hoc manner. In order to support the rigorous specification of adaptive systems requirements, this paper introduces RELAX, a new requirements language for self-adaptive systems that explicitly addresses uncertainty inherent in adaptive systems. We present the formal semantics for RELAX in terms of fuzzy logic, thus enabling a rigorous treatment of requirements that include uncertainty. RELAX enables developers to identify uncertainty in the requirements, thereby facilitating the design of systems that are, by definition, more flexible and amenable to adaptation in a systematic fashion. We illustrate the use of RELAX on smart home applications, including an adaptive assisted living system.},
annote = {10.1007/s00766-010-0101-0},
author = {Whittle, Jon and Sawyer, Pete and Bencomo, Nelly and Cheng, Betty H. C. and Bruel, Jean-Michel},
doi = {10.1007/s00766-010-0101-0},
file = {:Users/vitor/Mendeley/Whittle et al. - 2010 - RELAX a language to address uncertainty in self-adaptive systems requirement.pdf:pdf},
issn = {0947-3602},
journal = {Requirements Engineering},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
number = {2},
pages = {177--196},
publisher = {Springer},
title = {{RELAX: a language to address uncertainty in self-adaptive systems requirement}},
url = {http://www.springerlink.com/content/f3502m7882822411/},
volume = {15},
year = {2010}
}
@misc{wieringa:presentation10,
author = {Wieringa, Roel},
file = {:Users/vitor/Mendeley/Wieringa - 2010 - Design Science Research Methodology Principles and Practice, workshop presented at the 32nd International Conference o.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{Design Science Research Methodology: Principles and Practice, workshop presented at the 32nd International Conference on Software Engineering (handout slides available at http://wwwhome.cs.utwente.nl/{\~{}}roelw/DesignScienceMethodology-handout.pdf)}},
url = {http://wwwhome.cs.utwente.nl/{~}roelw/DesignScienceMethodology-handout.pdf},
year = {2010}
}
@article{wieringa-et-al:re06,
author = {Wieringa, Roel and Maiden, Neil and Mead, Nancy and Rolland, Colette},
doi = {10.1007/s00766-005-0021-6},
issn = {0947-3602},
journal = {Requirements Engineering},
keywords = {bibtex,paper classification,paper evaluation criteria,requirements engineering research,research methods},
mendeley-tags = {bibtex},
number = {1},
pages = {102--107},
publisher = {Springer},
title = {{Requirements engineering paper classification and evaluation criteria: a proposal and a discussion}},
url = {http://link.springer.com/10.1007/s00766-005-0021-6},
volume = {11},
year = {2006}
}
@inproceedings{winbladh-et-al:ase06,
abstract = {This paper presents a speciﬁcation-based approach that addresses several known challenges including false positives and domain knowledge errors. Our approach begins with a goal graph and plans. Source code is annotated with goals and events and precompiled to emit those at run time. Plans are automatically translated into a rule-based recognizer. An oracle is produced from the pre- and post-conditions associated with the plan's goals. When the program is executed, goals and events are emitted and automatically tested against plans and oracles. The concept is demonstrated on a small example and a larger publicly available case study.},
address = {Tokyo, Japan},
author = {Winbladh, Kristina and Alspaugh, Thomas and Ziv, Hadar and Richardson, Debra},
booktitle = {Proc. of the 21st IEEE/ACM International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2006.11},
file = {:Users/vitor/Mendeley/Winbladh et al. - 2006 - An Automated Approach for Goal-driven, Specification-based Testing.pdf:pdf},
isbn = {0-7695-2579-2},
keywords = {bibtex,commented,summarized},
mendeley-tags = {bibtex,commented,summarized},
month = {nov},
pages = {289--292},
publisher = {IEEE},
title = {{An Automated Approach for Goal-driven, Specification-based Testing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4019589},
year = {2006}
}
@inproceedings{winter-strauch:hicss03,
abstract = {Information requirements analysis for data warehouse systems differs significantly from requirements analysis for conventional information systems. Existing data warehouse specific approaches are reviewed. A comprehensive methodology that supports the entire process of determining information requirements of data warehouse users, matching information requirements with actual information supply, evaluating and homogenizing resulting information requirements, establishing priorities for unsatisfied information requirements, and formally specifying the results as a basis for subsequent phases of the data warehouse development (sub)project is proposed. Its components as well as its overall design are based partially on literature review, but mainly on findings from a four year collaboration project with several large companies, mostly from the service sector. While an application of the entire methodology is still outstanding, some components have been successfully applied in actual data warehouse development projects of the participating companies.},
address = {Waikoloa, HI, USA},
author = {Winter, Robert and Strauch, Bernhard},
booktitle = {Proc. of the 36th Annual Hawaii International Conference on System Sciences},
doi = {10.1109/HICSS.2003.1174602},
file = {:Users/vitor/Mendeley/Winter, Strauch - 2003 - A Method for Demand-driven Information Requirements Analysis in Data Warehousing Projects.pdf:pdf},
isbn = {0-7695-1874-5},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {jan},
publisher = {IEEE},
title = {{A Method for Demand-driven Information Requirements Analysis in Data Warehousing Projects}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1174602},
year = {2003}
}
@inproceedings{winter-strauch:sac04,
abstract = {Information requirements analysis for data warehouse systems differs significantly from requirements analysis for conventional information systems. Based on interviews with project managers and information systems managers, requirements for a methodological support of information requirements analysis for data warehouse systems are derived. Existing approaches are reviewed with regard to these requirements. Using the method engineering approach, a comprehensive methodology that supports the entire process of determining information requirements of data warehouse users, matching information requirements with actual information supply, evaluating and homogenizing resulting information requirements, establishing priorities for unsatisfied information requirements, and formally specifying the results as a basis for subsequent phases of the data warehouse development (sub)project has been proposed. The most important sources for methodology components were four in-depth case studies of information requirements analysis practices observed in data warehousing development projects of large organizations. In this paper, these case studies are presented and the resulting consolidated methodology is summarized. While an application of the proposed methodology in its entirety is still outstanding, its components have been successfully applied in actual data warehouse development projects.},
address = {Nicosia, Cyprus},
author = {Winter, Robert and Strauch, Bernhard},
booktitle = {Proc. of the 2004 ACM Symposium on Applied Computing},
doi = {10.1145/967900.968174},
file = {:Users/vitor/Mendeley/Winter, Strauch - 2004 - Information Requirements Engineering for Data Warehouse Systems.pdf:pdf},
isbn = {1581138121},
keywords = {bibtex,data warehouse systems,method engineering,not-commented,requiremetns specification},
mendeley-tags = {bibtex,not-commented},
month = {mar},
pages = {1359--1365},
publisher = {ACM},
title = {{Information Requirements Engineering for Data Warehouse Systems}},
url = {http://portal.acm.org/citation.cfm?doid=967900.968174},
year = {2004}
}
@book{wohlin-et-al:book99,
abstract = {The purpose of Experimentation in Software Engineering: An Introduction is to introduce students, teachers, researchers, and practitioners to experimentation and experimental evaluation with a focus on software engineering. The objective is, in particular, to provide guidelines for performing experiments evaluating methods, techniques and tools in software engineering. The introduction is provided through a process perspective. The focus is on the steps that we go through to perform experiments and quasi-experiments. The process also includes other types of empirical studies. The motivation for the book emerged from the need for support we experienced when turning our software engineering research more experimental. Several books are available which either treat the subject in very general terms or focus on some specific part of experimentation; most focus on the statistical methods in experimentation. These are important, but there were few books elaborating on experimentation from a process perspective, none addressing experimentation in software engineering in particular. The scope of Experimentation in Software Engineering: An Introduction is primarily experiments in software engineering as a means for evaluating methods, techniques and tools. The book provides some information regarding empirical studies in general, including both case studies and surveys. The intention is to provide a brief understanding of these strategies and in particular to relate them to experimentation. Experimentation in Software Engineering: An Introduction is suitable for use as a textbook or a secondary text for graduate courses, and for researchers and practitioners interested in an empirical approach to software engineering.},
author = {Wohlin, Claes and Runeson, Per and H{\"{o}}st, Martin},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{Experimentation in Software Engineering: An Introduction}},
year = {1999}
}
@book{wohlin-et-al:book12,
abstract = {Like other sciences and engineering disciplines, software engineering requires a cycle of model building, experimentation, and learning. Experiments are valuable tools for all software engineers who are involved in evaluating and choosing between different methods, techniques, languages and tools. The purpose of Experimentation in Software Engineering is to introduce students, teachers, researchers, and practitioners to empirical studies in software engineering, using controlled experiments. The introduction to experimentation is provided through a process perspective, and the focus is on the steps that we have to go through to perform an experiment. The book is divided into three parts. The first part provides a background of theories and methods used in experimentation. Part II then devotes one chapter to each of the five experiment steps: scoping, planning, execution, analysis, and result presentation. Part III completes the presentation with two examples. Assignments and statistical material are provided in appendixes. Overall the book provides indispensable information regarding empirical studies in particular for experiments, but also for case studies, systematic literature reviews, and surveys. It is a revision of the authors' book, which was published in 2000. In addition, substantial new material, e.g. concerning systematic literature reviews and case study research, is introduced. The book is self-contained and it is suitable as a course book in undergraduate or graduate studies where the need for empirical studies in software engineering is stressed. Exercises and assignments are included to combine the more theoretical material with practical aspects. Researchers will also benefit from the book, learning more about how to conduct empirical studies, and likewise practitioners may use it as a “cookbook” when evaluating new methods or techniques before implementing them in their organization.},
author = {Wohlin, Claes and Runeson, Per and H{\"{o}}st, Martin and Ohlsson, Magnus C. and Regnell, Bj{\"{o}}rn and Wessl{\'{e}}n, Anders},
doi = {10.1007/978-3-642-29044-2},
edition = {1},
isbn = {978-3-642-29043-5},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {Springer},
title = {{Experimentation in Software Engineering}},
url = {http://link.springer.com/10.1007/978-3-642-29044-2},
year = {2012}
}
@inproceedings{yang-et-al:refsq14,
abstract = {[Context and motivation] Over the last decade, researchers and engineers have developed a vast body of methodologies and technologies in requirements engineering for self-adaptive systems. Although existing studies have explored various aspects of this topic, few of them have categorized and evaluated these areas of research in requirements modeling and analysis. [Question/Problem] This review aims to investigate what modeling methods, RE activities, requirements quality attributes, application domains and research topics have been studied and how well these studies have been conveyed. [Principal ideas/results] We conduct a systematic literature review to answer the research questions by searching relevant studies, appraising the quality of these studies and extracting available data. The results are derived by synthesizing the extracted data with statistical methods. [Contributions] This paper provides an updated review of the research literature, enabling researchers and practitioners to better understand the research trends in these areas and identify research gaps which need to be further studied.},
address = {Essen, Germany},
author = {Yang, Zhuoqun and Li, Zhi and Jin, Zhi and Chen, Yunchuan},
booktitle = {Proc. of the 20th International Working Conference on Requirements Engineering: Foundation for Software Quality},
doi = {10.1007/978-3-319-05843-6_5},
keywords = {bibtex},
mendeley-tags = {bibtex},
month = {apr},
pages = {55--71},
publisher = {Springer},
title = {{A Systematic Literature Review of Requirements Modeling and Analysis for Self-adaptive Systems}},
url = {http://link.springer.com/10.1007/978-3-319-05843-6{\_}5},
year = {2014}
}
@techreport{you:report01,
abstract = {The i* framework models intentional dependency relationships among strategic actors and their rationales. Actors depend on each other for goals to be achieved, tasks to be performed, and resources to be furnished. The concept of soft-goal is used to model quality attributes for which there are not a priori, clear-cut criteria for satisfaction, rather are judged by actors as being sufficiently met (“satisfied”) on a case-by-case basis. This paper describes a real-life case study, the Computer Aided Despatch system deployed by the London Ambulance Service, in the application of the i* framework to its requirements modelling. The objective is to explore the extent to which its problems could have been mitigated if the i* framework were adopted during the development process, especially the Requirements Analysis process. A stepwise approach was taken in this paper, following aspects of the proposed problem were modeled and reviewed: the external environment (inter-organizational), the internal environment (organizational), the alternatives of computer-aided system, and the analysis of the key soft-goal – Effectiveness of a computer-aided system. I argued in this paper that the benefits of applying the i* framework to the LAS case study is qualitatively sufficient for lessoning the disastrous aftermath occurred on the 26/27th of October and the 4th of November, 1992. Even though in the real practice it has to integrate with other techniques to perform a quantitative analysis, the mapping and converting between them can be achieved with affordable effort.},
address = {Toronto, Canada},
author = {You, Zheng},
file = {:Users/vitor/Mendeley/You - 2001 - Experiences with applying the i framework to a real-life system.pdf:pdf},
institution = {Requirements Engineering (CSC2106) Course Project, University of Toronto, Canada},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{Experiences with applying the i* framework to a real-life system}},
year = {2001}
}
@phdthesis{you:masterthesis04,
abstract = {This thesis proposes an extension to the i* framework to address scalabilit y issues. The notion of “view” is exploited to selectively present portions of an i* “baseline model”, which contains all modeled objects for a given application using i* notations. We first reformulate the i* framework and define four types of views—Actor Class, Strategic Dependency, Strategic Rationale, and Evaluation Results. Next, we define sub view types based on the four types of views and supply a view management framework. The views and sub-views are defined using meta-models, and formalized using the Telos conceptual modeling language. Each view type is associated with a formally defined “selection rule” so that the projection of a specific view from a baseline model can be automated. Relationships among views are depicted in View Maps. Illustrative examples are taken from the London Ambulance Service and the Trusted Computing Group case studies.},
address = {Toronto, Canada},
author = {You, Zheng},
file = {:Users/vitor/Mendeley/You - 2004 - Using Meta-Model-Driven Views to Address Scalability in i Models.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
school = {University of Toronto, Canada},
title = {{Using Meta-Model-Driven Views to Address Scalability in i* Models}},
type = {Masters Thesis},
year = {2004}
}
@inproceedings{yu:re97,
abstract = {Requirements are usually understood as stating what a system is supposed to do, as opposed to how it should do it. However, understanding the organizational context and rationales (the “Whys”) that lead up to systems requirements can be just as important for the ongoing success of the system. Requirements modelling techniques can be used to help deal with the knowledge and reasoning needed in this earlier phase of requirements engineering. However, most existing requirements techniques are intended more for the later phase of requirements engineering, which focuses on completeness, consistency, and automated verification of requirements. In contrast, the early phase aims to model and analyze stakeholder interests and how they might be addressed, or compromised, by various system-and-environment alternatives. This paper argues, therefore, that a different kind of modelling and reasoning support is needed for the early phase. An outline of the i* framework is given as an example of a step in this direction. Meeting scheduling is used as a domain example.},
address = {Annapolis, MD, USA},
author = {Yu, Eric S. K.},
booktitle = {Proc. of the 3rd IEEE International Symposium on Requirements Engineering},
doi = {10.1109/ISRE.1997.566873},
file = {:Users/vitor/Mendeley/Yu - 1997 - Towards Modelling and Reasoning Support for Early-Phase Requirements Engineering.pdf:pdf},
isbn = {0-8186-7740-6},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {jan},
pages = {226--235},
publisher = {IEEE},
title = {{Towards Modelling and Reasoning Support for Early-Phase Requirements Engineering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=566873},
year = {1997}
}
@incollection{yu:cmfa09,
abstract = {Many different types of models are used in various scientific and engineering fields, reflecting the subject matter and the kinds of understanding that is sought in each field. Conceptual modeling techniques in software and information systems engineering have in the past focused mainly on describing and analyzing behaviours and structures that are implementable in software. As software systems become ever more complex and densely intertwined with the human social environment, we need models that reflect the social characteristics of complex systems. This chapter reviews the approach taken by the i* framework, highlights its application in several areas, and outlines some open research issues.},
author = {Yu, Eric S. K.},
booktitle = {Conceptual Modeling: Foundations and Applications},
chapter = {7},
doi = {10.1007/978-3-642-02463-4_7},
editor = {Borgida, Alex and Chaudhri, Vinay and Giorgini, Paolo and Yu, Eric},
file = {:Users/vitor/Mendeley/Yu - 2009 - Social Modeling and i.pdf:pdf},
isbn = {978-3-642-02462-7},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
pages = {99--121},
publisher = {Springer},
title = {{Social Modeling and i*}},
url = {http://www.springerlink.com/content/682l1wx71752170t/},
year = {2009}
}
@phdthesis{yu:phdthesis95,
author = {Yu, Eric S. K.},
file = {:Users/vitor/Mendeley/Yu - 1995 - Modelling Strategic Relationships For Process Reengineering.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
school = {University of Toronto, Canada},
title = {{Modelling Strategic Relationships For Process Reengineering}},
url = {ftp://ftp.cdf.toronto.edu/dist/eric/DKBS-TR-94-6.pdf},
year = {1995}
}
@book{yu-et-al:book11,
abstract = {Much of the difficulty in creating information technology systems that truly meet people's needs lies in the problem of pinning down system requirements. This book offers a new approach to the requirements challenge, based on modeling and analyzing the relationships among stakeholders. Although the importance of the system-environment relationship has long been recognized in the requirements engineering field, most requirements modeling techniques express the relationship in mechanistic and behavioral terms. This book describes a modeling approach (called the i* framework) that conceives of software-based information systems as being situated in environments in which social actors relate to each other in terms of goals to be achieved, tasks to be performed, and resources to be furnished. Social perspectives on computing have provided much insight for many years. The i* framework aims to offer a modeling approach to the relationships embedded in computer systems that is part of an engineering method that offers systematic techniques and tools providing smooth linkages to the rest of the system development process, including system design and implementation. The book includes Eric Yu's original proposal for the i* framework as well as research that applies, adapts, extends, or evaluates the social modeling concepts and approach.},
author = {Yu, Eric S. K. and Giorgini, Paolo and Maiden, Neil and Mylopoulos, John},
edition = {1st},
isbn = {978-0-262-24055-0},
keywords = {bibtex},
mendeley-tags = {bibtex},
publisher = {MIT Press},
title = {{Social Modeling for Requirements Engineering}},
url = {http://mitpress.mit.edu/catalog/item/default.asp?ttype=2{\&}tid=12306},
year = {2011}
}
@inproceedings{yu-mylopoulos:icse94,
abstract = {In trying to understandand redesign software processes, it is often necessary to have an understanding of the “whys” that underlie the “whats” – the motivations, intents, and rationales behind the activities and input-output flows. This paper presents a model which captures the intentional structure of a software process and its embedding organization, in terms of dependency relationships among actors. Actors depend on each other for goals to be achieved, tasks to be performed, and resources to be furnished. The model is embedded in the conceptual modelling language Telos. We outline some analytical tools to be developed for the model, and illustrate how the model can help in the systematic design of software processes. The examples used are adaptations of the ISPW-6/7 benchmark example.},
address = {Sorrento, Italy},
author = {Yu, Eric S. K. and Mylopoulos, John},
booktitle = {Proc. of the 16th International Conference on Software Engineering},
file = {:Users/vitor/Mendeley/Yu, Mylopoulos - 1994 - Understanding “Why” in Software Process Modelling, Analysis, and Design.pdf:pdf},
isbn = {0-8186-5855-X},
keywords = {actor dependency,bibtex,engineering,organization modelling,requirements,software process modelling,x-commented},
mendeley-tags = {bibtex,x-commented},
month = {may},
pages = {159--168},
publisher = {IEEE},
title = {{Understanding “Why” in Software Process Modelling, Analysis, and Design}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=296775{\&}tag=1},
year = {1994}
}
@inproceedings{yu-et-al:sac08,
abstract = {Goal models are effective in capturing stakeholder needs at the time when features of the system-to-be have not yet been conceptualized. Relating goals to solution-oriented features gives rise to a requirement traceability problem. In this paper, we present a new model-driven extension to an Early Requirements Engineering tool (OpenOME) that generates an initial feature model of the system-to-be from stakeholder goals. Enabled by such generative mapping, configuration constraints among variability features can be obtained by reasoning about stakeholder goals.},
address = {Fortaleza, CE, Brazil},
author = {Yu, Yijun and {do Prado Leite}, Julio Cesar Sampaio and Lapouchnian, Alexei and Mylopoulos, John},
booktitle = {Proc. of the 2008 ACM Symposium on Applied Computing (SAC 08)},
doi = {10.1145/1363686.1363840},
file = {:Users/vitor/Mendeley/Yu et al. - 2008 - Configuring features with stakeholder goals(2).pdf:pdf},
isbn = {9781595937537},
keywords = {bibtex,commented,configuration management,model-driven,traceability,variability},
mendeley-tags = {bibtex,commented},
month = {mar},
pages = {645--649},
publisher = {ACM},
title = {{Configuring features with stakeholder goals}},
url = {http://portal.acm.org/citation.cfm?doid=1363686.1363840},
year = {2008}
}
@inproceedings{yu-et-al:sac08,
abstract = {Goal models are effective in capturing stakeholder needs at the time when features of the system-to-be have not yet been conceptualized. Relating goals to solution-oriented features gives rise to a requirement traceability problem. In this paper, we present a new model-driven extension to an Early Requirements Engineering tool (OpenOME) that generates an initial feature model of the system-to-be from stakeholder goals. Enabled by such generative mapping, configuration constraints among variability features can be obtained by reasoning about stakeholder goals.},
address = {Fortaleza, CE, Brazil},
author = {Yu, Yijun and {do Prado Leite}, Julio Cesar Sampaio and Lapouchnian, Alexei and Mylopoulos, John},
booktitle = {Proc. of the 2008 ACM Symposium on Applied Computing (SAC '08)},
doi = {10.1145/1363686.1363840},
file = {:Users/vitor/Mendeley/Yu et al. - 2008 - Configuring features with stakeholder goals.pdf:pdf},
isbn = {9781595937537},
keywords = {bibtex,commented,configuration management,model-driven,traceability,variability},
mendeley-tags = {bibtex,commented},
month = {mar},
pages = {645--649},
publisher = {ACM},
title = {{Configuring features with stakeholder goals}},
url = {http://portal.acm.org/citation.cfm?doid=1363686.1363840},
year = {2008}
}
@incollection{yu-et-al:fis08,
abstract = {Software requirements consist of functionalities and qualities to be accommodated during design. Through goal-oriented requirements engineering, stakeholder goals are refined into a space of alternative functionalities. We adopt this framework and propose a decision-making process to generate a generic software design that can accommodate the full space of alternatives each of which can fulfill stakeholder goals. Specifically, we present a process for generating complementary design views from a goal model with high variability in configurations, behavioral specifications, architectures and business processes.},
author = {Yu, Yijun and Lapouchnian, Alexei and Liaskos, Sotirios and Mylopoulos, John and Leite, Julio C. S. P.},
booktitle = {Foundations of Intelligent Systems},
doi = {10.1007/978-3-540-68123-6_1},
editor = {An, Aijun and Matwin, Stan and Ra{\'{s}}, ZbigniewW. and {\'{S}}l{\c{e}}zak, Dominik},
file = {:Users/vitor/Mendeley/Yu et al. - 2008 - From Goals to High-Variability Software Design.pdf:pdf},
isbn = {978-3-540-68122-9},
keywords = {bibtex,commented},
mendeley-tags = {bibtex,commented},
pages = {1--16},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{From Goals to High-Variability Software Design}},
url = {http://link.springer.com/chapter/10.1007{\%}2F978-3-540-68123-6{\_}1},
volume = {4994},
year = {2008}
}
@article{zave-jackson:tsem97,
abstract = {Research in requirements engineering has produced an extensive body of knowledge, but there are four areas in which the foundation of the discipline seems weak or obscure. This article shines some light in the “four dark corners,” exposing problems and proposing solutions. We show that all descriptions involved in requirements engineering should be descriptions of the environment. We show that certain control information is necessary for sound requirements engineering, and we explain the close association between domain knowledge and refinement of requirements. Together these conclusions explain the precise nature of requirements, specifications, and domain knowledge, as well as the precise nature of the relationships among them. They establish minimum standards for what information should be represented in a requirements language. They also make it possible to determine exactly what it means for requirements and engineering to be successfully completed.},
author = {Zave, Pamela and Jackson, Michael},
doi = {10.1145/237432.237434},
file = {:Users/vitor/Mendeley/Zave, Jackson - 1997 - Four Dark Corners of Requirements Engineering.pdf:pdf},
issn = {1049331X},
journal = {ACM Transactions on Software Engineering and Methodology},
keywords = {bibtex,control of actions,domain knowledge,implementation bias,methodologies,not-commented,refinement of requirements,requirements,specifications,theory,verification},
mendeley-tags = {bibtex,not-commented},
month = {jan},
number = {1},
pages = {1--30},
title = {{Four Dark Corners of Requirements Engineering}},
url = {http://portal.acm.org/citation.cfm?doid=237432.237434},
volume = {6},
year = {1997}
}
@incollection{zeleny:hma10,
abstract = {In this chapter we explore some topics beyond traditional MCDM. First we explain in the simplest possible terms what multiobjective optimization is, and define the subject matter of this chapter. We discuss the role of tradeoffs and draw a distinction between tradeoffs-based versus tradeoffs-free thinking. Next, we introduce the concept of optimization and optimal systems design. Then we build the foundation of De novo programming , dealing with designing optimal systems in linear cases. Finally, we provide some numerical examples and discuss additional applications where optimal design and multiobjective optimization can be used.},
annote = {10.1007/978-3-540-92828-7{\_}8},
author = {Zeleny, Milan},
booktitle = {Handbook of Multicriteria Analysis},
chapter = {8},
doi = {10.1007/978-3-540-92828-7_8},
editor = {Zopounidis, Constantin and Pardalos, Panos M. and Hearn, Donald W},
isbn = {978-3-540-92828-7},
keywords = {bibtex},
mendeley-tags = {bibtex},
pages = {243--262},
publisher = {Springer},
series = {Applied Optimization},
title = {{Multiobjective Optimization, Systems Design and De Novo Programming}},
url = {http://www.springerlink.com/content/r537834317110q55/},
volume = {103},
year = {2010}
}
@inproceedings{zeng-et-al:icebe05,
abstract = {In this paper, we present a model-driven approach to Business Performance Management (BPM). BPM is a new frontier in IT-enabled enterprise that supports the moni- toring and control of business operations. BPM solutions must be able to efﬁciently process business events, compute business metrics, detect business situations, and provide the real-time visibility of key performance indicators. In addi- tion, system support is required for the rapid development of BPM solutions and the adaptation of the solutions to the dynamic business environment. We have adopted a meta- model, dubbed the observation meta-model, for capturing the business requirements for BPM, which frees solution de- velopers from low-level programming concerns. We have also used a hybrid compilation-interpretation approach to map an observation model to the runtime executable. First, we extract and refactor the data aspect of the observation model to facilitate runtime access. Second, we compile the operational aspect of the model, such as logic for metric computation and situation detection, into Java code. Third, we develop a runtime engine that interprets the refactored model and dynamically loads the generated code, accord- ing to the meta-model. Our framework further enables the evolution and hot deployment of the observation model and provides the platform for several on-going customer en- gagement efforts.},
address = {Beijing, China},
annote = {Mentions KPIs only in the abstract.},
author = {Zeng, Liangzhao and Lei, Hui and Dikun, Michael and Chang, Henry and Frank, Joachim and Bhaskaran, Kumar},
booktitle = {Proc. of the 2005 IEEE International Conference on e-Business Engineering},
doi = {10.1109/ICEBE.2005.89},
file = {:Users/vitor/Mendeley/Zeng et al. - 2005 - Model-Driven Business Performance Management.pdf:pdf},
isbn = {0-7695-2430-3},
keywords = {bibtex,not-commented,summarized},
mendeley-tags = {bibtex,not-commented,summarized},
month = {oct},
pages = {295--304},
publisher = {IEEE},
title = {{Model-Driven Business Performance Management}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1552908},
year = {2005}
}
@inproceedings{zhang-cheng:wads05,
abstract = {Computer software must dynamically adapt to changing conditions. In order to fully realize the benefit of dynamic adaptation, it must be performed correctly. The correctness of adaptation cannot be properly addressed without precisely specifying the requirements for adaptation. This paper introduces an approach to formally specifying adaptation requirements in temporal logic. We introduce A-LTL, an adaptation-based extension to linear temporal logic, and use this logic to specify three commonly used adaptation semantics. Neighborhood composition and sequential composition techniques are developed and applied to A-LTL to construct the specification of an adaptive system. We introduce adaptation semantics graphs to visually present the adaptation semantics. Specifications for adaptive systems can be automatically generated from adaptation semantics graphs.},
address = {St. Louis, MO, USA},
author = {Zhang, Ji and Cheng, Betty H. C.},
booktitle = {Proc. of the 2005 Workshop on Architecting Dependable Systems},
doi = {10.1145/1083217.1083220},
file = {:Users/vitor/Mendeley/Zhang, Cheng - 2005 - Specifying Adaptation Semantics.pdf:pdf},
isbn = {1595931244},
keywords = {adaptive software,autonomic computing,bibtex,commented,summarized,temporal logic},
mendeley-tags = {bibtex,commented,summarized},
month = {may},
pages = {1--7},
publisher = {ACM},
title = {{Specifying Adaptation Semantics}},
url = {http://portal.acm.org/citation.cfm?doid=1083217.1083220},
year = {2005}
}
@inproceedings{zhang-cheng:icse06,
abstract = {Increasingly, software should dynamically adapt its behavior at run-time in response to changing conditions in the supporting computing and communication infrastructure, and in the surrounding physical environment. In order for an adaptive program to be trusted, it is important to have mechanisms to ensure that the program functions correctly during and after adaptations. Adaptive programs are generally more difficult to specify, verify, and validate due to their high complexity. Particularly, when involving multi-threaded adaptations, the program behavior is the result of the collaborative behavior of multiple threads and software components. This paper introduces an approach to create formal models for the behavior of adaptive programs. Our approach separates the adaptation behavior and non-adaptive behavior specifications of adaptive programs, making the models easier to specify and more amenable to automated analysis and visual inspection. We introduce a process to construct adaptation models, automatically generate adaptive programs from the models, and verify and validate themodels. We illustrate our approach through the development of an adaptive GSM-oriented audio streaming protocol for a mobile computing application.},
address = {Shanghai, China},
author = {Zhang, Ji and Cheng, Betty H. C.},
booktitle = {Proc. of the 28th International Conference on Software Engineering},
doi = {10.1145/1134285.1134337},
file = {:Users/vitor/Mendeley/Zhang, Cheng - 2006 - Model-Based Development of Dynamically Adaptive Software.pdf:pdf},
isbn = {1-59593-375-1},
keywords = {autonomic computing,bibtex,commented,dynamic adaptation,formal specification,global invariants,reliability,summarized,verification},
mendeley-tags = {bibtex,commented,summarized},
month = {may},
pages = {371--380},
publisher = {ACM},
title = {{Model-Based Development of Dynamically Adaptive Software}},
url = {http://portal.acm.org/citation.cfm?doid=1134285.1134337},
year = {2006}
}
@article{zhu-et-al:osr09,
abstract = {Feedback mechanisms can help today's increasingly complex computer systems adapt to changes in workloads or operating conditions. Control theory offers a principled way for designing feedback loops to deal with unpredictable changes, uncertainties, and disturbances in systems. We provide an overview of the joint research at HP Labs and University of Michigan in the past few years, where control theory was applied to automated resource and service level management in data centers. We highlight the key benefits of a control-theoretic approach for systems research, and present specific examples from our experience of designing adaptive resource control systems where this approach worked well. In addition, we outline the main limitations of this approach, and discuss the lessons learned from our experience.},
author = {Zhu, Xiaoyun and Uysal, Mustafa and Wang, Zhikui and Singhal, Sharad and Merchant, Arif and Padala, Pradeep and Shin, Kang},
doi = {10.1145/1496909.1496922},
file = {:Users/vitor/Mendeley/Zhu et al. - 2009 - What Does Control Theory Bring to Systems Research.pdf:pdf},
issn = {01635980},
journal = {ACM SIGOPS Operating Systems Review},
keywords = {bibtex,commented,control theory,dynamics,mdoel,stability,systems research},
mendeley-tags = {bibtex,commented},
month = {jan},
number = {1},
pages = {62},
publisher = {ACM},
title = {{What Does Control Theory Bring to Systems Research?}},
url = {http://dl.acm.org/citation.cfm?doid=1496909.1496922},
volume = {43},
year = {2009}
}
@inproceedings{zowghi-offen:re97,
abstract = {We present a logical framework for modeling and reasoning about the evolution of requirements. We demonstrate how a sufficiently rich meta level logic can formally capture intuitive aspects of managing changes to requirements models, while maintaining completeness and consistency. We consider a theory as the deductive closure of a given set of axioms and conclude that software engineering is concerned, in essence, with, building and managing large theories. This theory construction commences with the development of the requirements model which we view as a theory of some nonmonotonic logic. Requirements evolution then involves the mapping of one such theory to another. Exploiting the deductive power of the theory of belief revision and nonmonotonic reasoning we develop a formal description of this mapping, as well as the requirements engineering process itself. This work thus offers a rigorous approach to reasoning about requirements evolution and a important focus for defining semantically well founded methods and tools for the effective management of changing requirements},
address = {Annapolis, MD , USA},
author = {Zowghi, Didar and Offen, Ray},
booktitle = {Proc. of the 3rd IEEE International Symposium on Requirements Engineering},
doi = {10.1109/ISRE.1997.566875},
file = {:Users/vitor/Mendeley/Zowghi, Offen - 1997 - A Logical Framework for Modeling and Reasoning about the Evolution of Requirements.pdf:pdf},
isbn = {0-8186-7740-6},
keywords = {bibtex,not-commented},
mendeley-tags = {bibtex,not-commented},
month = {aug},
pages = {247--257},
publisher = {IEEE},
title = {{A Logical Framework for Modeling and Reasoning about the Evolution of Requirements}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=566875},
year = {1997}
}
@misc{grl:website11,
file = {:Users/vitor/Mendeley/Unknown - 2011 - GRL Website, httpwww.cs.toronto.edukmGRL (last access January 15th, 2011).pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{GRL Website, http://www.cs.toronto.edu/km/GRL/ (last access: January 15th, 2011)}},
url = {http://www.cs.toronto.edu/km/GRL/},
year = {2011}
}
@misc{omg:website06,
file = {:Users/vitor/Mendeley/Unknown - 2006 - Object Constraint Language, OMG Available Specification, Version 2.0, httpwww.omg.orgcgi-bindocformal2006-05-01.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{Object Constraint Language, OMG Available Specification, Version 2.0, http://www.omg.org/cgi-bin/doc?formal/2006-05-01}},
url = {http://www.omg.org/cgi-bin/doc?formal/2006-05-01},
year = {2006}
}
@misc{eeat:website13,
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{EEAT, http://eeat.cis.gsu.edu:8080/xwiki/bin/view/EEAT/WebHome (last access: October 25th, 2013)}},
url = {http://eeat.cis.gsu.edu:8080/xwiki/bin/view/EEAT/WebHome},
year = {2013}
}
@misc{omg:website08,
file = {:Users/vitor/Mendeley/Unknown - 2008 - OMG Semantics of Business Vocabulary and Rules (SBVR) Specification, v. 1.0 (formal08-01-02), httpwww.omg.orgspecSBVR1..pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{OMG: Semantics of Business Vocabulary and Rules (SBVR) Specification, v. 1.0 (formal/08-01-02), http://www.omg.org/spec/SBVR/1.0/}},
url = {http://www.omg.org/spec/SBVR/1.0/},
year = {2008}
}
@misc{omg:website14,
file = {:Users/vitor/Mendeley/Unknown - 2014 - OMG Ontology Definition Metamodel (ODM) Specification, v. 1.1 (formal14-09-02), httpwww.omg.orgspecODM1.1.pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{OMG: Ontology Definition Metamodel (ODM) Specification, v. 1.1 (formal/14-09-02), http://www.omg.org/spec/ODM/1.1/}},
url = {http://www.omg.org/spec/ODM/1.1/},
year = {2014}
}
@misc{ca:website12,
file = {:Users/vitor/Mendeley/Unknown - 2012 - CA Success Stories, httpwww.ca.comusSuccess-Stories.aspx (last access April 10th, 2012).pdf:pdf},
keywords = {bibtex},
mendeley-tags = {bibtex},
title = {{CA Success Stories, http://www.ca.com/us/Success-Stories.aspx (last access: April 10th, 2012)}},
url = {http://www.ca.com/us/Success-Stories.aspx},
year = {2012}
}
